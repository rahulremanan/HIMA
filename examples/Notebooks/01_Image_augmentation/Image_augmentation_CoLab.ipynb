{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_augmentation_CoLab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "D8b9z7iZuNQN",
        "colab_type": "text",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "# Image augmentation strategies:\n",
        "\n",
        "## Author: Dr. Rahul Remanan \n",
        "### (CEO and Chief Imagination Officer, [Moad Computer](https://www.moad.computer))\n",
        "\n",
        "### Demo data: [Kaggle Cats Vs. Dogs Redux](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition)\n",
        "\n",
        "### [Launch this notebook in Google Colab](https://colab.research.google.com/github/rahulremanan/HIMA/blob/master/examples/Notebooks/01_Image_augmentation/Image_augmentation_CoLab.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "DS23B36vugJv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download data into CoLab instance:"
      ]
    },
    {
      "metadata": {
        "id": "XzPZbthyueZF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6c29d7db-0583-4193-c5ec-14332f1b00ca"
      },
      "cell_type": "code",
      "source": [
        "! pip3 install kaggle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.3)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.3.9)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.0)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KwtJkqhCxz-F",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "d0563597-d5e3-49a1-a777-1996d40a2425"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload() "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bddcbeb0-94d0-436e-9e2a-c32e66902569\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-bddcbeb0-94d0-436e-9e2a-c32e66902569\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VOARSEANKGxT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A_GNnJ2kyDOu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! mv *.json ~/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ee-1jc0HBmXy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "096f1069-f81a-41d7-99ff-e240edfbe0f1"
      },
      "cell_type": "code",
      "source": [
        "! ls ~/.kaggle/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LFfJRxgoxS7j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "dc57c894-030d-4a60-aa68-b6b9c0cb510a"
      },
      "cell_type": "code",
      "source": [
        "! kaggle competitions download -c dogs-vs-cats-redux-kernels-edition"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading test.zip to /content\n",
            " 97% 264M/271M [00:04<00:00, 46.1MB/s]\n",
            "100% 271M/271M [00:04<00:00, 57.1MB/s]\n",
            "Downloading train.zip to /content\n",
            " 97% 529M/544M [00:05<00:00, 102MB/s] \n",
            "100% 544M/544M [00:05<00:00, 106MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/111k [00:00<?, ?B/s]\n",
            "100% 111k/111k [00:00<00:00, 84.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GXlZBR18yScm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! rm ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZQ86t7ZQyumV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! mkdir ./data\n",
        "! mkdir ./data/train\n",
        "! mkdir ./data/train/cats\n",
        "! mkdir ./data/train/dogs\n",
        "! mkdir ./data/preview\n",
        "! mkdir ./data/validation\n",
        "! mkdir ./data/validation/cats/\n",
        "! mkdir ./data/validation/dogs/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MHaLL688y1H7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kMIgaCZMynfQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! mv ./*.zip ./data/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7_LRYC5jzUu2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! unzip -q ./data/train.zip -d ./data/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LcDuFrzSuojv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Label training data:"
      ]
    },
    {
      "metadata": {
        "id": "KxMzDN9vzldl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! mv ./data/train/train/cat.* ./data/train/cats/\n",
        "! mv ./data/train/train/dog.* ./data/train/dogs/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7sXiGC1Dz13w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! ls ./data/train/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jWYFq9aDz65C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! rm -r ./data/train/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LOGKGClU2BXz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! ls ./data/train/dogs/ -1 | wc -l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iDn_zLsw71NB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "i8vRR6im2uVo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! ls ./data/train/cats/ -1 | wc -l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fng-ShcQ7ae7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create train-validation split:"
      ]
    },
    {
      "metadata": {
        "id": "RY-hvhyp23sH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! cd ./data/train/cats/ ; shuf -n 500 -e * | xargs -i mv {} ../../../data/validation/cats/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sgk3b-Ep4W-l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! cd ./data/train/dogs/ ; shuf -n 500 -e * | xargs -i mv {} ../../../data/validation/dogs/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wRdenn6k4eSj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! ls ./data/train/cats/ -1 | wc -l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zOh2TL394ewF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! ls ./data/train/dogs/ -1 | wc -l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZvHgm44F4lwg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! ls ./data/validation/cats/ -1 | wc -l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d-h8inkA4p1X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! ls ./data/validation/dogs/ -1 | wc -l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UefiXipL5vVo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! rm -r ./data/validation/cats/model\n",
        "! rm -r ./data/validation/cats/datalab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lC52bCVi5_OE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! mkdir ./model/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iU3bX0rpuNQV",
        "colab_type": "text",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "## Part 01 - [Using Keras pre-processing:](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)\n",
        "\n",
        "### Why perform image augmentation?\n",
        "\n",
        "In order to make the most out of our few training image data, the process of \"augmentation\" of these images via a number of random transformations is helpful. This process feed the data to the neural network model, so that it would never see twice the exact same picture. The key advantage of implementation such an augmentation strategy is to help prevent overfitting and better generalization by the trained model.\n",
        "\n",
        "In Keras this can be done via the keras.preprocessing.image.ImageDataGenerator class. This class allows you to:\n",
        "\n",
        "* configure random transformations and normalization operations to be done on your image data during training\n",
        "* instantiate generators of augmented image batches (and their labels) via .flow(data, labels) or .flow_from_directory(directory). These generators can then be used with the Keras model methods that accept data generators as inputs, fit_generator, evaluate_generator and predict_generator."
      ]
    },
    {
      "metadata": {
        "id": "l9wH9UjTuNQZ",
        "colab_type": "text",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "### Example implementation of image augmentation in Keras:"
      ]
    },
    {
      "metadata": {
        "id": "g3vBdohzuNQf",
        "colab_type": "code",
        "slideshow": {
          "slide_type": "subslide"
        },
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import warnings\n",
        "    warnings.filterwarnings('ignore')\n",
        "    from keras.preprocessing.image import ImageDataGenerator\n",
        "except:\n",
        "    print (\"Please install Keras (cmd: $sudo pip3 install keras) to run this notebook ...\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N6ADEiXCuNQw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(rotation_range=40,\n",
        "                             width_shift_range=0.2,\n",
        "                             height_shift_range=0.2,\n",
        "                             rescale=1./255,\n",
        "                             shear_range=0.2,\n",
        "                             zoom_range=0.2,\n",
        "                             horizontal_flip=True,\n",
        "                             fill_mode='nearest')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gdq2yPVeuNQ9",
        "colab_type": "text",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "### Image Augmentation in Keras -- Quick start:\n",
        "\n",
        "For more information, see the [documentation](https://keras.io/preprocessing/image/).\n",
        "\n",
        "* rotation_range is a value in degrees (0-180), a range within which to randomly rotate pictures\n",
        "* width_shift and height_shift are ranges (as a fraction of total width or height) within which to randomly translate pictures vertically or horizontally\n",
        "* rescale is a value by which we will multiply the data before any other processing. Our original images consist in RGB coefficients in the 0-255, but such values would be too high for our models to process (given a typical learning rate), so we target values between 0 and 1 instead by scaling with a 1/255. factor.\n",
        "* shear_range is for randomly applying [shearing transformations](https://en.wikipedia.org/wiki/Shear_mapping)\n",
        "* zoom_range is for randomly zooming inside pictures\n",
        "* horizontal_flip is for randomly flipping half of the images horizontally --relevant when there are no assumptions of horizontal assymetry (e.g. real-world pictures).\n",
        "* fill_mode is the strategy used for filling in newly created pixels, which can appear after a rotation or a width/height shift."
      ]
    },
    {
      "metadata": {
        "id": "JGJvYrzBuNRC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k5s1P3nluNRQ",
        "colab_type": "code",
        "slideshow": {
          "slide_type": "subslide"
        },
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(rotation_range=40,\n",
        "                             width_shift_range=0.2,\n",
        "                             height_shift_range=0.2,\n",
        "                             shear_range=0.2,\n",
        "                             zoom_range=0.2,\n",
        "                             horizontal_flip=True,\n",
        "                             fill_mode='nearest')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AkpEZJXxuNRe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os, random\n",
        "random_image = random.choice(os.listdir('./data/train/cats/'))\n",
        "\n",
        "img = load_img(os.path.join('./data/train/cats/' + str(random_image)))\n",
        "print ('Loaded image for preview : ' + str(random_image))\n",
        "x = img_to_array(img)\n",
        "x = x.reshape((1,) + x.shape)  \n",
        "i = 0\n",
        "for batch in datagen.flow(x, batch_size=1,\n",
        "                          save_to_dir='./data/preview/', save_prefix='cat', save_format='jpeg'):\n",
        "    i += 1\n",
        "    if i > 20:\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "niqy0Lx7uNRs",
        "colab_type": "text",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "### Keras pre-processing overview:\n",
        "\n",
        "* The load_img uses Pillow, a complete fork of PIL. This creates a PIL image.\n",
        "* The img_to_array creates a Numpy array with shape (3, 150, 150).\n",
        "* The reshape command creates a Numpy array with shape (1, 3, 150, 150).\n",
        "* The .flow() command below generates batches of randomly transformed images and saves the results to the `../data/cats_dogs/preview/` directory\n",
        "* The break function prevents the loop from iterating indefinitely."
      ]
    },
    {
      "metadata": {
        "id": "uyokM55FuNRx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.image as mpl_image\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image as PyImage"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UcLvvbw2uNR-",
        "colab_type": "code",
        "slideshow": {
          "slide_type": "subslide"
        },
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_images(folder):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = mpl_image.imread(os.path.join(folder, filename))\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "    return images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t6roXIC5uNSO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def stack_plot(stack_size, folder):\n",
        "    rows, cols = stack_size, stack_size\n",
        "    fig,ax = plt.subplots(rows,cols,figsize=[24,24])\n",
        "    i = 0\n",
        "    try:\n",
        "        for filename in os.listdir(folder):\n",
        "            img = mpl_image.imread(os.path.join(folder, filename))\n",
        "            ax[int(i/rows),int(i % rows)].imshow(img)\n",
        "            ax[int(i/rows),int(i % rows)].axis('off')\n",
        "            i += 1\n",
        "    except:\n",
        "        print (\"Failed to add an image to the stacked plot ...\")\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x8LGhGjguNSb",
        "colab_type": "text",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "### Plotting augmented images:\n",
        "\n",
        "* Using matplotlib library.\n",
        "* The load_images function return a Numpy array of all the images in the folder specified in the function.\n",
        "* The stack_plot generates a stack of images contained inside a specific folder of size: stack_size*stack_size"
      ]
    },
    {
      "metadata": {
        "id": "2MPBiizauNSh",
        "colab_type": "code",
        "slideshow": {
          "slide_type": "subslide"
        },
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stack_plot(5, './data/preview/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KWR4-gfWuNSz",
        "colab_type": "text",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "## Part 02 - Implementing a convolutional neural network that uses image augmentation:"
      ]
    },
    {
      "metadata": {
        "id": "gHT9-VwIuNS4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Importing dependent libraries:"
      ]
    },
    {
      "metadata": {
        "id": "mdkTpwKPuNS8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import keras\n",
        "    from keras.preprocessing.image import ImageDataGenerator\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Conv2D, MaxPooling2D\n",
        "    from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "    from keras import backend as K\n",
        "except:\n",
        "    print (\"Failed to load Keras modules. Verify if dependency requirements are satisfied ...\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9nOSbv1BuNTI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* Importing preprocessing.image and models functions from Keras\n",
        "* Importing layers function\n",
        "* Importing keras backend"
      ]
    },
    {
      "metadata": {
        "id": "_pwYs_H6uNTN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Initialize some variables:"
      ]
    },
    {
      "metadata": {
        "id": "ZEa9i9pRuNTQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_width, img_height = 150, 150\n",
        "\n",
        "train_data_dir = './data/train/'\n",
        "validation_data_dir = './data/validation/'\n",
        "\n",
        "nb_train_samples = 24000\n",
        "nb_validation_samples = 1000\n",
        "\n",
        "epochs = 5\n",
        "batch_size = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AxWG4KuIuNTi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FnXzxNg9uNT0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* Using img_width, img_height variables for specifying the dimensions of images to be consumed by the neural network\n",
        "* Initilaizing variables for location pointers to training data, validation data, train data sample size, validation data sample size, number of training epochs, number of images to be processed in each batch\n",
        "* Specifying a function to adjust input shape of the tensor if the image RGB data format is channels first or channels last"
      ]
    },
    {
      "metadata": {
        "id": "g3m_bUxsuNT4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Build and compile a neural network:"
      ]
    },
    {
      "metadata": {
        "id": "0PRzw7O8uNT8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* Building a neural network model using the Sequential format in Keras\n",
        "* Compile the model using binary cross entropy as the loss function, RMSProp as the optimizer and accuracy as the evaluation metrics"
      ]
    },
    {
      "metadata": {
        "id": "C10pDI7TuNT-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8el3MMUvuNUL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h_FnZq8guNUd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Configuring data generators to process and feed the data to the neural network:"
      ]
    },
    {
      "metadata": {
        "id": "NSCST35BuNUg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NcPj3sMguNUx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* The image augmentation configuration for training"
      ]
    },
    {
      "metadata": {
        "id": "gNQnhvJ7uNU1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1. / 255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ACY4UaeSuNVI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* Image augmentation configuration to be used for testing\n",
        "* This generator uses only rescaling"
      ]
    },
    {
      "metadata": {
        "id": "Zho7zZpTuNVM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Creating train and validation generators:"
      ]
    },
    {
      "metadata": {
        "id": "kAql_PWfuNVP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
        "                                                    target_size=(img_width, img_height),\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0wQ7bw11uNVZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "validation_generator = test_datagen.flow_from_directory(validation_data_dir,\n",
        "                                                        target_size=(img_width, img_height),\n",
        "                                                        batch_size=batch_size,\n",
        "                                                        class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CqUIrdL9J1DX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Download pre-trained weights file:"
      ]
    },
    {
      "metadata": {
        "id": "aRTKVRZoG_O6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! wget https://github.com/rahulremanan/HIMA/raw/master/examples/Notebooks/01_Image_augmentation/weights/first_try.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "itQ_w-ZxHSF5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! mv ./first_try.h5 ./model/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PJ6Qta4xIEzn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###[ Loading saved model weights file using Keras](https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model):"
      ]
    },
    {
      "metadata": {
        "id": "vvqBc19zm4e3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_path = './model/first_try.h5'\n",
        "lr = 1e-4\n",
        "\n",
        "import keras\n",
        "\n",
        "if os.path.exists(model_path):\n",
        "  model.load_weights(model_path)\n",
        "  print ('Loaded saved weights file ...')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nqyqes4luNVk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Creating a model fit generator function for training the neural network:"
      ]
    },
    {
      "metadata": {
        "id": "8evvEwTyuNVs",
        "colab_type": "code",
        "slideshow": {
          "slide_type": "subslide"
        },
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit_generator(train_generator,\n",
        "                    steps_per_epoch=nb_train_samples // batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=nb_validation_samples // batch_size,\n",
        "                    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', \n",
        "                                                               min_delta=0, \n",
        "                                                               patience=10, \n",
        "                                                               verbose=0, \n",
        "                                                               mode='min'),\n",
        "                                 keras.callbacks.ModelCheckpoint(model_path,\n",
        "                                                                 monitor='val_loss', \n",
        "                                                                 save_best_only=True, \n",
        "                                                                 mode='min', \n",
        "                                                                 verbose=0),\n",
        "                                 keras.callbacks.ReduceLROnPlateau(monitor='val_acc', \n",
        "                                                                   patience=2,\n",
        "                                                                   mode = 'max',\n",
        "                                                                   min_delta=1e-4, \n",
        "                                                                   cooldown=1,\n",
        "                                                                   verbose=1, \n",
        "                                                                   factor=0.5, \n",
        "                                                                   min_lr=lr*1e-4)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6k9_FBxsuNV2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Saving model weights at the end of the training session:"
      ]
    },
    {
      "metadata": {
        "id": "FHzjF3D0uNV5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save_weights(model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QP76jki3ueu4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! ls ./model/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MVIgifNBuNWD",
        "colab_type": "text",
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "## Part 03 - Improving classification accuracy of a neural network using transfer learning:"
      ]
    },
    {
      "metadata": {
        "id": "ELRyS8DYuNWH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Importing dependent libraries:"
      ]
    },
    {
      "metadata": {
        "id": "uKB79XX3uNWK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YjgPhEVcuNWU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Defining and initializing variables:"
      ]
    },
    {
      "metadata": {
        "id": "UPKxyrLOuNWY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "top_model_weights_path = './model/bottleneck_fc_model.h5'\n",
        "train_data_dir = './data/train'\n",
        "validation_data_dir = './data/validation'\n",
        "bottleneck_train_path = './model/bottleneck_features_train.npy'\n",
        "bottleneck_val_path = './model/bottleneck_features_validation.npy'\n",
        "\n",
        "nb_train_samples = 24000\n",
        "nb_validation_samples = 1000\n",
        "\n",
        "epochs = 2\n",
        "batch_size = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vMw61N2XuNWi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Specify the dimensions of images:"
      ]
    },
    {
      "metadata": {
        "id": "CTU3eNiUuNWl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_width, img_height = 150, 150"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UWs4OT18uNWz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Build the VGG16 network:"
      ]
    },
    {
      "metadata": {
        "id": "aIAVL1equNW4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = applications.VGG16(include_top=False, weights='imagenet', input_shape = (img_width, img_height,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9Fgg2jnHuNXI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define data generator:"
      ]
    },
    {
      "metadata": {
        "id": "bIniB4hduNXL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(rescale=1. / 255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ya8UBCC4uNXa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Creating a function to save bottleneck features:"
      ]
    },
    {
      "metadata": {
        "id": "IJOajJlhuNXd",
        "colab_type": "code",
        "slideshow": {
          "slide_type": "subslide"
        },
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_bottlebeck_features(bottleneck_path=None,\n",
        "                             data_dir = None,\n",
        "                             nb_samples=None,\n",
        "                             batch_size = None):\n",
        "    generator = datagen.flow_from_directory(data_dir,\n",
        "                                            target_size=(img_width, img_height),\n",
        "                                            batch_size=batch_size,\n",
        "                                            class_mode=\"binary\",\n",
        "                                            shuffle=False)\n",
        "    \n",
        "    bottleneck_features = model.predict_generator(generator, nb_samples // batch_size)\n",
        "    \n",
        "    np.save((bottleneck_path),\n",
        "            bottleneck_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pxAnRlJsuNXx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Saving bottleneck features:"
      ]
    },
    {
      "metadata": {
        "id": "_4QUJPl1uNX0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save_bottlebeck_features(bottleneck_path=bottleneck_train_path,\n",
        "                             data_dir = train_data_dir,\n",
        "                             nb_samples = nb_train_samples,\n",
        "                             batch_size = batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "87lfLjGyuNX8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save_bottlebeck_features(bottleneck_path = bottleneck_val_path,\n",
        "                         data_dir = validation_data_dir,\n",
        "                         nb_samples = nb_validation_samples,\n",
        "                         batch_size = batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XUzJ3xqOuNYF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Creating a function to train the top model:"
      ]
    },
    {
      "metadata": {
        "id": "MGRAZiQLuNYH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_top_model(save_path=None, bottleneck_train_path = None, bottleneck_val_path = None):\n",
        "    top_model_weights_path = save_path\n",
        "    train_data = np.load(open(bottleneck_train_path, 'rb'))\n",
        "    train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
        "\n",
        "    validation_data = np.load(open(bottleneck_val_path, 'rb'))\n",
        "    validation_labels = np.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_data, train_labels,\n",
        "              epochs=epochs,\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(validation_data, validation_labels))\n",
        "    \n",
        "    model.save_weights(top_model_weights_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ipEHNP54uNYT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Intialize trainig session of the top model and save weights at the end of training:"
      ]
    },
    {
      "metadata": {
        "id": "TN6wT2A2uNYV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_top_model(save_path=top_model_weights_path,              \\\n",
        "                bottleneck_train_path = bottleneck_train_path, \\\n",
        "                bottleneck_val_path = bottleneck_val_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NnRDPKxJuNYy",
        "colab_type": "text",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "### Fine tuning the model:"
      ]
    },
    {
      "metadata": {
        "id": "ZU9khPJQuNY2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Load dependent libraries:"
      ]
    },
    {
      "metadata": {
        "id": "J6japxDVuNY5",
        "colab_type": "code",
        "slideshow": {
          "slide_type": "subslide"
        },
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t-orkTs2uNZG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Specify dimensions of the images:"
      ]
    },
    {
      "metadata": {
        "id": "EXw3hR8XuNZL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_width, img_height = 150, 150"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wSVSSPpQuNZZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Load model weights:"
      ]
    },
    {
      "metadata": {
        "id": "V4iB6iPjuNZc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weights_path = './model/vgg16_weights.h5'\n",
        "top_model_weights_path = './model/bottleneck_fc_model.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6bivJfP-uNZl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Initialize some variables:"
      ]
    },
    {
      "metadata": {
        "id": "qkb-yfRjuNZo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data_dir = './data/train'\n",
        "validation_data_dir = './data/validation'\n",
        "\n",
        "nb_train_samples = 20000\n",
        "nb_validation_samples = 5000\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 16\n",
        "\n",
        "checkpointer_savepath = './model/checkpointer.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BVSk1q5wuNZx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Build the VGG16 network:"
      ]
    },
    {
      "metadata": {
        "id": "DkO9lDqauNZz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(applications.VGG16(weights='imagenet', include_top=False, input_shape = (img_width, img_height,3)))\n",
        "print('Model loaded ...')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uNZ5Z_j5uNZ8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Build a classifier model to put on top of the V6616 convolutional model:"
      ]
    },
    {
      "metadata": {
        "id": "Kc0yRKSWuNZ_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "top_model = Sequential()\n",
        "top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TbTe3OGWuNaI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Generate model summary:"
      ]
    },
    {
      "metadata": {
        "id": "N2p27vlLuNaK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nkwlwPYA6klN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "top_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RJPows6k0Bbc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! apt-get install -y graphviz libgraphviz-dev && pip3 install pydot graphviz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gsUKQGxyuNaS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model \n",
        "import pydot \n",
        "import graphviz # apt-get install -y graphviz libgraphviz-dev && pip3 install pydot graphviz \n",
        "from IPython.display import SVG \n",
        "from keras.utils.vis_utils import model_to_dot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xKEEMZTKuNai",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output_dir = './model'\n",
        "plot_model(model, to_file= output_dir + '/model_top.png') \n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y-3bWswhuNar",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Load model weights:\n",
        "* It is necessary to start with a fully-trained classifier\n",
        "* This includes the top classifier\n",
        "* Initializing model weights from zero may not train the train the network successfully"
      ]
    },
    {
      "metadata": {
        "id": "grQ5MFFOuNa0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "top_model.load_weights(top_model_weights_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SVIbfjJEuNa9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Add top model to the Vgg16 convolutional base:"
      ]
    },
    {
      "metadata": {
        "id": "Yk14tLZWuNbC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(top_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9F2TXtSnuNbi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Generate sumary with base VGG16 model:"
      ]
    },
    {
      "metadata": {
        "id": "-r1K8OVsuNbk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ExlQuXUHuNbu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output_dir = './model'\n",
        "plot_model(model, to_file= output_dir + '/model_full.png') \n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g5JX7g3cuNb3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Freezing layers:\n",
        "\n",
        "* Freeze the first 25 layers, up to the last conv block\n",
        "* Weighhts become non-trainable and will not be updated"
      ]
    },
    {
      "metadata": {
        "id": "CjFckkeyuNb5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for layer in model.layers[:25]:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DM-mw3h5uNcC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Compile the model:\n",
        "\n",
        "* With a SGD/momentum optimizer\n",
        "* Very slow learning rate."
      ]
    },
    {
      "metadata": {
        "id": "9ZIGHVB4uNcF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k_RpTmfU6_6p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JmQVhzI9uNcP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Prepare data augmentation configuration:"
      ]
    },
    {
      "metadata": {
        "id": "Mi37YHaXuNcS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F7kVOzhKuNcb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1. / 255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PFpkEqs0uNcp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Create generator functions to handle data:"
      ]
    },
    {
      "metadata": {
        "id": "tTZhZMEzuNcs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
        "                                                    target_size=(img_height, img_width),\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mO7hOBzmuNcy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "validation_generator = test_datagen.flow_from_directory(validation_data_dir,\n",
        "                                                        target_size=(img_height, img_width),\n",
        "                                                        batch_size=batch_size,\n",
        "                                                        class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3nG7q48HuNc9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Implement a checkpoiting mechanism:"
      ]
    },
    {
      "metadata": {
        "id": "Pc037gleuNc_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "early_stopper = EarlyStopping(patience=5, verbose=1)\n",
        "checkpointer = ModelCheckpoint(checkpointer_savepath,\\\n",
        "                               verbose=1,\\\n",
        "                               save_best_only=True)\n",
        "reduceLR = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', \n",
        "                                             patience=2,\n",
        "                                             mode = 'max',\n",
        "                                             min_delta=1e-4, \n",
        "                                             cooldown=1,\n",
        "                                             verbose=1, \n",
        "                                             factor=0.5, \n",
        "                                             min_lr=lr*1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B1z4NkAbuNdH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Load saved model:"
      ]
    },
    {
      "metadata": {
        "id": "FTxZ2Y8puNdI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model, load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OwkSwCzuuNdQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "load_from_checkpoint = True\n",
        "load_from_config = False\n",
        "load_model_weights = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jHkC6imTuNda",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if load_from_checkpoint == True and os.path.exists(checkpointer_savepath):\n",
        "    model = load_model(checkpointer_savepath)\n",
        "elif load_from_config == True:\n",
        "    model = load_prediction_model(args)\n",
        "    model = load_prediction_model_weights(args)\n",
        "elif load_model_weights == True:\n",
        "    try:\n",
        "        model = load_prediction_model_weights(args)\n",
        "    except:\n",
        "        print (\"An exception has occurred, while loading model weights ...\")\n",
        "else:\n",
        "    model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PKX8uBoruNdi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Train the model:"
      ]
    },
    {
      "metadata": {
        "id": "V77ir7jIuNdl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit_generator(train_generator,\n",
        "                    steps_per_epoch=nb_train_samples // batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=nb_validation_samples // batch_size,\n",
        "                    callbacks=[early_stopper, checkpointer, reduceLR])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pBJEZVVJuNds",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.output_shape[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZGCTwQRTuNd0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Save the model:"
      ]
    },
    {
      "metadata": {
        "id": "56mbbTeUuNd2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save_weights('./model/vgg16_tl.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T3Mi1ZYKds1V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rXeULtB6giy8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('./model/vgg16_tl.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pwu3OdxZhBOr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! ls ./model/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5OKiFMqBhzvG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('./model/bottleneck_fc_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IkrMiaxqh83U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('./model/bottleneck_features_train.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xb2f2kqOiByu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('./model/bottleneck_features_validation.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rRwJ9x7LiHSw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('./model/first_try.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C4eP1sQLuNd_",
        "colab_type": "text",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "## Part 04 - [Using radial image transformation:](https://arxiv.org/abs/1708.04347)\n",
        "\n",
        "Deep learning models have a large number of free parameters that must be estimated by efficient training of the models on a large number of training data samples to increase their generalization performance. In real-world applications, the data available to train these networks is often limited or imbalanced. Hojjat Salehinejad et.al  propose a sampling method based on the radial transform in a polar coordinate system for image augmentation. This facilitates the training of deep learning models from limited source data. The pixel-wise transformation implemeted here provides representations of the original image in the polar coordinate system by generating a new image from each pixel. This technique can generate radial transformed images up to the number of pixels in the original image to increase the diversity of poorly represented image classes. Our experiments show improved generalization performance in training deep convolutional neural networks using these radial transformed images. "
      ]
    },
    {
      "metadata": {
        "id": "brpt7H5suNeB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from skimage import data\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IJgwneVGuNeJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_gray(img):\n",
        "    w, h,_ = img.shape\n",
        "    ret = np.empty((w, h), dtype=np.uint8)\n",
        "    retf = np.empty((w, h), dtype=np.float)\n",
        "    imgf = img.astype(float)\n",
        "    retf[:, :] = ((imgf[:, :, 1] + imgf[:, :, 2] + imgf[:, :, 0])/3)\n",
        "    ret = retf.astype(np.uint8)\n",
        "    return ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iKMHnpYmuNec",
        "colab_type": "code",
        "slideshow": {
          "slide_type": "subslide"
        },
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def radial_transform(img,w,h):\n",
        "    shape = im.shape\n",
        "\n",
        "    new_im = np.zeros(shape)\n",
        "    print(shape)\n",
        "    print(len(shape))\n",
        "    print('w',w)\n",
        "    print('h',h)\n",
        "    width = shape[1]\n",
        "    height = shape[0]\n",
        "    lens = len(shape)\n",
        "    for i in range(0,width):\n",
        "\t    xita = 2*3.14159*i/width\n",
        "\t    for a in range(0,height):\n",
        "\t\t    x = (int)(math.floor(a * math.cos(xita)))\n",
        "\t\t    y = (int)(math.floor(a * math.sin(xita)))\n",
        "\t\t    new_y = (int)(h+x)\n",
        "\t\t    new_x = (int)(w+y)\n",
        "\t\t    #print(h.dtype)\n",
        "\t\t    if new_x>=0 and new_x<width:\n",
        "\t\t\t    if new_y>=0 and new_y<height:\n",
        "\t\t\t\t    if lens==3:\n",
        "\t\t\t\t\t    new_im[a,i,0] = (im[new_y,new_x,0]-127.5)/128\n",
        "\t\t\t\t\t    new_im[a,i,1] = (im[new_y,new_x,1]-127.5)/128\n",
        "\t\t\t\t\t    new_im[a,i,2] = (im[new_y,new_x,2]-127.5)/128\n",
        "\t\t\t\t    else:\n",
        "\t\t\t\t\t    new_im[a,i] = (im[new_y,new_x]-127.5)/128\n",
        "\t\t\t\t\t    new_im[a,i] = (im[new_y,new_x]-127.5)/128\n",
        "\t\t\t\t\t    new_im[a,i] = (im[new_y,new_x]-127.5)/128\n",
        "    return new_im"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EV9EGlMJj629",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! ls ./data/preview/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PF7D9kPBuNej",
        "colab_type": "code",
        "slideshow": {
          "slide_type": "subslide"
        },
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os, random\n",
        "random_image = random.choice(os.listdir('./data/preview/'))\n",
        "\n",
        "im = io.imread(os.path.join('./data/preview/' + str(random_image)))\n",
        "print (\"Applying radial image transformation on image: \" + str(random_image))\n",
        "im = to_gray(im)\n",
        "h = im.shape[0]\n",
        "w = im.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hot8M3NyuNes",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rt_im1 = radial_transform(im,(int)(w/2),(int)(h/2))\n",
        "rt_im2 = radial_transform(im,(int)(w/4),(int)(h/4))\n",
        "rt_im3 = radial_transform(im,(int)(w*0.5),(int)(h*0.75))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1fRSxj8Uk-O2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! mkdir ./data/preview/radial_transform/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nHuAGuN0uNe7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "io.imshow(im)\n",
        "io.imsave('./data/preview/radial_transform/112.jpg',im)\n",
        "io.imsave('./data/preview/radial_transform/112_1.jpg',rt_im1)\n",
        "io.imsave('./data/preview/radial_transform/112_2.jpg',rt_im2)\n",
        "io.imsave('./data/preview/radial_transform/112_3.jpg',rt_im3)\n",
        "io.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ISL_rQB4uNfH",
        "colab_type": "code",
        "slideshow": {
          "slide_type": "subslide"
        },
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(num='cats_dogs',figsize=(8,8))  \n",
        "\n",
        "plt.subplot(2,2,1)     \n",
        "plt.title('Input image')  \n",
        "plt.imshow(im,plt.cm.gray)      \n",
        "\n",
        "plt.subplot(2,2,2)    \n",
        "plt.title('Radial image transformation by: 0.5')  \n",
        "plt.imshow(rt_im1,plt.cm.gray)     \n",
        "plt.axis('off')    \n",
        "\n",
        "plt.subplot(2,2,3)    \n",
        "plt.title('Radial image transformation by: 0.25')  \n",
        "plt.imshow(rt_im2,plt.cm.gray)     \n",
        "plt.axis('off')    \n",
        "\n",
        "plt.subplot(2,2,4)    \n",
        "plt.title('Radial image transformation by: 0.75')  \n",
        "plt.imshow(rt_im3,plt.cm.gray)     \n",
        "plt.axis('off')     \n",
        "\n",
        "plt.show() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b25GPAd9lWn9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! ls ./data/preview/radial_transform/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ggviOQALmIpl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('./data/preview/radial_transform/112.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6wx6y3kSmRFc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('./data/preview/radial_transform/112_1.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JmBTqYK8mSMy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('./data/preview/radial_transform/112_2.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8OVWcmBMmTaA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('./data/preview/radial_transform/112_3.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}