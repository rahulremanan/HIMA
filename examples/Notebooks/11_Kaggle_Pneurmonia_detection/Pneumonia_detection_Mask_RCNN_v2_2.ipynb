{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pneumonia_detection_Mask_RCNN_v2_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "2I3ZIYZ9lYSu"
      },
      "cell_type": "markdown",
      "source": [
        "# [Radiological Society of North America -- Pneumonia Detection Challenge](https://www.kaggle.com/c/rsna-pneumonia-detection-challenge)\n",
        "\n",
        "Pneumonia accounts for over 15% of all deaths of children under 5 years old internationally. In 2015, 920,000 children under the age of 5 died from the disease. In the United States, pneumonia accounts for over 500,000 visits to emergency departments [1](www.cdc.gov/nchs/data/nhamcs/web_tables/2015_ed_web_tables.pdf) and over 50,000 deaths in 2015 [2](http://www.cdc.gov/nchs/data/nvsr/nvsr66/nvsr66_06_tables.pdf), keeping the ailment on the list of top 10 causes of death in the country.\n",
        "\n",
        "While common, accurately diagnosing pneumonia is a tall order. It requires review of a chest radiograph (CXR) by highly trained specialists and confirmation through clinical history, vital signs and laboratory exams. Pneumonia usually manifests as an area or areas of increased opacity [3](https://www.ncbi.nlm.nih.gov/pubmed/30036297) on CXR. However, the diagnosis of pneumonia on CXR is complicated because of a number of other conditions in the lungs such as fluid overload (pulmonary edema), bleeding, volume loss (atelectasis or collapse), lung cancer, or post-radiation or surgical changes. Outside of the lungs, fluid in the pleural space (pleural effusion) also appears as increased opacity on CXR. When available, comparison of CXRs of the patient taken at different time points and correlation with clinical symptoms and history are helpful in making the diagnosis.\n",
        "\n",
        "CXRs are the most commonly performed diagnostic imaging study. A number of factors such as positioning of the patient and depth of inspiration can alter the appearance of the CXR [4](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3632825/), complicating interpretation further. In addition, clinicians are faced with reading high volumes of images every shift.\n",
        "\n",
        "[The images for the Kaggle-RSNA challenge are from the NIH chest x-ray dataset](https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/36938765345). National Institutes of Health Clinical Center has provided this Chest X-Ray dataset publicly.[5](http://openaccess.thecvf.com/content_cvpr_2017/papers/Wang_ChestX-ray8_Hospital-Scale_Chest_CVPR_2017_paper.pdf) There has already been excellent attempts at developing an end-to-end deep-learning models, using this dataset, that classifies chest x-rays with expert human level accuracy.[6](https://stanfordmlgroup.github.io/projects/chexnet/)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "x0i215yRg6Uv",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "setup = True\n",
        "download_data = True\n",
        "update_weights = True\n",
        "\n",
        "gen_preds = True\n",
        "download_submission = True\n",
        "fetch_raw_data = False\n",
        "upload_data = False\n",
        "\n",
        "colab_mode = True\n",
        "\n",
        "use_transfer_learn = False\n",
        "fine_tune = False\n",
        "load_weights =True\n",
        "\n",
        "stage_2 = True\n",
        "\n",
        "use_augmentation = 2 # 0, 1 or 2\n",
        "\n",
        "LEARNING_RATE = 1e-5\n",
        "NUM_EPOCHS = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "K5VOhfCT6wes",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Original DICOM image size: 1024 x 1024\n",
        "ORIG_SIZE = 1024\n",
        "IMG_PROC_SIZE = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KQExkuZs29ez",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "hello = tf.constant('Hello, TensorFlow!')\n",
        "sess = tf.Session()\n",
        "print(tf.__version__)\n",
        "print(sess.run(hello))\n",
        "\n",
        "print(tf.GIT_VERSION, tf.VERSION)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PCQySLbGpEP6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os \n",
        "import sys\n",
        "import subprocess"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fAKjuZb-fnYt",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def execute_in_shell(command=None, \n",
        "                     verbose = False):\n",
        "    \"\"\" \n",
        "        command -- keyword argument, takes a list as input\n",
        "        verbsoe -- keyword argument, takes a boolean value as input\n",
        "    \n",
        "        This is a function that executes shell scripts from within python.\n",
        "        \n",
        "        Keyword argument 'command', should be a list of shell commands.\n",
        "        Keyword argument 'verbose', should be a boolean value to set verbose level.\n",
        "        \n",
        "        Example usage: execute_in_shell(command = ['ls ./some/folder/',\n",
        "                                                    ls ./some/folder/  -1 | wc -l'],\n",
        "                                        verbose = True ) \n",
        "                                        \n",
        "        This command returns dictionary with elements: Output and Error.\n",
        "        \n",
        "        Output records the console output,\n",
        "        Error records the console error messages.\n",
        "                                        \n",
        "    \"\"\"\n",
        "    error = []\n",
        "    output = []\n",
        "    \n",
        "    if isinstance(command, list):\n",
        "        for i in range(len(command)):\n",
        "            try:\n",
        "                process = subprocess.Popen(command[i], shell=True, stdout=subprocess.PIPE)\n",
        "                process.wait()\n",
        "                out, err = process.communicate()\n",
        "                error.append(err)\n",
        "                output.append(out)\n",
        "                if verbose:\n",
        "                    print ('Success running shell command: {}'.format(command[i]))\n",
        "            except Exception as e:\n",
        "                print ('Failed running shell command: {}'.format(command[i]))\n",
        "                if verbose:\n",
        "                    print(type(e))\n",
        "                    print(e.args)\n",
        "                    print(e)\n",
        "                \n",
        "    else:\n",
        "        print ('The argument command takes a list input ...')\n",
        "    return {'Output': output, 'Error': error }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LY1WnphPofDT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "command = ['pip3 install -q pydicom kaggle PyDrive  cython >/dev/null 2>&1',\n",
        "           'git clone https://github.com/rahulremanan/Mask_RCNN >/dev/null 2>&1',\n",
        "           'git clone https://github.com/rahulremanan/cocoapi >/dev/null 2>&1',\n",
        "           'cd ./cocoapi/PythonAPI/; make >/dev/null 2>&1; make install >/dev/null 2>&1; python3 setup.py install >/dev/null 2>&1; python3 setup.py build_ext --inplace >/dev/null 2>&1',\n",
        "           'cd ./Mask_RCNN/; pip3 install -r requirements.txt >/dev/null 2>&1; python3 setup.py install >/dev/null 2>&1',\n",
        "           'mkdir /content/',\n",
        "           'mkdir /content/.kaggle/',\n",
        "           'mkdir ./pneumonia_detection/']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Z2HB8eMagjjT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if setup and colab_mode:\n",
        "  execute_in_shell(command = command, \n",
        "                   verbose = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "w1krniYdm50e",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pydicom\n",
        "from imgaug import augmenters as iaa\n",
        "from tqdm import tqdm\n",
        "import pandas as pd \n",
        "import glob "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "crGcqEbP29gH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if colab_mode:\n",
        "    from pydrive.auth import GoogleAuth\n",
        "    from pydrive.drive import GoogleDrive\n",
        "    from google.colab import auth\n",
        "    from oauth2client.client import GoogleCredentials\n",
        "    from googleapiclient.http import MediaIoBaseDownload"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2tL_4kbOrbCU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import io\n",
        "import glob\n",
        "import fnmatch\n",
        "import random\n",
        "\n",
        "from multiprocessing import Process"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "4thnyYZwrj38"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 01 -- Fetching and processing data"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "wWclH9mzhUnK"
      },
      "cell_type": "markdown",
      "source": [
        "### Setting up Kaggle access for Google Colab\n",
        "\n",
        "1.  Click on the right top corner of Kaggle website, where it displays your profile picture\n",
        "2.  Go to My Accounts\n",
        "3. Under API, click on Create new API token\n",
        "4. Upload the kaggle.json file to Google Colab environment or to the Jupyter notebook\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "dXEQwtTLklSz"
      },
      "cell_type": "markdown",
      "source": [
        "#### Upload kaggle.json file"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "baYztOythLM4",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if setup and fetch_raw_data and colab_mode:\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "tRiLz1Zaks5k"
      },
      "cell_type": "markdown",
      "source": [
        "### Download RSNA pneumonia detection dataset using Kaggle API"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "DvdoRWwNfGkK",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "command = ['mv ./*.json /content/.kaggle/',\n",
        "           'cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json',\n",
        "           'chmod ~/.kaggle/kaggle.json',\n",
        "           'kaggle competitions download -c rsna-pneumonia-detection-challenge',\n",
        "           'mv /content/stage_1_* ./',\n",
        "           'mv /content/stage_2_* ./']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Y-5TI7oLhWFj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if fetch_raw_data:\n",
        "  execute_in_shell(command = command, verbose = True)\n",
        "  filename = \"/content/.kaggle/kaggle.json\"\n",
        "  os.chmod(filename, 600)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "G_Cs3gPgr4ra"
      },
      "cell_type": "markdown",
      "source": [
        "### Setup Google Drive as Colab object storage"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "90rIo8vqpmqU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cloud_authenticate():\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  print (\"Sucessfully authenticated to access Google Drive ...\")\n",
        "  return drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FBuC3cnN0wNn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Authenticate Google Drive in CoLab mode"
      ]
    },
    {
      "metadata": {
        "id": "jfC1o7az0nOJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if colab_mode:\n",
        "    drive = cloud_authenticate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ax05uMCo02Nb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Google Drive fetch and save for CoLab"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9x-yY5XCpp_d",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def googledrive_fetch(file_name = None, \n",
        "                fetch=True, \n",
        "                fetch_by_id = False,\n",
        "                latest = True,\n",
        "                file_id = None,\n",
        "                multi_file = False):\n",
        "  \n",
        "  \"\"\"\n",
        "    A function that fetches files from Google Drive.\n",
        "    \n",
        "    The function takes five keyword arguments:\n",
        "      file_name -- Passes the file name string\n",
        "      fetch -- Specify if a file name should be downloaded\n",
        "      fetch_by_id -- Specify a file to be downloaded by file id\n",
        "      multi_file -- Download all the files with the same file name from Google Drive\n",
        "  \"\"\"\n",
        "  \n",
        "  query = 'title='+\"'\"+file_name+\"'\"\n",
        "  try:\n",
        "    file_list=drive.ListFile({'q': \"{}\".format(query)}).GetList()\n",
        "  except:\n",
        "    return (\"Error finding file with {}\".format(query))\n",
        "  \n",
        "  if len(file_list) >1:\n",
        "    print (\"A total of {} files with the same file name found ...\".format(len(file_list)))\n",
        "    for f in file_list:\n",
        "      title = f['title']\n",
        "      id = f.metadata.get('id')\n",
        "      print (\"Found: {} file, with file id: {}\".format(title, id))\n",
        "    \n",
        "    if multi_file:\n",
        "      print (\"Downloading {} files with file name {}\".format(len(file_list), title))\n",
        "      print (\"Staring download ...\")\n",
        "    elif latest:\n",
        "      print (\"Downloading the most recent {} file ...\".format(title))\n",
        "    elif file_id == None:\n",
        "      print (\"Set keyword argument fetch_by_id = True and specify id using keyword argument file_id = 'id' to download a specific file ...\")\n",
        "      print (\"--OR--\")\n",
        "      print (\"Set keyword argument multi_file = True to automatically download all the files ...\")\n",
        "      return None\n",
        "    else:\n",
        "      print (\"Starting download ...\")\n",
        "    \n",
        "  n = 0\n",
        "  \n",
        "  if latest:\n",
        "    try:\n",
        "      title = file_list[0]['title']\n",
        "    except:\n",
        "      return (\"Error finding file with {}\".format(query))\n",
        "    latest_file_id = file_list[0].metadata.get('id')\n",
        "    print (\"Found most recent version of: {} file with file id: {} ...\".format(title, latest_file_id))    \n",
        "  \n",
        "  for f in file_list:\n",
        "      if fetch and multi_file and n>0:\n",
        "        save_path = os.path.join('./'+str(n)+'_'+file_name)\n",
        "      else:\n",
        "        save_path = os.path.join('./'+file_name)     \n",
        "      \n",
        "      title = f['title']\n",
        "      \n",
        "      if fetch_by_id and file_id !=None:\n",
        "        id = file_id\n",
        "      elif latest:\n",
        "        id = latest_file_id\n",
        "      elif fetch_by_id and file_id == None:\n",
        "        print ('Please specify the file id for downloading using the file_id argument ...')\n",
        "      else:\n",
        "        id = f.metadata.get('id')\n",
        "      \n",
        "      print (\"Downloading {} file, with file id: {} ...\".format(title, id))\n",
        "      \n",
        "      if fetch or fetch_by_id or latest:\n",
        "        local_file = io.FileIO(save_path, mode='wb')\n",
        "        try:\n",
        "          request = drive.auth.service.files().get_media(fileId=id)\n",
        "          downloader = MediaIoBaseDownload(local_file, request, chunksize=2048*102400)\n",
        "\n",
        "          done = False\n",
        "\n",
        "          while done is False:\n",
        "              status, done = downloader.next_chunk()\n",
        "        except:\n",
        "          return 'Downloading failed ...'\n",
        "        \n",
        "        local_file.close()\n",
        "        print (\"Successfully downloaded the file: {} to: {} ...\".format(file_name, save_path))\n",
        "      \n",
        "      if fetch_by_id and file_id !=None:\n",
        "        return None\n",
        "      elif latest:\n",
        "        return None\n",
        "      elif n >= 0:\n",
        "        print (\"Downloaded {} of {} files ...\".format(n+1, len(file_list)))\n",
        "      else:\n",
        "        print (\"Download failed ...\")\n",
        "      \n",
        "      n +=1\n",
        "  \n",
        "  return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "MoCWoNwXps3D",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def googledrive_save(file_name = None, \n",
        "               file_dir = None, \n",
        "               upload = False,\n",
        "               prefix = None):\n",
        "  if upload == True and file_name != None and file_dir !=None:\n",
        "    try:\n",
        "      if prefix != None:\n",
        "        file = drive.CreateFile({'title': str(prefix) + str(file_name) })\n",
        "      else:\n",
        "        file = drive.CreateFile({'title': str(file_name) })\n",
        "      file.SetContentFile(os.path.join(file_dir + str(file_name)))\n",
        "      file.Upload()\n",
        "      print (str(file_name) + \" successfully uploaded to Google drive ...\")\n",
        "    except:\n",
        "      print (\"Failed to save :\" + str(file_name) + \" to Google drive ...\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d93s0_Cv29h2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Setup Google Drive as object storage using rClone"
      ]
    },
    {
      "metadata": {
        "id": "ho6XwH2P29h6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rClone_upload(drive_name = None,\n",
        "                  local_folder = None,\n",
        "                  cloud_folder = None,\n",
        "                  verbose = False):\n",
        "    command = ['rclone copy {} {}:{}'.format(local_folder,\n",
        "                                             drive_name, \n",
        "                                             cloud_folder)]\n",
        "    execute_in_shell(command = command, \n",
        "                     verbose = verbose)\n",
        "    del command"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pSJAqC8B29iH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rClone_download(drive_name = None,\n",
        "                    local_folder = None,\n",
        "                    cloud_folder = None,\n",
        "                    verbose = False):\n",
        "    command = ['rclone copy {}:{} {}'.format(drive_name, \n",
        "                                             cloud_folder, \n",
        "                                             local_folder)]\n",
        "    execute_in_shell(command = command, \n",
        "                     verbose = verbose)\n",
        "    del command"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ptGPQCO429iT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Authenticate Google drive in Colab"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FPgipDFAw0js",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if colab_mode:\n",
        "    drive = cloud_authenticate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "HoquDImWsEPj"
      },
      "cell_type": "markdown",
      "source": [
        "#### Upload data to object storage"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "P8i3lkCU3we_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_dir = './pneumonia_detection/'\n",
        "file_name = ['stage_1_detailed_class_info.csv.zip',\n",
        "             'stage_1_train_images.zip',\n",
        "             'stage_1_sample_submission.csv',\n",
        "             'stage_1_train_labels.csv.zip',\n",
        "             'stage_1_test_images.zip']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0b8Gggiunm6F",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if upload_data and colab_mode:\n",
        "  for f in file_name:\n",
        "    googledrive_save(file_name = f,\n",
        "               file_dir = './',\n",
        "               upload = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xMVO9cmj7eGR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_dir = './pneumonia_detection/'\n",
        "file_name = ['stage_2_detailed_class_info.csv.zip',\n",
        "             'stage_2_train_images.zip',\n",
        "             'stage_2_sample_submission.csv',\n",
        "             'stage_2_train_labels.csv.zip',\n",
        "             'stage_2_test_images.zip']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vHe9bVj28IDW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if upload_data and colab_mode and stage_2:\n",
        "  for f in file_name:\n",
        "    googledrive_save(file_name = f,\n",
        "               file_dir = './',\n",
        "               upload = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "MxS2zjK0sJsZ"
      },
      "cell_type": "markdown",
      "source": [
        "#### Download data from object storage"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jWwaNBtVxBSN",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if download_data and colab_mode:\n",
        "  for f in file_name:\n",
        "    googledrive_fetch(file_name = f, \n",
        "                      fetch=True, \n",
        "                      latest = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sLArR9qaQmZ3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_dir = './pneumonia_detection/'\n",
        "file_name = ['mask_rcnn_coco.h5',\n",
        "             '{}_mask_rcnn_pneumonia.h5'.format(IMG_PROC_SIZE)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pwX7Cnb1ZIP3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if upload_data and colab_mode:\n",
        "  for f in file_name:\n",
        "    googledrive_save(file_name = f,\n",
        "               file_dir = './',\n",
        "               upload = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wfLUkPCMYpFt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if download_data and colab_mode:\n",
        "  for f in file_name:\n",
        "    googledrive_fetch(file_name = f, \n",
        "                fetch=True, \n",
        "                latest = True)\n",
        "elif update_weights:\n",
        "  for f in file_name:\n",
        "    googledrive_fetch(file_name = f, \n",
        "                fetch=True, \n",
        "                latest = True)\n",
        "else:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v3A9Kjc2Qxzm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "command = ['mv ./{}_mask_rcnn_pneumonia.h5 ./mask_rcnn_pneumonia.h5'.format(IMG_PROC_SIZE)]\n",
        "if setup and download_data and colab_mode:\n",
        "  execute_in_shell(command = command, \n",
        "                   verbose = True)\n",
        "elif os.path.exists('./{}_mask_rcnn_pneumonia.h5'.format(IMG_PROC_SIZE)):\n",
        "  execute_in_shell(command = command, \n",
        "                   verbose = True)\n",
        "else:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o9XW40i2QyOz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "command = ['mv ./pneumonia_detection/{}_mask_rcnn_pneumonia.h5 ./mask_rcnn_pneumonia.h5'.format(IMG_PROC_SIZE)]\n",
        "if setup and download_data and not colab_mode:\n",
        "  execute_in_shell(command = command, \n",
        "                   verbose = True)\n",
        "elif os.path.exists('./pneumonia_detection/{}_mask_rcnn_pneumonia.h5'.format(IMG_PROC_SIZE)):\n",
        "  execute_in_shell(command = command, \n",
        "                   verbose = True)\n",
        "else:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "a3L0j-k9scfp"
      },
      "cell_type": "markdown",
      "source": [
        "#### Unzip and prepare data for ingestion into a deep-neural network"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "CwNATEcMFove",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "command = ['ls ./pneumonia_detection/',\n",
        "           'mkdir ./pneumonia_detection/stage_1_train_images/',\n",
        "           'mkdir ./pneumonia_detection/stage_1_test_images/',\n",
        "           'unzip -q ./stage_1_detailed_class_info.csv.zip -d ./pneumonia_detection/',\n",
        "           'unzip -q ./stage_1_train_images.zip  -d ./pneumonia_detection/stage_1_train_images/',\n",
        "           'unzip -q ./stage_1_train_labels.csv.zip -d ./pneumonia_detection/',\n",
        "           'unzip -q ./stage_1_test_images.zip -d ./pneumonia_detection/stage_1_test_images/']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aby2x8_ByeD7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if setup and not stage_2:\n",
        "  execute_in_shell(command = command, verbose = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p7ZQzDzV8278",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "command = ['ls ./pneumonia_detection/',\n",
        "           'mkdir ./pneumonia_detection/stage_2_train_images/',\n",
        "           'mkdir ./pneumonia_detection/stage_2_test_images/',\n",
        "           'unzip -q ./stage_2_detailed_class_info.csv.zip -d ./pneumonia_detection/',\n",
        "           'unzip -q ./stage_2_train_images.zip  -d ./pneumonia_detection/stage_2_train_images/',\n",
        "           'unzip -q ./stage_2_train_labels.csv.zip -d ./pneumonia_detection/',\n",
        "           'unzip -q ./stage_2_test_images.zip -d ./pneumonia_detection/stage_2_test_images/']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8TQFS-ed9F_y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if setup and stage_2:\n",
        "  execute_in_shell(command = command, verbose = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2uTxxGRuZyF2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cmd = [\"wget --quiet https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\"]\n",
        "\n",
        "if use_transfer_learn and not load_weights and setup and fetch_raw_data:\n",
        "  execute_in_shell(command = command, verbose = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tCOysUloYcSt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "COCO_WEIGHTS_PATH = \"./mask_rcnn_coco.h5\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "iZkrJyMjspoD"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 02 -- Mask RCNN Model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jVEKzGVtm_hm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from mrcnn.config import Config\n",
        "from mrcnn import utils\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import visualize\n",
        "from mrcnn.model import log"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "elExaxWfwbEe",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "DATA_DIR = './pneumonia_detection'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6HP4e8UInf_s",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if stage_2:\n",
        "  train_dicom_dir = os.path.join(DATA_DIR, 'stage_2_train_images')\n",
        "  test_dicom_dir = os.path.join(DATA_DIR, 'stage_2_test_images')\n",
        "else:\n",
        "  train_dicom_dir = os.path.join(DATA_DIR, 'stage_1_train_images')\n",
        "  test_dicom_dir = os.path.join(DATA_DIR, 'stage_1_test_images')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "OB04x04TyrFU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_dicom_fps(dicom_dir):\n",
        "    dicom_fps = glob.glob(dicom_dir+'/'+'*.dcm')\n",
        "    return list(set(dicom_fps))\n",
        "\n",
        "def parse_dataset(dicom_dir, anns): \n",
        "    image_fps = get_dicom_fps(dicom_dir)\n",
        "    image_annotations = {fp: [] for fp in image_fps}\n",
        "    for index, row in anns.iterrows(): \n",
        "        fp = os.path.join(dicom_dir, row['patientId']+'.dcm')\n",
        "        image_annotations[fp].append(row)\n",
        "    return image_fps, image_annotations "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2UwJy50E-gHK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Initialize weights using transfer learning -- COCO pre-trained weights"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BQJxQcmd03tT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The following parameters have been selected to reduce running time for demonstration purposes \n",
        "# These are not optimal \n",
        "\n",
        "class DetectorConfig(Config):\n",
        "    \"\"\"Configuration for training pneumonia detection on the RSNA pneumonia dataset.\n",
        "    Overrides values in the base Config class.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Give the configuration a recognizable name  \n",
        "    NAME = 'pneumonia'\n",
        "    \n",
        "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
        "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    \n",
        "    BACKBONE = 'resnet101'\n",
        "    NUM_CLASSES = 2  # background + 1 pneumonia classes\n",
        "    \n",
        "    IMAGE_MIN_DIM = IMG_PROC_SIZE\n",
        "    IMAGE_MAX_DIM = IMG_PROC_SIZE\n",
        "    RPN_ANCHOR_SCALES = (2, 4, 8, 16, 32)\n",
        "    TRAIN_ROIS_PER_IMAGE = 256\n",
        "    MAX_GT_INSTANCES = 1024\n",
        "    DETECTION_MAX_INSTANCES = 3\n",
        "    DETECTION_MIN_CONFIDENCE = 0.9  ## match target distribution\n",
        "    DETECTION_NMS_THRESHOLD = 0.01\n",
        "    \n",
        "    #IMAGE_SHAPE = [IMG_PROC_SIZE, IMG_PROC_SIZE, 3]\n",
        "    \n",
        "    LOSS_WEIGHTS = {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
        "      \n",
        "    LEARNING_RATE = LEARNING_RATE\n",
        "\n",
        "    STEPS_PER_EPOCH = 1600\n",
        "    \n",
        "config = DetectorConfig()\n",
        "config.display()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "kP7BadhczSrl",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DetectorDataset(utils.Dataset):\n",
        "    \"\"\"Dataset class for training pneumonia detection on the RSNA pneumonia dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, image_fps, image_annotations, orig_height, orig_width):\n",
        "        super().__init__(self)\n",
        "        \n",
        "        # Add classes\n",
        "        self.add_class('pneumonia', 1, 'Lung Opacity')\n",
        "   \n",
        "        # add images \n",
        "        for i, fp in enumerate(image_fps):\n",
        "            annotations = image_annotations[fp]\n",
        "            self.add_image('pneumonia', image_id=i, path=fp, \n",
        "                           annotations=annotations, orig_height=orig_height, orig_width=orig_width)\n",
        "            \n",
        "    def image_reference(self, image_id):\n",
        "        info = self.image_info[image_id]\n",
        "        return info['path']\n",
        "\n",
        "    def load_image(self, image_id):\n",
        "        info = self.image_info[image_id]\n",
        "        fp = info['path']\n",
        "        ds = pydicom.read_file(fp)\n",
        "        image = ds.pixel_array\n",
        "        # If grayscale. Convert to RGB for consistency.\n",
        "        if len(image.shape) != 3 or image.shape[2] != 3:\n",
        "            image = np.stack((image,) * 3, -1)\n",
        "        return image\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        info = self.image_info[image_id]\n",
        "        annotations = info['annotations']\n",
        "        count = len(annotations)\n",
        "        if count == 0:\n",
        "            mask = np.zeros((info['orig_height'], info['orig_width'], 1), dtype=np.uint8)\n",
        "            class_ids = np.zeros((1,), dtype=np.int32)\n",
        "        else:\n",
        "            mask = np.zeros((info['orig_height'], info['orig_width'], count), dtype=np.uint8)\n",
        "            class_ids = np.zeros((count,), dtype=np.int32)\n",
        "            for i, a in enumerate(annotations):\n",
        "                if a['Target'] == 1:\n",
        "                    x = int(a['x'])\n",
        "                    y = int(a['y'])\n",
        "                    w = int(a['width'])\n",
        "                    h = int(a['height'])\n",
        "                    mask_instance = mask[:, :, i].copy()\n",
        "                    cv2.rectangle(mask_instance, (x, y), (x+w, y+h), 255, -1)\n",
        "                    mask[:, :, i] = mask_instance\n",
        "                    class_ids[i] = 1\n",
        "        return mask.astype(np.bool), class_ids.astype(np.int32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "F_Ro1zEJ3AWw",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# training dataset\n",
        "if stage_2:\n",
        "  anns = pd.read_csv(os.path.join(DATA_DIR, 'stage_2_train_labels.csv'))\n",
        "else:\n",
        "  anns = pd.read_csv(os.path.join(DATA_DIR, 'stage_1_train_labels.csv'))\n",
        "anns.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YUfXGRxV3MYv",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_fps, image_annotations = parse_dataset(train_dicom_dir, anns=anns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Au48ErSo3QHg",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ds = pydicom.read_file(image_fps[0]) # read dicom image from filepath \n",
        "image = ds.pixel_array # get image array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9octjulN2luG",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# show dicom fields \n",
        "preview = False\n",
        "if preview:\n",
        "  ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "C_ZGkV8b7O8M",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "######################################################################\n",
        "# Modify this line to use more or fewer images for training/validation. \n",
        "# To use all images, do: image_fps_list = list(image_fps)\n",
        "image_fps_list = list(image_fps) \n",
        "#####################################################################\n",
        "\n",
        "# split dataset into training vs. validation dataset \n",
        "# split ratio is set to 0.9 vs. 0.1 (train vs. validation, respectively)\n",
        "sorted(image_fps_list)\n",
        "random.seed(42)\n",
        "random.shuffle(image_fps_list)\n",
        "\n",
        "validation_split = 0.1\n",
        "split_index = int((1 - validation_split) * len(image_fps_list))\n",
        "\n",
        "image_fps_train = image_fps_list[:split_index]\n",
        "image_fps_val = image_fps_list[split_index:]\n",
        "\n",
        "print(len(image_fps_train), len(image_fps_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wkF-Nc-g7Xph",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# prepare the training dataset\n",
        "dataset_train = DetectorDataset(image_fps_train, image_annotations, ORIG_SIZE, ORIG_SIZE)\n",
        "dataset_train.prepare()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "nzcHhM1c8iYL",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Show annotation(s) for a DICOM image \n",
        "test_fp = random.choice(image_fps_train)\n",
        "image_annotations[test_fp]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3gZz5bGc8oKq",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# prepare the validation dataset\n",
        "dataset_val = DetectorDataset(image_fps_val, image_annotations, ORIG_SIZE, ORIG_SIZE)\n",
        "dataset_val.prepare()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "p4wJVzv9cGG2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load and display random samples and their bounding boxes\n",
        "# Suggestion: Run this a few times to see different examples. \n",
        "\n",
        "summary_plot = False\n",
        "\n",
        "if summary_plot:\n",
        "    image_id = random.choice(dataset_train.image_ids)\n",
        "    image_fp = dataset_train.image_reference(image_id)\n",
        "    image = dataset_train.load_image(image_id)\n",
        "    mask, class_ids = dataset_train.load_mask(image_id)\n",
        "\n",
        "    print(image.shape)\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(image[:, :, 0], cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    masked = np.zeros(image.shape[:2])\n",
        "    for i in range(mask.shape[2]):\n",
        "        masked += image[:, :, 0] * mask[:, :, i]\n",
        "    plt.imshow(masked, cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "    print(image_fp)\n",
        "    print(class_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xBPocw6R0E78",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ROOT_DIR = './pneumonia_detection/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2tmW3hBqMbGN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = modellib.MaskRCNN(mode='training', \n",
        "                          config=config, \n",
        "                          model_dir=ROOT_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G_xNrRB6c9C1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if use_transfer_learn:\n",
        "  # Exclude the last layers because they require a matching\n",
        "  # number of classes\n",
        "  try:\n",
        "    model.load_weights(COCO_WEIGHTS_PATH, by_name=True, exclude=[\"mrcnn_class_logits\", \n",
        "                                                               \"mrcnn_bbox_fc\",\n",
        "                                                               \"mrcnn_bbox\", \n",
        "                                                               \"mrcnn_mask\"])\n",
        "    print ('Loaded trained weights using COCO dataset ...')\n",
        "  except:\n",
        "    print ('Failed to load trained weights using COCO dataset ...')\n",
        "elif load_weights and not use_transfer_learn:\n",
        "  try:\n",
        "    model.load_weights('./pneumonia_detection/mask_rcnn_pneumonia.h5', by_name=True)\n",
        "    print ('Loaded weights from {}'.format('./pneumonia_detection/mask_rcnn_pneumonia.h5'))\n",
        "  except:\n",
        "    model.load_weights('./mask_rcnn_pneumonia.h5', by_name=True)\n",
        "    print ('Loaded weights from {}'.format('./mask_rcnn_pneumonia.h5'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hDvD2arq8rrS",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Image augmentation \n",
        "augmentation_1 = iaa.SomeOf((0, 1), [\n",
        "    iaa.Fliplr(0.5),\n",
        "    iaa.Affine(scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
        "               translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
        "               rotate=(-25, 25),\n",
        "               shear=(-8, 8)),\n",
        "               iaa.Multiply((0.9, 1.1))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f1vLHrpcdjVJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Image augmentation (light but constant)\n",
        "augmentation_2 = iaa.Sequential([\n",
        "    iaa.OneOf([ ## geometric transform\n",
        "        iaa.Affine(\n",
        "            scale={\"x\": (0.98, 1.02), \"y\": (0.98, 1.04)},\n",
        "            translate_percent={\"x\": (-0.02, 0.02), \"y\": (-0.04, 0.04)},\n",
        "            rotate=(-2, 2),\n",
        "            shear=(-1, 1),\n",
        "        ),\n",
        "        iaa.PiecewiseAffine(scale=(0.001, 0.025)),\n",
        "    ]),\n",
        "    iaa.OneOf([ ## brightness or contrast\n",
        "        iaa.Multiply((0.9, 1.1)),\n",
        "        iaa.ContrastNormalization((0.9, 1.1)),\n",
        "    ]),\n",
        "    iaa.OneOf([ ## blur or sharpen\n",
        "        iaa.GaussianBlur(sigma=(0.0, 0.1)),\n",
        "        iaa.Sharpen(alpha=(0.0, 0.1)),\n",
        "    ]),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "puVfufaOd3h1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if use_augmentation == 2:\n",
        "  augmentation = augmentation_2\n",
        "  print ('Using augmentation mode: 2')\n",
        "elif use_augmentation == 1:\n",
        "  augmentation = augmentation_1\n",
        "  print ('Using augmentation mode: 1')\n",
        "else:\n",
        "  augmentation = None\n",
        "  print ('Using augmentation mode: None')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PQ7tKzkAd0-C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train Mask-RCNN Model \n",
        "import warnings \n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bJpBP-THmi7t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train top layer using COCO weights or pre-trained weights"
      ]
    },
    {
      "metadata": {
        "id": "QY_ti8kKed1S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "command = ['rm -r {}/pneumonia2018*'.format(ROOT_DIR)]\n",
        "execute_in_shell(command = command, verbose = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9EhRV6M8dwhF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "## train heads with higher lr to speedup the learning\n",
        "if use_transfer_learn or fine_tune:\n",
        "  layers = 'heads'\n",
        "else:\n",
        "  layers = 'all'\n",
        "  \n",
        "model.train(dataset_train, dataset_val,\n",
        "            learning_rate=LEARNING_RATE*2,\n",
        "            epochs=2,\n",
        "            layers=layers,\n",
        "            augmentation=None)  ## no need to augment yet\n",
        "history = model.keras_model.history.history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ibTtdmw4qs0k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Retrain all layers of the MRCNN network"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "euqq2r4KPW4_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Train Mask-RCNN Model \n",
        "import warnings \n",
        "warnings.filterwarnings(\"ignore\")\n",
        "model.train(dataset_train, dataset_val, \n",
        "            learning_rate=LEARNING_RATE, \n",
        "            epochs=NUM_EPOCHS, \n",
        "            layers='all',\n",
        "            augmentation=augmentation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QlN37XX13Ixl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "new_history = model.keras_model.history.history\n",
        "for k in new_history: history[k] = history[k] + new_history[k]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Jcxgb4Tq7AZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test predictions using the same image as above"
      ]
    },
    {
      "metadata": {
        "id": "Z5-q8xL1dmbB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if augmentation != None:\n",
        "  imggrid = augmentation.draw_grid(image[:, :], cols=2, rows=2)\n",
        "  plt.figure(figsize=(30, 12))\n",
        "  _ = plt.imshow(imggrid[:, :, 0], cmap='gray')\n",
        "else:\n",
        "  _ = plt.imshow(image, cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y_UcCOjZ4YRJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Summarize training performance"
      ]
    },
    {
      "metadata": {
        "id": "T6MZBeGNe6dR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = range(1,len(next(iter(history.values())))+1)\n",
        "pd.DataFrame(history, index=epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ugJ4JmZtfCdd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(17,5))\n",
        "\n",
        "plt.subplot(131)\n",
        "plt.plot(epochs, history[\"loss\"], label=\"Train loss\")\n",
        "plt.plot(epochs, history[\"val_loss\"], label=\"Valid loss\")\n",
        "plt.legend()\n",
        "plt.subplot(132)\n",
        "plt.plot(epochs, history[\"mrcnn_class_loss\"], label=\"Train class ce\")\n",
        "plt.plot(epochs, history[\"val_mrcnn_class_loss\"], label=\"Valid class ce\")\n",
        "plt.legend()\n",
        "plt.subplot(133)\n",
        "plt.plot(epochs, history[\"mrcnn_bbox_loss\"], label=\"Train box loss\")\n",
        "plt.plot(epochs, history[\"val_mrcnn_bbox_loss\"], label=\"Valid box loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XPXSYpCBrHzJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Output the best epoch"
      ]
    },
    {
      "metadata": {
        "id": "1jfc24-IfLrV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save_last = True\n",
        "if save_last:\n",
        "  best_epoch = len(epochs)-1\n",
        "  print(\"Best Epoch:\", best_epoch+1)\n",
        "else:\n",
        "  best_epoch = np.argmin(history[\"val_loss\"])\n",
        "  print(\"Best Epoch:\", best_epoch + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3SqkrxlbrQRB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Select best performing trained model for saving weights"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8Lr-K5ib9GYa",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dir_names = next(os.walk(model.model_dir))[1]\n",
        "key = config.NAME.lower()\n",
        "dir_names = filter(lambda f: f.startswith(key), dir_names)\n",
        "dir_names = sorted(dir_names)\n",
        "\n",
        "if not dir_names:\n",
        "    import errno\n",
        "    raise FileNotFoundError(\n",
        "        errno.ENOENT,\n",
        "        \"Could not find model directory under {}\".format(self.model_dir))\n",
        "    \n",
        "fps = []\n",
        "# Pick last directory\n",
        "for d in dir_names: \n",
        "    dir_name = os.path.join(model.model_dir, d)\n",
        "    # Find the last checkpoint\n",
        "    checkpoints = next(os.walk(dir_name))[2]\n",
        "    checkpoints = filter(lambda f: f.startswith(\"mask_rcnn\"), checkpoints)\n",
        "    checkpoints = sorted(checkpoints)\n",
        "    if not checkpoints:\n",
        "        print('No weight files in {}'.format(dir_name))\n",
        "    else:\n",
        "        checkpoint = os.path.join(dir_name, checkpoints[best_epoch])\n",
        "        fps.append(checkpoint)\n",
        "\n",
        "model_path = sorted(fps)[-1]\n",
        "print('Found model {}'.format(model_path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ko1GvcSuvZgS",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "command = ['mv {} {}/{}_mask_rcnn_pneumonia.h5'.format(model_path, ROOT_DIR, IMG_PROC_SIZE),\n",
        "           'rm -r {}/pneumonia2018*'.format(ROOT_DIR),\n",
        "           'ls {}'.format(ROOT_DIR)]\n",
        "execute_in_shell(command = command, verbose = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GkEekraQmrl3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! ls ./pneumonia_detection/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zDcDjM9UrY0Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Upload weights file to Google drive"
      ]
    },
    {
      "metadata": {
        "id": "rcrEJqU2v2M1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if colab_mode:\n",
        "    drive = cloud_authenticate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "S4eec6uiiA2G",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_dir = '{}'.format(ROOT_DIR)\n",
        "checkpoint_file = '{}_mask_rcnn_pneumonia.h5'.format(IMG_PROC_SIZE)\n",
        "\n",
        "upload = False\n",
        "if colab_mode:\n",
        "    upload = True\n",
        "    googledrive_save(file_name = checkpoint_file,\n",
        "               file_dir = file_dir,\n",
        "               upload = upload)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9qTd18r629pp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "drive_name = 'googledrive'\n",
        "cloud_folder = 'Pneumonia_detection'\n",
        "local_folder = '{}/{}_mask_rcnn_pneumonia.h5'.format(ROOT_DIR, IMG_PROC_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yF_l6AX029pv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if not colab_mode:\n",
        "    rClone_upload(drive_name = drive_name,\n",
        "                  local_folder = local_folder,\n",
        "                  cloud_folder = cloud_folder,\n",
        "                  verbose = True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rc_Beo_OsoXj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create a function to generate predictions using MRCNN"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zPeq8EnpcxLp",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class InferenceConfig(DetectorConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "inference_config = InferenceConfig()\n",
        "\n",
        "# Recreate the model in inference mode\n",
        "model = modellib.MaskRCNN(mode='inference', \n",
        "                          config=inference_config,\n",
        "                          model_dir=ROOT_DIR)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zQH3mACtzY5L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if gen_preds:\n",
        "  # Exclude the last layers because they require a matching\n",
        "  # number of classes\n",
        "  try:\n",
        "    model_path = '{}/{}_mmask_rcnn_pneumonia.h5'.format(ROOT_DIR, IMG_PROC_SIZE)\n",
        "\n",
        "    # Load trained weights (fill in path to trained weights here)\n",
        "    assert model_path != \"\", \"Provide path to trained weights\"\n",
        "    model.load_weights(model_path, by_name=True)\n",
        "    print(\"Loading weights from \", model_path)\n",
        "  except:\n",
        "      try:\n",
        "        model.load_weights('{}/mask_rcnn_pneumonia.h5'.format(ROOT_DIR), by_name=True)\n",
        "        print ('Loaded weights from {}'.format('{}/mask_rcnn_pneumonia.h5'.format(ROOT_DIR)))\n",
        "      except:\n",
        "        model.load_weights('./mask_rcnn_pneumonia.h5', by_name=True)\n",
        "        print ('Loaded weights from {}'.format('./mask_rcnn_pneumonia.h5'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nzssPUUIsyVW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Set color for predictions class"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "w7jVb8p_3Bqg",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_colors_for_class_ids(class_ids):\n",
        "    colors = []\n",
        "    for class_id in class_ids:\n",
        "        if class_id == 1:\n",
        "            colors.append((.941, .204, .204))\n",
        "    return colors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4TAB9jN-rklC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Display a few example of ground truth vs. predictions on the validation dataset "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VUQzduNY3G8p",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset = dataset_val\n",
        "fig = plt.figure(figsize=(10, 30))\n",
        "\n",
        "for i in range(4):\n",
        "\n",
        "    image_id = random.choice(dataset.image_ids)\n",
        "    \n",
        "    original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "        modellib.load_image_gt(dataset_val, inference_config, \n",
        "                               image_id, use_mini_mask=False)\n",
        "        \n",
        "    plt.subplot(6, 2, 2*i + 1)\n",
        "    visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "                                dataset.class_names,\n",
        "                                colors=get_colors_for_class_ids(gt_class_id), ax=fig.axes[-1])\n",
        "    \n",
        "    plt.subplot(6, 2, 2*i + 2)\n",
        "    results = model.detect([original_image]) #, verbose=1)\n",
        "    r = results[0]\n",
        "    visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "                                dataset.class_names, r['scores'], \n",
        "                                colors=get_colors_for_class_ids(r['class_ids']), ax=fig.axes[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1qpGvE4trwPY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Get filenames of test dataset DICOM images"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-4u3EGRv3L1L",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if gen_preds:\n",
        "  test_image_fps = get_dicom_fps(test_dicom_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DaYmWSKer5Zv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Make predictions on test images and write out submission file"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "CyL8HfdW3RZM",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict(image_fps, filepath='sample_submission.csv', min_conf=0.98): \n",
        "    \n",
        "    # assume square image\n",
        "    resize_factor = ORIG_SIZE / config.IMAGE_SHAPE[0]\n",
        "    \n",
        "    with open(filepath, 'w') as file:\n",
        "      file.write(\"{},{}\\n\".format(\"patientId\",\t\"PredictionString\"))\n",
        "      for image_id in tqdm(image_fps): \n",
        "        ds = pydicom.read_file(image_id)\n",
        "        image = ds.pixel_array\n",
        "          \n",
        "        # If grayscale. Convert to RGB for consistency.\n",
        "        if len(image.shape) != 3 or image.shape[2] != 3:\n",
        "            image = np.stack((image,) * 3, -1)\n",
        "        image, window, scale, padding, crop = utils.resize_image(image,\n",
        "                                                                 min_dim=config.IMAGE_MIN_DIM,\n",
        "                min_scale=config.IMAGE_MIN_SCALE,\n",
        "                max_dim=config.IMAGE_MAX_DIM,\n",
        "                mode=config.IMAGE_RESIZE_MODE)\n",
        "            \n",
        "        patient_id = os.path.splitext(os.path.basename(image_id))[0]\n",
        "\n",
        "        results = model.detect([image])\n",
        "        r = results[0]\n",
        "\n",
        "        out_str = \"\"\n",
        "        out_str += patient_id \n",
        "        assert( len(r['rois']) == len(r['class_ids']) == len(r['scores']) )\n",
        "        if len(r['rois']) == 0: \n",
        "            pass\n",
        "        else: \n",
        "            num_instances = len(r['rois'])\n",
        "            out_str += \",\"\n",
        "            for i in range(num_instances): \n",
        "                if r['scores'][i] > min_conf: \n",
        "                    out_str += ' '\n",
        "                    out_str += str(round(r['scores'][i], 2))\n",
        "                    out_str += ' '\n",
        "\n",
        "                    # x1, y1, width, height \n",
        "                    x1 = r['rois'][i][1]\n",
        "                    y1 = r['rois'][i][0]\n",
        "                    width = r['rois'][i][3] - x1 \n",
        "                    height = r['rois'][i][2] - y1 \n",
        "                    bboxes_str = \"{} {} {} {}\".format(x1*resize_factor, y1*resize_factor, \\\n",
        "                                                      width*resize_factor, height*resize_factor)    \n",
        "                    out_str += bboxes_str\n",
        "\n",
        "        file.write(out_str+\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4yrGj0S1sIef",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Generate predictions"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WipC8GxF3UJ2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if gen_preds:\n",
        "  sample_submission_fp = 'MRCNN_submission.csv'\n",
        "  predict(test_image_fps, \n",
        "          filepath=sample_submission_fp, \n",
        "          min_conf=0.98)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ErHoKsgb3ZMC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if gen_preds:\n",
        "  output = pd.read_csv(sample_submission_fp)\n",
        "  print (output.head(10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lsLzJSdv4ygK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Save submission files to Google Drive"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Rg_UWwods9py",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_dir = '{}'.format('./')\n",
        "if gen_preds and colab_mode:\n",
        "  googledrive_save(file_name = sample_submission_fp,\n",
        "             file_dir = file_dir,\n",
        "             upload = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6N9ERmX2sbPn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Display a few test image predictions"
      ]
    },
    {
      "metadata": {
        "id": "Su-HievAfz8E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def visualize(): \n",
        "    image_id = random.choice(test_image_fps)\n",
        "    ds = pydicom.read_file(image_id)\n",
        "    \n",
        "    # original image \n",
        "    image = ds.pixel_array\n",
        "    \n",
        "    # assume square image \n",
        "    resize_factor = ORIG_SIZE / config.IMAGE_SHAPE[0]\n",
        "    \n",
        "    # If grayscale. Convert to RGB for consistency.\n",
        "    if len(image.shape) != 3 or image.shape[2] != 3:\n",
        "        image = np.stack((image,) * 3, -1) \n",
        "    resized_image, window, scale, padding, crop = utils.resize_image(\n",
        "        image,\n",
        "        min_dim=config.IMAGE_MIN_DIM,\n",
        "        min_scale=config.IMAGE_MIN_SCALE,\n",
        "        max_dim=config.IMAGE_MAX_DIM,\n",
        "        mode=config.IMAGE_RESIZE_MODE)\n",
        "\n",
        "    patient_id = os.path.splitext(os.path.basename(image_id))[0]\n",
        "    print(patient_id)\n",
        "\n",
        "    results = model.detect([resized_image])\n",
        "    r = results[0]\n",
        "    for bbox in r['rois']: \n",
        "        print(bbox)\n",
        "        x1 = int(bbox[1] * resize_factor)\n",
        "        y1 = int(bbox[0] * resize_factor)\n",
        "        x2 = int(bbox[3] * resize_factor)\n",
        "        y2 = int(bbox[2]  * resize_factor)\n",
        "        cv2.rectangle(image, (x1,y1), (x2,y2), (77, 255, 9), 3, 1)\n",
        "        width = x2 - x1 \n",
        "        height = y2 - y1 \n",
        "        print(\"x {} y {} h {} w {}\".format(x1, y1, width, height))\n",
        "    plt.figure() \n",
        "    plt.imshow(image, cmap=plt.cm.gist_gray)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WgF43OjjsVTj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if gen_preds:\n",
        "  visualize()\n",
        "  visualize()\n",
        "  visualize()\n",
        "  visualize()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LLytabW93d-A",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if gen_preds and download_submission and colab_mode:\n",
        "  from google.colab import files\n",
        "  files.download(sample_submission_fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WsPxfqxb6_Wd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}