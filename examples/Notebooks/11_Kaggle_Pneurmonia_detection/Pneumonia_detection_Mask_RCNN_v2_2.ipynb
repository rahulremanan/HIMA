{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pneumonia_detection_Mask_RCNN_v2_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "2I3ZIYZ9lYSu"
      },
      "cell_type": "markdown",
      "source": [
        "# [Radiological Society of North America -- Pneumonia Detection Challenge](https://www.kaggle.com/c/rsna-pneumonia-detection-challenge)\n",
        "\n",
        "Pneumonia accounts for over 15% of all deaths of children under 5 years old internationally. In 2015, 920,000 children under the age of 5 died from the disease. In the United States, pneumonia accounts for over 500,000 visits to emergency departments [1](www.cdc.gov/nchs/data/nhamcs/web_tables/2015_ed_web_tables.pdf) and over 50,000 deaths in 2015 [2](http://www.cdc.gov/nchs/data/nvsr/nvsr66/nvsr66_06_tables.pdf), keeping the ailment on the list of top 10 causes of death in the country.\n",
        "\n",
        "While common, accurately diagnosing pneumonia is a tall order. It requires review of a chest radiograph (CXR) by highly trained specialists and confirmation through clinical history, vital signs and laboratory exams. Pneumonia usually manifests as an area or areas of increased opacity [3](https://www.ncbi.nlm.nih.gov/pubmed/30036297) on CXR. However, the diagnosis of pneumonia on CXR is complicated because of a number of other conditions in the lungs such as fluid overload (pulmonary edema), bleeding, volume loss (atelectasis or collapse), lung cancer, or post-radiation or surgical changes. Outside of the lungs, fluid in the pleural space (pleural effusion) also appears as increased opacity on CXR. When available, comparison of CXRs of the patient taken at different time points and correlation with clinical symptoms and history are helpful in making the diagnosis.\n",
        "\n",
        "CXRs are the most commonly performed diagnostic imaging study. A number of factors such as positioning of the patient and depth of inspiration can alter the appearance of the CXR [4](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3632825/), complicating interpretation further. In addition, clinicians are faced with reading high volumes of images every shift.\n",
        "\n",
        "[The images for the Kaggle-RSNA challenge are from the NIH chest x-ray dataset](https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/36938765345). National Institutes of Health Clinical Center has provided this Chest X-Ray dataset publicly.[5](http://openaccess.thecvf.com/content_cvpr_2017/papers/Wang_ChestX-ray8_Hospital-Scale_Chest_CVPR_2017_paper.pdf) There has already been excellent attempts at developing an end-to-end deep-learning models, using this dataset, that classifies chest x-rays with expert human level accuracy.[6](https://stanfordmlgroup.github.io/projects/chexnet/)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "x0i215yRg6Uv",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "setup = False\n",
        "download_data = False\n",
        "update_weights = True\n",
        "\n",
        "gen_preds = True\n",
        "download_submission = True\n",
        "fetch_raw_data = False\n",
        "upload_data = False\n",
        "\n",
        "colab_mode = True\n",
        "\n",
        "use_transfer_learn = False\n",
        "fine_tune = False\n",
        "load_weights =True\n",
        "\n",
        "stage_2 = True\n",
        "\n",
        "use_augmentation = 2 # 0, 1 or 2\n",
        "\n",
        "LEARNING_RATE = 1e-5\n",
        "NUM_EPOCHS = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "K5VOhfCT6wes",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Original DICOM image size: 1024 x 1024\n",
        "ORIG_SIZE = 1024\n",
        "IMG_PROC_SIZE = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KQExkuZs29ez",
        "colab_type": "code",
        "outputId": "1ebfd465-f5e1-4d85-ccce-8e287908d48f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "hello = tf.constant('Hello, TensorFlow!')\n",
        "sess = tf.Session()\n",
        "print(tf.__version__)\n",
        "print(sess.run(hello))\n",
        "\n",
        "print(tf.GIT_VERSION, tf.VERSION)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "b'Hello, TensorFlow!'\n",
            "b'v1.13.1-2-g09e3b09e69' 1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PCQySLbGpEP6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os \n",
        "import sys\n",
        "import subprocess"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fAKjuZb-fnYt",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def execute_in_shell(command=None, \n",
        "                     verbose = False):\n",
        "    \"\"\" \n",
        "        command -- keyword argument, takes a list as input\n",
        "        verbsoe -- keyword argument, takes a boolean value as input\n",
        "    \n",
        "        This is a function that executes shell scripts from within python.\n",
        "        \n",
        "        Keyword argument 'command', should be a list of shell commands.\n",
        "        Keyword argument 'verbose', should be a boolean value to set verbose level.\n",
        "        \n",
        "        Example usage: execute_in_shell(command = ['ls ./some/folder/',\n",
        "                                                    ls ./some/folder/  -1 | wc -l'],\n",
        "                                        verbose = True ) \n",
        "                                        \n",
        "        This command returns dictionary with elements: Output and Error.\n",
        "        \n",
        "        Output records the console output,\n",
        "        Error records the console error messages.\n",
        "                                        \n",
        "    \"\"\"\n",
        "    error = []\n",
        "    output = []\n",
        "    \n",
        "    if isinstance(command, list):\n",
        "        for i in range(len(command)):\n",
        "            try:\n",
        "                process = subprocess.Popen(command[i], shell=True, stdout=subprocess.PIPE)\n",
        "                process.wait()\n",
        "                out, err = process.communicate()\n",
        "                error.append(err)\n",
        "                output.append(out)\n",
        "                if verbose:\n",
        "                    print ('Success running shell command: {}'.format(command[i]))\n",
        "            except Exception as e:\n",
        "                print ('Failed running shell command: {}'.format(command[i]))\n",
        "                if verbose:\n",
        "                    print(type(e))\n",
        "                    print(e.args)\n",
        "                    print(e)\n",
        "                \n",
        "    else:\n",
        "        print ('The argument command takes a list input ...')\n",
        "    return {'Output': output, 'Error': error }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LY1WnphPofDT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "command = ['pip3 install -q pydicom kaggle PyDrive  cython >/dev/null 2>&1',\n",
        "           'git clone https://github.com/rahulremanan/Mask_RCNN >/dev/null 2>&1',\n",
        "           'git clone https://github.com/rahulremanan/cocoapi >/dev/null 2>&1',\n",
        "           'cd ./cocoapi/PythonAPI/; make >/dev/null 2>&1; make install >/dev/null 2>&1; python3 setup.py install >/dev/null 2>&1; python3 setup.py build_ext --inplace >/dev/null 2>&1',\n",
        "           'cd ./Mask_RCNN/; pip3 install -r requirements.txt >/dev/null 2>&1; python3 setup.py install >/dev/null 2>&1',\n",
        "           'mkdir /content/',\n",
        "           'mkdir /content/.kaggle/',\n",
        "           'mkdir ./pneumonia_detection/']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Z2HB8eMagjjT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if setup and colab_mode:\n",
        "  execute_in_shell(command = command, \n",
        "                   verbose = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "w1krniYdm50e",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pydicom\n",
        "from imgaug import augmenters as iaa\n",
        "from tqdm import tqdm\n",
        "import pandas as pd \n",
        "import glob "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "crGcqEbP29gH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if colab_mode:\n",
        "    from pydrive.auth import GoogleAuth\n",
        "    from pydrive.drive import GoogleDrive\n",
        "    from google.colab import auth\n",
        "    from oauth2client.client import GoogleCredentials\n",
        "    from googleapiclient.http import MediaIoBaseDownload"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2tL_4kbOrbCU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import io\n",
        "import glob\n",
        "import fnmatch\n",
        "import random\n",
        "\n",
        "from multiprocessing import Process"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "4thnyYZwrj38"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 01 -- Fetching and processing data"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "wWclH9mzhUnK"
      },
      "cell_type": "markdown",
      "source": [
        "### Setting up Kaggle access for Google Colab\n",
        "\n",
        "1.  Click on the right top corner of Kaggle website, where it displays your profile picture\n",
        "2.  Go to My Accounts\n",
        "3. Under API, click on Create new API token\n",
        "4. Upload the kaggle.json file to Google Colab environment or to the Jupyter notebook\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "dXEQwtTLklSz"
      },
      "cell_type": "markdown",
      "source": [
        "#### Upload kaggle.json file"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "baYztOythLM4",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if setup and fetch_raw_data and colab_mode:\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "tRiLz1Zaks5k"
      },
      "cell_type": "markdown",
      "source": [
        "### Download RSNA pneumonia detection dataset using Kaggle API"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "DvdoRWwNfGkK",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "command = ['mv ./*.json /root/.kaggle/',\n",
        "           'cp /root/.kaggle/kaggle.json ~/.kaggle/kaggle.json',\n",
        "           'chmod ~/.kaggle/kaggle.json',\n",
        "           'kaggle competitions download -c rsna-pneumonia-detection-challenge',\n",
        "           'mv /content/stage_1_* ./',\n",
        "           'mv /content/stage_2_* ./']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Y-5TI7oLhWFj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if fetch_raw_data:\n",
        "  execute_in_shell(command = command, verbose = True)\n",
        "  filename = \"/content/.kaggle/kaggle.json\"\n",
        "  os.chmod(filename, 600)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "G_Cs3gPgr4ra"
      },
      "cell_type": "markdown",
      "source": [
        "### Setup Google Drive as Colab object storage"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "90rIo8vqpmqU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cloud_authenticate():\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  print (\"Sucessfully authenticated to access Google Drive ...\")\n",
        "  return drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FBuC3cnN0wNn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Authenticate Google Drive in CoLab mode"
      ]
    },
    {
      "metadata": {
        "id": "jfC1o7az0nOJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74719591-cc61-4b84-d37e-05404b2d0237"
      },
      "cell_type": "code",
      "source": [
        "if colab_mode:\n",
        "    drive = cloud_authenticate()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sucessfully authenticated to access Google Drive ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ax05uMCo02Nb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Google Drive fetch and save for CoLab"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9x-yY5XCpp_d",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def googledrive_fetch(file_name = None, \n",
        "                fetch=True, \n",
        "                fetch_by_id = False,\n",
        "                latest = True,\n",
        "                file_id = None,\n",
        "                multi_file = False):\n",
        "  \n",
        "  \"\"\"\n",
        "    A function that fetches files from Google Drive.\n",
        "    \n",
        "    The function takes five keyword arguments:\n",
        "      file_name -- Passes the file name string\n",
        "      fetch -- Specify if a file name should be downloaded\n",
        "      fetch_by_id -- Specify a file to be downloaded by file id\n",
        "      multi_file -- Download all the files with the same file name from Google Drive\n",
        "  \"\"\"\n",
        "  \n",
        "  query = 'title='+\"'\"+file_name+\"'\"\n",
        "  try:\n",
        "    file_list=drive.ListFile({'q': \"{}\".format(query)}).GetList()\n",
        "  except:\n",
        "    return (\"Error finding file with {}\".format(query))\n",
        "  \n",
        "  if len(file_list) >1:\n",
        "    print (\"A total of {} files with the same file name found ...\".format(len(file_list)))\n",
        "    for f in file_list:\n",
        "      title = f['title']\n",
        "      id = f.metadata.get('id')\n",
        "      print (\"Found: {} file, with file id: {}\".format(title, id))\n",
        "    \n",
        "    if multi_file:\n",
        "      print (\"Downloading {} files with file name {}\".format(len(file_list), title))\n",
        "      print (\"Staring download ...\")\n",
        "    elif latest:\n",
        "      print (\"Downloading the most recent {} file ...\".format(title))\n",
        "    elif file_id == None:\n",
        "      print (\"Set keyword argument fetch_by_id = True and specify id using keyword argument file_id = 'id' to download a specific file ...\")\n",
        "      print (\"--OR--\")\n",
        "      print (\"Set keyword argument multi_file = True to automatically download all the files ...\")\n",
        "      return None\n",
        "    else:\n",
        "      print (\"Starting download ...\")\n",
        "    \n",
        "  n = 0\n",
        "  \n",
        "  if latest:\n",
        "    try:\n",
        "      title = file_list[0]['title']\n",
        "    except:\n",
        "      return (\"Error finding file with {}\".format(query))\n",
        "    latest_file_id = file_list[0].metadata.get('id')\n",
        "    print (\"Found most recent version of: {} file with file id: {} ...\".format(title, latest_file_id))    \n",
        "  \n",
        "  for f in file_list:\n",
        "      if fetch and multi_file and n>0:\n",
        "        save_path = os.path.join('./'+str(n)+'_'+file_name)\n",
        "      else:\n",
        "        save_path = os.path.join('./'+file_name)     \n",
        "      \n",
        "      title = f['title']\n",
        "      \n",
        "      if fetch_by_id and file_id !=None:\n",
        "        id = file_id\n",
        "      elif latest:\n",
        "        id = latest_file_id\n",
        "      elif fetch_by_id and file_id == None:\n",
        "        print ('Please specify the file id for downloading using the file_id argument ...')\n",
        "      else:\n",
        "        id = f.metadata.get('id')\n",
        "      \n",
        "      print (\"Downloading {} file, with file id: {} ...\".format(title, id))\n",
        "      \n",
        "      if fetch or fetch_by_id or latest:\n",
        "        local_file = io.FileIO(save_path, mode='wb')\n",
        "        try:\n",
        "          request = drive.auth.service.files().get_media(fileId=id)\n",
        "          downloader = MediaIoBaseDownload(local_file, request, chunksize=2048*102400)\n",
        "\n",
        "          done = False\n",
        "\n",
        "          while done is False:\n",
        "              status, done = downloader.next_chunk()\n",
        "        except:\n",
        "          return 'Downloading failed ...'\n",
        "        \n",
        "        local_file.close()\n",
        "        print (\"Successfully downloaded the file: {} to: {} ...\".format(file_name, save_path))\n",
        "      \n",
        "      if fetch_by_id and file_id !=None:\n",
        "        return None\n",
        "      elif latest:\n",
        "        return None\n",
        "      elif n >= 0:\n",
        "        print (\"Downloaded {} of {} files ...\".format(n+1, len(file_list)))\n",
        "      else:\n",
        "        print (\"Download failed ...\")\n",
        "      \n",
        "      n +=1\n",
        "  \n",
        "  return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "MoCWoNwXps3D",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def googledrive_save(file_name = None, \n",
        "               file_dir = None, \n",
        "               upload = False,\n",
        "               prefix = None):\n",
        "  if upload == True and file_name != None and file_dir !=None:\n",
        "    try:\n",
        "      if prefix != None:\n",
        "        file = drive.CreateFile({'title': str(prefix) + str(file_name) })\n",
        "      else:\n",
        "        file = drive.CreateFile({'title': str(file_name) })\n",
        "      file.SetContentFile(os.path.join(file_dir + str(file_name)))\n",
        "      file.Upload()\n",
        "      print (str(file_name) + \" successfully uploaded to Google drive ...\")\n",
        "    except:\n",
        "      print (\"Failed to save :\" + str(file_name) + \" to Google drive ...\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d93s0_Cv29h2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Setup Google Drive as object storage using rClone"
      ]
    },
    {
      "metadata": {
        "id": "ho6XwH2P29h6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rClone_upload(drive_name = None,\n",
        "                  local_folder = None,\n",
        "                  cloud_folder = None,\n",
        "                  verbose = False):\n",
        "    command = ['rclone copy {} {}:{}'.format(local_folder,\n",
        "                                             drive_name, \n",
        "                                             cloud_folder)]\n",
        "    execute_in_shell(command = command, \n",
        "                     verbose = verbose)\n",
        "    del command"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pSJAqC8B29iH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rClone_download(drive_name = None,\n",
        "                    local_folder = None,\n",
        "                    cloud_folder = None,\n",
        "                    verbose = False):\n",
        "    command = ['rclone copy {}:{} {}'.format(drive_name, \n",
        "                                             cloud_folder, \n",
        "                                             local_folder)]\n",
        "    execute_in_shell(command = command, \n",
        "                     verbose = verbose)\n",
        "    del command"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ptGPQCO429iT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Authenticate Google drive in Colab"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FPgipDFAw0js",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0f9d964-a747-44b9-a52f-9ab6d5429248"
      },
      "cell_type": "code",
      "source": [
        "if colab_mode:\n",
        "    drive = cloud_authenticate()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sucessfully authenticated to access Google Drive ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "HoquDImWsEPj"
      },
      "cell_type": "markdown",
      "source": [
        "#### Upload data to object storage"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "P8i3lkCU3we_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_dir = './pneumonia_detection/'\n",
        "file_name = ['stage_1_detailed_class_info.csv.zip',\n",
        "             'stage_1_train_images.zip',\n",
        "             'stage_1_sample_submission.csv',\n",
        "             'stage_1_train_labels.csv.zip',\n",
        "             'stage_1_test_images.zip']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0b8Gggiunm6F",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if upload_data and colab_mode:\n",
        "  for f in file_name:\n",
        "    googledrive_save(file_name = f,\n",
        "               file_dir = './',\n",
        "               upload = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xMVO9cmj7eGR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_dir = './pneumonia_detection/'\n",
        "file_name = ['stage_2_detailed_class_info.csv.zip',\n",
        "             'stage_2_train_images.zip',\n",
        "             'stage_2_sample_submission.csv',\n",
        "             'stage_2_train_labels.csv.zip',\n",
        "             'stage_2_test_images.zip']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vHe9bVj28IDW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if upload_data and colab_mode and stage_2:\n",
        "  for f in file_name:\n",
        "    googledrive_save(file_name = f,\n",
        "               file_dir = './',\n",
        "               upload = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "MxS2zjK0sJsZ"
      },
      "cell_type": "markdown",
      "source": [
        "#### Download data from object storage"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jWwaNBtVxBSN",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if download_data and colab_mode:\n",
        "  for f in file_name:\n",
        "    googledrive_fetch(file_name = f, \n",
        "                      fetch=True, \n",
        "                      latest = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sLArR9qaQmZ3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_dir = './pneumonia_detection/'\n",
        "file_name = ['mask_rcnn_coco.h5',\n",
        "             '{}_mask_rcnn_pneumonia.h5'.format(IMG_PROC_SIZE)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pwX7Cnb1ZIP3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if upload_data and colab_mode:\n",
        "  for f in file_name:\n",
        "    googledrive_save(file_name = f,\n",
        "               file_dir = './',\n",
        "               upload = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wfLUkPCMYpFt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "b856c9a5-495d-43c7-9787-a7e3b435d365"
      },
      "cell_type": "code",
      "source": [
        "if download_data and colab_mode:\n",
        "  for f in file_name:\n",
        "    googledrive_fetch(file_name = f, \n",
        "                fetch=True, \n",
        "                latest = True)\n",
        "elif update_weights:\n",
        "  for f in file_name:\n",
        "    googledrive_fetch(file_name = f, \n",
        "                fetch=True, \n",
        "                latest = True)\n",
        "else:\n",
        "  pass"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A total of 2 files with the same file name found ...\n",
            "Found: mask_rcnn_coco.h5 file, with file id: 1ZpriNeKdIp_ibxWV6Ru2FyYbcpbYeFYL\n",
            "Found: mask_rcnn_coco.h5 file, with file id: 1P4ByEx3B19bcseBGYXJXxKvX1ymY28jQ\n",
            "Downloading the most recent mask_rcnn_coco.h5 file ...\n",
            "Found most recent version of: mask_rcnn_coco.h5 file with file id: 1ZpriNeKdIp_ibxWV6Ru2FyYbcpbYeFYL ...\n",
            "Downloading mask_rcnn_coco.h5 file, with file id: 1ZpriNeKdIp_ibxWV6Ru2FyYbcpbYeFYL ...\n",
            "Successfully downloaded the file: mask_rcnn_coco.h5 to: ./mask_rcnn_coco.h5 ...\n",
            "Found most recent version of: 1024_mask_rcnn_pneumonia.h5 file with file id: 1RPKoFT8Sipmo3b7QEDg8TxyBsotW4739 ...\n",
            "Downloading 1024_mask_rcnn_pneumonia.h5 file, with file id: 1RPKoFT8Sipmo3b7QEDg8TxyBsotW4739 ...\n",
            "Successfully downloaded the file: 1024_mask_rcnn_pneumonia.h5 to: ./1024_mask_rcnn_pneumonia.h5 ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v3A9Kjc2Qxzm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e67fbec9-7b2f-4346-8103-fe88c67d7c39"
      },
      "cell_type": "code",
      "source": [
        "command = ['mv ./{}_mask_rcnn_pneumonia.h5 ./mask_rcnn_pneumonia.h5'.format(IMG_PROC_SIZE)]\n",
        "if setup and download_data and colab_mode:\n",
        "  execute_in_shell(command = command, \n",
        "                   verbose = True)\n",
        "elif os.path.exists('./{}_mask_rcnn_pneumonia.h5'.format(IMG_PROC_SIZE)):\n",
        "  execute_in_shell(command = command, \n",
        "                   verbose = True)\n",
        "else:\n",
        "  pass"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success running shell command: mv ./1024_mask_rcnn_pneumonia.h5 ./mask_rcnn_pneumonia.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o9XW40i2QyOz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "command = ['mv ./pneumonia_detection/{}_mask_rcnn_pneumonia.h5 ./mask_rcnn_pneumonia.h5'.format(IMG_PROC_SIZE)]\n",
        "if setup and download_data and not colab_mode:\n",
        "  execute_in_shell(command = command, \n",
        "                   verbose = True)\n",
        "elif os.path.exists('./pneumonia_detection/{}_mask_rcnn_pneumonia.h5'.format(IMG_PROC_SIZE)):\n",
        "  execute_in_shell(command = command, \n",
        "                   verbose = True)\n",
        "else:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "a3L0j-k9scfp"
      },
      "cell_type": "markdown",
      "source": [
        "#### Unzip and prepare data for ingestion into a deep-neural network"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "CwNATEcMFove",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "command = ['ls ./pneumonia_detection/',\n",
        "           'mkdir ./pneumonia_detection/stage_1_train_images/',\n",
        "           'mkdir ./pneumonia_detection/stage_1_test_images/',\n",
        "           'unzip -q ./stage_1_detailed_class_info.csv.zip -d ./pneumonia_detection/',\n",
        "           'unzip -q ./stage_1_train_images.zip  -d ./pneumonia_detection/stage_1_train_images/',\n",
        "           'unzip -q ./stage_1_train_labels.csv.zip -d ./pneumonia_detection/',\n",
        "           'unzip -q ./stage_1_test_images.zip -d ./pneumonia_detection/stage_1_test_images/']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aby2x8_ByeD7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if setup and not stage_2:\n",
        "  execute_in_shell(command = command, verbose = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p7ZQzDzV8278",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "command = ['ls ./pneumonia_detection/',\n",
        "           'mkdir ./pneumonia_detection/stage_2_train_images/',\n",
        "           'mkdir ./pneumonia_detection/stage_2_test_images/',\n",
        "           'unzip -q ./stage_2_detailed_class_info.csv.zip -d ./pneumonia_detection/',\n",
        "           'unzip -q ./stage_2_train_images.zip  -d ./pneumonia_detection/stage_2_train_images/',\n",
        "           'unzip -q ./stage_2_train_labels.csv.zip -d ./pneumonia_detection/',\n",
        "           'unzip -q ./stage_2_test_images.zip -d ./pneumonia_detection/stage_2_test_images/']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8TQFS-ed9F_y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if setup and stage_2:\n",
        "  execute_in_shell(command = command, verbose = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2uTxxGRuZyF2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cmd = [\"wget --quiet https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\"]\n",
        "\n",
        "if use_transfer_learn and not load_weights and setup and fetch_raw_data:\n",
        "  execute_in_shell(command = command, verbose = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tCOysUloYcSt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "COCO_WEIGHTS_PATH = \"./mask_rcnn_coco.h5\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "iZkrJyMjspoD"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 02 -- Mask RCNN Model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jVEKzGVtm_hm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b460b84e-1289-46e5-ac91-67be31a14e96"
      },
      "cell_type": "code",
      "source": [
        "from mrcnn.config import Config\n",
        "from mrcnn import utils\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import visualize\n",
        "from mrcnn.model import log"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "elExaxWfwbEe",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "DATA_DIR = './pneumonia_detection'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6HP4e8UInf_s",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if stage_2:\n",
        "  train_dicom_dir = os.path.join(DATA_DIR, 'stage_2_train_images')\n",
        "  test_dicom_dir = os.path.join(DATA_DIR, 'stage_2_test_images')\n",
        "else:\n",
        "  train_dicom_dir = os.path.join(DATA_DIR, 'stage_1_train_images')\n",
        "  test_dicom_dir = os.path.join(DATA_DIR, 'stage_1_test_images')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "OB04x04TyrFU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_dicom_fps(dicom_dir):\n",
        "    dicom_fps = glob.glob(dicom_dir+'/'+'*.dcm')\n",
        "    return list(set(dicom_fps))\n",
        "\n",
        "def parse_dataset(dicom_dir, anns): \n",
        "    image_fps = get_dicom_fps(dicom_dir)\n",
        "    image_annotations = {fp: [] for fp in image_fps}\n",
        "    for index, row in anns.iterrows(): \n",
        "        fp = os.path.join(dicom_dir, row['patientId']+'.dcm')\n",
        "        image_annotations[fp].append(row)\n",
        "    return image_fps, image_annotations "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2UwJy50E-gHK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Initialize weights using transfer learning -- COCO pre-trained weights"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BQJxQcmd03tT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "dc1ed4b9-40a6-4820-d821-e22177fec81d"
      },
      "cell_type": "code",
      "source": [
        "# The following parameters have been selected to reduce running time for demonstration purposes \n",
        "# These are not optimal \n",
        "\n",
        "class DetectorConfig(Config):\n",
        "    \"\"\"Configuration for training pneumonia detection on the RSNA pneumonia dataset.\n",
        "    Overrides values in the base Config class.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Give the configuration a recognizable name  \n",
        "    NAME = 'pneumonia'\n",
        "    \n",
        "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
        "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    \n",
        "    BACKBONE = 'resnet101'\n",
        "    NUM_CLASSES = 2  # background + 1 pneumonia classes\n",
        "    \n",
        "    IMAGE_MIN_DIM = IMG_PROC_SIZE\n",
        "    IMAGE_MAX_DIM = IMG_PROC_SIZE\n",
        "    RPN_ANCHOR_SCALES = (2, 4, 8, 16, 32)\n",
        "    TRAIN_ROIS_PER_IMAGE = 256\n",
        "    MAX_GT_INSTANCES = 1024\n",
        "    DETECTION_MAX_INSTANCES = 3\n",
        "    DETECTION_MIN_CONFIDENCE = 0.9  ## match target distribution\n",
        "    DETECTION_NMS_THRESHOLD = 0.01\n",
        "    \n",
        "    #IMAGE_SHAPE = [IMG_PROC_SIZE, IMG_PROC_SIZE, 3]\n",
        "    \n",
        "    LOSS_WEIGHTS = {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
        "      \n",
        "    LEARNING_RATE = LEARNING_RATE\n",
        "\n",
        "    STEPS_PER_EPOCH = 1600\n",
        "    \n",
        "config = DetectorConfig()\n",
        "config.display()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     1\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        3\n",
            "DETECTION_MIN_CONFIDENCE       0.9\n",
            "DETECTION_NMS_THRESHOLD        0.01\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 1\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  1024\n",
            "IMAGE_META_SIZE                14\n",
            "IMAGE_MIN_DIM                  1024\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [1024 1024    3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  1e-05\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               1024\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           pneumonia\n",
            "NUM_CLASSES                    2\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (2, 4, 8, 16, 32)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                1600\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           256\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "kP7BadhczSrl",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DetectorDataset(utils.Dataset):\n",
        "    \"\"\"Dataset class for training pneumonia detection on the RSNA pneumonia dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, image_fps, image_annotations, orig_height, orig_width):\n",
        "        super().__init__(self)\n",
        "        \n",
        "        # Add classes\n",
        "        self.add_class('pneumonia', 1, 'Lung Opacity')\n",
        "   \n",
        "        # add images \n",
        "        for i, fp in enumerate(image_fps):\n",
        "            annotations = image_annotations[fp]\n",
        "            self.add_image('pneumonia', image_id=i, path=fp, \n",
        "                           annotations=annotations, orig_height=orig_height, orig_width=orig_width)\n",
        "            \n",
        "    def image_reference(self, image_id):\n",
        "        info = self.image_info[image_id]\n",
        "        return info['path']\n",
        "\n",
        "    def load_image(self, image_id):\n",
        "        info = self.image_info[image_id]\n",
        "        fp = info['path']\n",
        "        ds = pydicom.read_file(fp)\n",
        "        image = ds.pixel_array\n",
        "        # If grayscale. Convert to RGB for consistency.\n",
        "        if len(image.shape) != 3 or image.shape[2] != 3:\n",
        "            image = np.stack((image,) * 3, -1)\n",
        "        return image\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        info = self.image_info[image_id]\n",
        "        annotations = info['annotations']\n",
        "        count = len(annotations)\n",
        "        if count == 0:\n",
        "            mask = np.zeros((info['orig_height'], info['orig_width'], 1), dtype=np.uint8)\n",
        "            class_ids = np.zeros((1,), dtype=np.int32)\n",
        "        else:\n",
        "            mask = np.zeros((info['orig_height'], info['orig_width'], count), dtype=np.uint8)\n",
        "            class_ids = np.zeros((count,), dtype=np.int32)\n",
        "            for i, a in enumerate(annotations):\n",
        "                if a['Target'] == 1:\n",
        "                    x = int(a['x'])\n",
        "                    y = int(a['y'])\n",
        "                    w = int(a['width'])\n",
        "                    h = int(a['height'])\n",
        "                    mask_instance = mask[:, :, i].copy()\n",
        "                    cv2.rectangle(mask_instance, (x, y), (x+w, y+h), 255, -1)\n",
        "                    mask[:, :, i] = mask_instance\n",
        "                    class_ids[i] = 1\n",
        "        return mask.astype(np.bool), class_ids.astype(np.int32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "F_Ro1zEJ3AWw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f1a456ab-9819-472c-f67d-986e7dcb0fd6"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# training dataset\n",
        "if stage_2:\n",
        "  anns = pd.read_csv(os.path.join(DATA_DIR, 'stage_2_train_labels.csv'))\n",
        "else:\n",
        "  anns = pd.read_csv(os.path.join(DATA_DIR, 'stage_1_train_labels.csv'))\n",
        "anns.head()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patientId</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0004cfab-14fd-4e49-80ba-63a80b6bddd6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00313ee0-9eaa-42f4-b0ab-c148ed3241cd</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00322d4d-1c29-4943-afc9-b6754be640eb</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>003d8fa0-6bf1-40ed-b54c-ac657f8495c5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00436515-870c-4b36-a041-de91049b9ab4</td>\n",
              "      <td>264.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>213.0</td>\n",
              "      <td>379.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              patientId      x      y  width  height  Target\n",
              "0  0004cfab-14fd-4e49-80ba-63a80b6bddd6    NaN    NaN    NaN     NaN       0\n",
              "1  00313ee0-9eaa-42f4-b0ab-c148ed3241cd    NaN    NaN    NaN     NaN       0\n",
              "2  00322d4d-1c29-4943-afc9-b6754be640eb    NaN    NaN    NaN     NaN       0\n",
              "3  003d8fa0-6bf1-40ed-b54c-ac657f8495c5    NaN    NaN    NaN     NaN       0\n",
              "4  00436515-870c-4b36-a041-de91049b9ab4  264.0  152.0  213.0   379.0       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YUfXGRxV3MYv",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_fps, image_annotations = parse_dataset(train_dicom_dir, anns=anns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Au48ErSo3QHg",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ds = pydicom.read_file(image_fps[0]) # read dicom image from filepath \n",
        "image = ds.pixel_array # get image array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9octjulN2luG",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# show dicom fields \n",
        "preview = False\n",
        "if preview:\n",
        "  ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "C_ZGkV8b7O8M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b278516-cbb3-4df6-d426-f5e3dc93b87e"
      },
      "cell_type": "code",
      "source": [
        "######################################################################\n",
        "# Modify this line to use more or fewer images for training/validation. \n",
        "# To use all images, do: image_fps_list = list(image_fps)\n",
        "image_fps_list = list(image_fps) \n",
        "#####################################################################\n",
        "\n",
        "# split dataset into training vs. validation dataset \n",
        "# split ratio is set to 0.9 vs. 0.1 (train vs. validation, respectively)\n",
        "sorted(image_fps_list)\n",
        "random.seed(42)\n",
        "random.shuffle(image_fps_list)\n",
        "\n",
        "validation_split = 0.1\n",
        "split_index = int((1 - validation_split) * len(image_fps_list))\n",
        "\n",
        "image_fps_train = image_fps_list[:split_index]\n",
        "image_fps_val = image_fps_list[split_index:]\n",
        "\n",
        "print(len(image_fps_train), len(image_fps_val))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24015 2669\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wkF-Nc-g7Xph",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# prepare the training dataset\n",
        "dataset_train = DetectorDataset(image_fps_train, image_annotations, ORIG_SIZE, ORIG_SIZE)\n",
        "dataset_train.prepare()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "nzcHhM1c8iYL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "b982268e-0e19-44c9-91d8-e40e17eb5558"
      },
      "cell_type": "code",
      "source": [
        "# Show annotation(s) for a DICOM image \n",
        "test_fp = random.choice(image_fps_train)\n",
        "image_annotations[test_fp]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[patientId    58dddcca-2f38-4556-8a72-326f8113ebb5\n",
              " x                                             NaN\n",
              " y                                             NaN\n",
              " width                                         NaN\n",
              " height                                        NaN\n",
              " Target                                          0\n",
              " Name: 7667, dtype: object]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3gZz5bGc8oKq",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# prepare the validation dataset\n",
        "dataset_val = DetectorDataset(image_fps_val, image_annotations, ORIG_SIZE, ORIG_SIZE)\n",
        "dataset_val.prepare()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "p4wJVzv9cGG2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load and display random samples and their bounding boxes\n",
        "# Suggestion: Run this a few times to see different examples. \n",
        "\n",
        "summary_plot = False\n",
        "\n",
        "if summary_plot:\n",
        "    image_id = random.choice(dataset_train.image_ids)\n",
        "    image_fp = dataset_train.image_reference(image_id)\n",
        "    image = dataset_train.load_image(image_id)\n",
        "    mask, class_ids = dataset_train.load_mask(image_id)\n",
        "\n",
        "    print(image.shape)\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(image[:, :, 0], cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    masked = np.zeros(image.shape[:2])\n",
        "    for i in range(mask.shape[2]):\n",
        "        masked += image[:, :, 0] * mask[:, :, i]\n",
        "    plt.imshow(masked, cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "    print(image_fp)\n",
        "    print(class_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xBPocw6R0E78",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ROOT_DIR = './pneumonia_detection/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2tmW3hBqMbGN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "02ba762a-52ff-4124-f502-8528f7283905"
      },
      "cell_type": "code",
      "source": [
        "model = modellib.MaskRCNN(mode='training', \n",
        "                          config=config, \n",
        "                          model_dir=ROOT_DIR)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G_xNrRB6c9C1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f84f42c6-ef50-4c7c-97f2-8a42d1a90499"
      },
      "cell_type": "code",
      "source": [
        "if use_transfer_learn:\n",
        "  # Exclude the last layers because they require a matching\n",
        "  # number of classes\n",
        "  try:\n",
        "    model.load_weights(COCO_WEIGHTS_PATH, by_name=True, exclude=[\"mrcnn_class_logits\", \n",
        "                                                               \"mrcnn_bbox_fc\",\n",
        "                                                               \"mrcnn_bbox\", \n",
        "                                                               \"mrcnn_mask\"])\n",
        "    print ('Loaded trained weights using COCO dataset ...')\n",
        "  except:\n",
        "    print ('Failed to load trained weights using COCO dataset ...')\n",
        "elif load_weights and not use_transfer_learn:\n",
        "  try:\n",
        "    model.load_weights('./pneumonia_detection/mask_rcnn_pneumonia.h5', by_name=True)\n",
        "    print ('Loaded weights from {}'.format('./pneumonia_detection/mask_rcnn_pneumonia.h5'))\n",
        "  except:\n",
        "    model.load_weights('./mask_rcnn_pneumonia.h5', by_name=True)\n",
        "    print ('Loaded weights from {}'.format('./mask_rcnn_pneumonia.h5'))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded weights from ./mask_rcnn_pneumonia.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hDvD2arq8rrS",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Image augmentation \n",
        "augmentation_1 = iaa.SomeOf((0, 1), [\n",
        "    iaa.Fliplr(0.5),\n",
        "    iaa.Affine(scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
        "               translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
        "               rotate=(-25, 25),\n",
        "               shear=(-8, 8)),\n",
        "               iaa.Multiply((0.9, 1.1))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f1vLHrpcdjVJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Image augmentation (light but constant)\n",
        "augmentation_2 = iaa.Sequential([\n",
        "    iaa.OneOf([ ## geometric transform\n",
        "        iaa.Affine(\n",
        "            scale={\"x\": (0.98, 1.02), \"y\": (0.98, 1.04)},\n",
        "            translate_percent={\"x\": (-0.02, 0.02), \"y\": (-0.04, 0.04)},\n",
        "            rotate=(-2, 2),\n",
        "            shear=(-1, 1),\n",
        "        ),\n",
        "        iaa.PiecewiseAffine(scale=(0.001, 0.025)),\n",
        "    ]),\n",
        "    iaa.OneOf([ ## brightness or contrast\n",
        "        iaa.Multiply((0.9, 1.1)),\n",
        "        iaa.ContrastNormalization((0.9, 1.1)),\n",
        "    ]),\n",
        "    iaa.OneOf([ ## blur or sharpen\n",
        "        iaa.GaussianBlur(sigma=(0.0, 0.1)),\n",
        "        iaa.Sharpen(alpha=(0.0, 0.1)),\n",
        "    ]),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "puVfufaOd3h1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "89197fb4-77d0-468a-d806-676fbd9df932"
      },
      "cell_type": "code",
      "source": [
        "if use_augmentation == 2:\n",
        "  augmentation = augmentation_2\n",
        "  print ('Using augmentation mode: 2')\n",
        "elif use_augmentation == 1:\n",
        "  augmentation = augmentation_1\n",
        "  print ('Using augmentation mode: 1')\n",
        "else:\n",
        "  augmentation = None\n",
        "  print ('Using augmentation mode: None')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using augmentation mode: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PQ7tKzkAd0-C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train Mask-RCNN Model \n",
        "import warnings \n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bJpBP-THmi7t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train top layer using COCO weights or pre-trained weights"
      ]
    },
    {
      "metadata": {
        "id": "QY_ti8kKed1S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "df79d31d-ed82-4fed-e083-5be5dd02bf6f"
      },
      "cell_type": "code",
      "source": [
        "command = ['rm -r {}/pneumonia2018*'.format(ROOT_DIR)]\n",
        "execute_in_shell(command = command, verbose = True)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success running shell command: rm -r ./pneumonia_detection//pneumonia2018*\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Error': [None], 'Output': [b'']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "metadata": {
        "id": "9EhRV6M8dwhF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5930
        },
        "outputId": "d6e8ac61-0f1a-453f-d8f3-27b1d9ce3b44"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "## train heads with higher lr to speedup the learning\n",
        "if use_transfer_learn or fine_tune:\n",
        "  layers = 'heads'\n",
        "else:\n",
        "  layers = 'all'\n",
        "  \n",
        "model.train(dataset_train, dataset_val,\n",
        "            learning_rate=LEARNING_RATE*2,\n",
        "            epochs=2,\n",
        "            layers=layers,\n",
        "            augmentation=None)  ## no need to augment yet\n",
        "history = model.keras_model.history.history"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting at epoch 0. LR=2e-05\n",
            "\n",
            "Checkpoint Path: ./pneumonia_detection/pneumonia20190326T2143/mask_rcnn_pneumonia_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "conv1                  (Conv2D)\n",
            "bn_conv1               (BatchNorm)\n",
            "res2a_branch2a         (Conv2D)\n",
            "bn2a_branch2a          (BatchNorm)\n",
            "res2a_branch2b         (Conv2D)\n",
            "bn2a_branch2b          (BatchNorm)\n",
            "res2a_branch2c         (Conv2D)\n",
            "res2a_branch1          (Conv2D)\n",
            "bn2a_branch2c          (BatchNorm)\n",
            "bn2a_branch1           (BatchNorm)\n",
            "res2b_branch2a         (Conv2D)\n",
            "bn2b_branch2a          (BatchNorm)\n",
            "res2b_branch2b         (Conv2D)\n",
            "bn2b_branch2b          (BatchNorm)\n",
            "res2b_branch2c         (Conv2D)\n",
            "bn2b_branch2c          (BatchNorm)\n",
            "res2c_branch2a         (Conv2D)\n",
            "bn2c_branch2a          (BatchNorm)\n",
            "res2c_branch2b         (Conv2D)\n",
            "bn2c_branch2b          (BatchNorm)\n",
            "res2c_branch2c         (Conv2D)\n",
            "bn2c_branch2c          (BatchNorm)\n",
            "res3a_branch2a         (Conv2D)\n",
            "bn3a_branch2a          (BatchNorm)\n",
            "res3a_branch2b         (Conv2D)\n",
            "bn3a_branch2b          (BatchNorm)\n",
            "res3a_branch2c         (Conv2D)\n",
            "res3a_branch1          (Conv2D)\n",
            "bn3a_branch2c          (BatchNorm)\n",
            "bn3a_branch1           (BatchNorm)\n",
            "res3b_branch2a         (Conv2D)\n",
            "bn3b_branch2a          (BatchNorm)\n",
            "res3b_branch2b         (Conv2D)\n",
            "bn3b_branch2b          (BatchNorm)\n",
            "res3b_branch2c         (Conv2D)\n",
            "bn3b_branch2c          (BatchNorm)\n",
            "res3c_branch2a         (Conv2D)\n",
            "bn3c_branch2a          (BatchNorm)\n",
            "res3c_branch2b         (Conv2D)\n",
            "bn3c_branch2b          (BatchNorm)\n",
            "res3c_branch2c         (Conv2D)\n",
            "bn3c_branch2c          (BatchNorm)\n",
            "res3d_branch2a         (Conv2D)\n",
            "bn3d_branch2a          (BatchNorm)\n",
            "res3d_branch2b         (Conv2D)\n",
            "bn3d_branch2b          (BatchNorm)\n",
            "res3d_branch2c         (Conv2D)\n",
            "bn3d_branch2c          (BatchNorm)\n",
            "res4a_branch2a         (Conv2D)\n",
            "bn4a_branch2a          (BatchNorm)\n",
            "res4a_branch2b         (Conv2D)\n",
            "bn4a_branch2b          (BatchNorm)\n",
            "res4a_branch2c         (Conv2D)\n",
            "res4a_branch1          (Conv2D)\n",
            "bn4a_branch2c          (BatchNorm)\n",
            "bn4a_branch1           (BatchNorm)\n",
            "res4b_branch2a         (Conv2D)\n",
            "bn4b_branch2a          (BatchNorm)\n",
            "res4b_branch2b         (Conv2D)\n",
            "bn4b_branch2b          (BatchNorm)\n",
            "res4b_branch2c         (Conv2D)\n",
            "bn4b_branch2c          (BatchNorm)\n",
            "res4c_branch2a         (Conv2D)\n",
            "bn4c_branch2a          (BatchNorm)\n",
            "res4c_branch2b         (Conv2D)\n",
            "bn4c_branch2b          (BatchNorm)\n",
            "res4c_branch2c         (Conv2D)\n",
            "bn4c_branch2c          (BatchNorm)\n",
            "res4d_branch2a         (Conv2D)\n",
            "bn4d_branch2a          (BatchNorm)\n",
            "res4d_branch2b         (Conv2D)\n",
            "bn4d_branch2b          (BatchNorm)\n",
            "res4d_branch2c         (Conv2D)\n",
            "bn4d_branch2c          (BatchNorm)\n",
            "res4e_branch2a         (Conv2D)\n",
            "bn4e_branch2a          (BatchNorm)\n",
            "res4e_branch2b         (Conv2D)\n",
            "bn4e_branch2b          (BatchNorm)\n",
            "res4e_branch2c         (Conv2D)\n",
            "bn4e_branch2c          (BatchNorm)\n",
            "res4f_branch2a         (Conv2D)\n",
            "bn4f_branch2a          (BatchNorm)\n",
            "res4f_branch2b         (Conv2D)\n",
            "bn4f_branch2b          (BatchNorm)\n",
            "res4f_branch2c         (Conv2D)\n",
            "bn4f_branch2c          (BatchNorm)\n",
            "res4g_branch2a         (Conv2D)\n",
            "bn4g_branch2a          (BatchNorm)\n",
            "res4g_branch2b         (Conv2D)\n",
            "bn4g_branch2b          (BatchNorm)\n",
            "res4g_branch2c         (Conv2D)\n",
            "bn4g_branch2c          (BatchNorm)\n",
            "res4h_branch2a         (Conv2D)\n",
            "bn4h_branch2a          (BatchNorm)\n",
            "res4h_branch2b         (Conv2D)\n",
            "bn4h_branch2b          (BatchNorm)\n",
            "res4h_branch2c         (Conv2D)\n",
            "bn4h_branch2c          (BatchNorm)\n",
            "res4i_branch2a         (Conv2D)\n",
            "bn4i_branch2a          (BatchNorm)\n",
            "res4i_branch2b         (Conv2D)\n",
            "bn4i_branch2b          (BatchNorm)\n",
            "res4i_branch2c         (Conv2D)\n",
            "bn4i_branch2c          (BatchNorm)\n",
            "res4j_branch2a         (Conv2D)\n",
            "bn4j_branch2a          (BatchNorm)\n",
            "res4j_branch2b         (Conv2D)\n",
            "bn4j_branch2b          (BatchNorm)\n",
            "res4j_branch2c         (Conv2D)\n",
            "bn4j_branch2c          (BatchNorm)\n",
            "res4k_branch2a         (Conv2D)\n",
            "bn4k_branch2a          (BatchNorm)\n",
            "res4k_branch2b         (Conv2D)\n",
            "bn4k_branch2b          (BatchNorm)\n",
            "res4k_branch2c         (Conv2D)\n",
            "bn4k_branch2c          (BatchNorm)\n",
            "res4l_branch2a         (Conv2D)\n",
            "bn4l_branch2a          (BatchNorm)\n",
            "res4l_branch2b         (Conv2D)\n",
            "bn4l_branch2b          (BatchNorm)\n",
            "res4l_branch2c         (Conv2D)\n",
            "bn4l_branch2c          (BatchNorm)\n",
            "res4m_branch2a         (Conv2D)\n",
            "bn4m_branch2a          (BatchNorm)\n",
            "res4m_branch2b         (Conv2D)\n",
            "bn4m_branch2b          (BatchNorm)\n",
            "res4m_branch2c         (Conv2D)\n",
            "bn4m_branch2c          (BatchNorm)\n",
            "res4n_branch2a         (Conv2D)\n",
            "bn4n_branch2a          (BatchNorm)\n",
            "res4n_branch2b         (Conv2D)\n",
            "bn4n_branch2b          (BatchNorm)\n",
            "res4n_branch2c         (Conv2D)\n",
            "bn4n_branch2c          (BatchNorm)\n",
            "res4o_branch2a         (Conv2D)\n",
            "bn4o_branch2a          (BatchNorm)\n",
            "res4o_branch2b         (Conv2D)\n",
            "bn4o_branch2b          (BatchNorm)\n",
            "res4o_branch2c         (Conv2D)\n",
            "bn4o_branch2c          (BatchNorm)\n",
            "res4p_branch2a         (Conv2D)\n",
            "bn4p_branch2a          (BatchNorm)\n",
            "res4p_branch2b         (Conv2D)\n",
            "bn4p_branch2b          (BatchNorm)\n",
            "res4p_branch2c         (Conv2D)\n",
            "bn4p_branch2c          (BatchNorm)\n",
            "res4q_branch2a         (Conv2D)\n",
            "bn4q_branch2a          (BatchNorm)\n",
            "res4q_branch2b         (Conv2D)\n",
            "bn4q_branch2b          (BatchNorm)\n",
            "res4q_branch2c         (Conv2D)\n",
            "bn4q_branch2c          (BatchNorm)\n",
            "res4r_branch2a         (Conv2D)\n",
            "bn4r_branch2a          (BatchNorm)\n",
            "res4r_branch2b         (Conv2D)\n",
            "bn4r_branch2b          (BatchNorm)\n",
            "res4r_branch2c         (Conv2D)\n",
            "bn4r_branch2c          (BatchNorm)\n",
            "res4s_branch2a         (Conv2D)\n",
            "bn4s_branch2a          (BatchNorm)\n",
            "res4s_branch2b         (Conv2D)\n",
            "bn4s_branch2b          (BatchNorm)\n",
            "res4s_branch2c         (Conv2D)\n",
            "bn4s_branch2c          (BatchNorm)\n",
            "res4t_branch2a         (Conv2D)\n",
            "bn4t_branch2a          (BatchNorm)\n",
            "res4t_branch2b         (Conv2D)\n",
            "bn4t_branch2b          (BatchNorm)\n",
            "res4t_branch2c         (Conv2D)\n",
            "bn4t_branch2c          (BatchNorm)\n",
            "res4u_branch2a         (Conv2D)\n",
            "bn4u_branch2a          (BatchNorm)\n",
            "res4u_branch2b         (Conv2D)\n",
            "bn4u_branch2b          (BatchNorm)\n",
            "res4u_branch2c         (Conv2D)\n",
            "bn4u_branch2c          (BatchNorm)\n",
            "res4v_branch2a         (Conv2D)\n",
            "bn4v_branch2a          (BatchNorm)\n",
            "res4v_branch2b         (Conv2D)\n",
            "bn4v_branch2b          (BatchNorm)\n",
            "res4v_branch2c         (Conv2D)\n",
            "bn4v_branch2c          (BatchNorm)\n",
            "res4w_branch2a         (Conv2D)\n",
            "bn4w_branch2a          (BatchNorm)\n",
            "res4w_branch2b         (Conv2D)\n",
            "bn4w_branch2b          (BatchNorm)\n",
            "res4w_branch2c         (Conv2D)\n",
            "bn4w_branch2c          (BatchNorm)\n",
            "res5a_branch2a         (Conv2D)\n",
            "bn5a_branch2a          (BatchNorm)\n",
            "res5a_branch2b         (Conv2D)\n",
            "bn5a_branch2b          (BatchNorm)\n",
            "res5a_branch2c         (Conv2D)\n",
            "res5a_branch1          (Conv2D)\n",
            "bn5a_branch2c          (BatchNorm)\n",
            "bn5a_branch1           (BatchNorm)\n",
            "res5b_branch2a         (Conv2D)\n",
            "bn5b_branch2a          (BatchNorm)\n",
            "res5b_branch2b         (Conv2D)\n",
            "bn5b_branch2b          (BatchNorm)\n",
            "res5b_branch2c         (Conv2D)\n",
            "bn5b_branch2c          (BatchNorm)\n",
            "res5c_branch2a         (Conv2D)\n",
            "bn5c_branch2a          (BatchNorm)\n",
            "res5c_branch2b         (Conv2D)\n",
            "bn5c_branch2b          (BatchNorm)\n",
            "res5c_branch2c         (Conv2D)\n",
            "bn5c_branch2c          (BatchNorm)\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-369b8414b452>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"## train heads with higher lr to speedup the learning\\nif use_transfer_learn or fine_tune:\\n  layers = 'heads'\\nelse:\\n  layers = 'all'\\n  \\nmodel.train(dataset_train, dataset_val,\\n            learning_rate=LEARNING_RATE*2,\\n            epochs=2,\\n            layers=layers,\\n            augmentation=None)  ## no need to augment yet\\nhistory = model.keras_model.history.history\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation, custom_callbacks, no_augmentation_sources)\u001b[0m\n\u001b[1;32m   2373\u001b[0m             \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2374\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2375\u001b[0;31m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2376\u001b[0m         )\n\u001b[1;32m   2377\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1,512,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node bn3c_branch2c/FusedBatchNorm}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node mul_259}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ibTtdmw4qs0k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Retrain all layers of the MRCNN network"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "euqq2r4KPW4_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Train Mask-RCNN Model \n",
        "import warnings \n",
        "warnings.filterwarnings(\"ignore\")\n",
        "model.train(dataset_train, dataset_val, \n",
        "            learning_rate=LEARNING_RATE, \n",
        "            epochs=NUM_EPOCHS, \n",
        "            layers='all',\n",
        "            augmentation=augmentation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QlN37XX13Ixl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "new_history = model.keras_model.history.history\n",
        "for k in new_history: history[k] = history[k] + new_history[k]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Jcxgb4Tq7AZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test predictions using the same image as above"
      ]
    },
    {
      "metadata": {
        "id": "Z5-q8xL1dmbB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if augmentation != None:\n",
        "  imggrid = augmentation.draw_grid(image[:, :], cols=2, rows=2)\n",
        "  plt.figure(figsize=(30, 12))\n",
        "  _ = plt.imshow(imggrid[:, :, 0], cmap='gray')\n",
        "else:\n",
        "  _ = plt.imshow(image, cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y_UcCOjZ4YRJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Summarize training performance"
      ]
    },
    {
      "metadata": {
        "id": "T6MZBeGNe6dR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = range(1,len(next(iter(history.values())))+1)\n",
        "pd.DataFrame(history, index=epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ugJ4JmZtfCdd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(17,5))\n",
        "\n",
        "plt.subplot(131)\n",
        "plt.plot(epochs, history[\"loss\"], label=\"Train loss\")\n",
        "plt.plot(epochs, history[\"val_loss\"], label=\"Valid loss\")\n",
        "plt.legend()\n",
        "plt.subplot(132)\n",
        "plt.plot(epochs, history[\"mrcnn_class_loss\"], label=\"Train class ce\")\n",
        "plt.plot(epochs, history[\"val_mrcnn_class_loss\"], label=\"Valid class ce\")\n",
        "plt.legend()\n",
        "plt.subplot(133)\n",
        "plt.plot(epochs, history[\"mrcnn_bbox_loss\"], label=\"Train box loss\")\n",
        "plt.plot(epochs, history[\"val_mrcnn_bbox_loss\"], label=\"Valid box loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XPXSYpCBrHzJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Output the best epoch"
      ]
    },
    {
      "metadata": {
        "id": "1jfc24-IfLrV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save_last = True\n",
        "if save_last:\n",
        "  best_epoch = len(epochs)-1\n",
        "  print(\"Best Epoch:\", best_epoch+1)\n",
        "else:\n",
        "  best_epoch = np.argmin(history[\"val_loss\"])\n",
        "  print(\"Best Epoch:\", best_epoch + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3SqkrxlbrQRB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Select best performing trained model for saving weights"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8Lr-K5ib9GYa",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dir_names = next(os.walk(model.model_dir))[1]\n",
        "key = config.NAME.lower()\n",
        "dir_names = filter(lambda f: f.startswith(key), dir_names)\n",
        "dir_names = sorted(dir_names)\n",
        "\n",
        "if not dir_names:\n",
        "    import errno\n",
        "    raise FileNotFoundError(\n",
        "        errno.ENOENT,\n",
        "        \"Could not find model directory under {}\".format(self.model_dir))\n",
        "    \n",
        "fps = []\n",
        "# Pick last directory\n",
        "for d in dir_names: \n",
        "    dir_name = os.path.join(model.model_dir, d)\n",
        "    # Find the last checkpoint\n",
        "    checkpoints = next(os.walk(dir_name))[2]\n",
        "    checkpoints = filter(lambda f: f.startswith(\"mask_rcnn\"), checkpoints)\n",
        "    checkpoints = sorted(checkpoints)\n",
        "    if not checkpoints:\n",
        "        print('No weight files in {}'.format(dir_name))\n",
        "    else:\n",
        "        checkpoint = os.path.join(dir_name, checkpoints[best_epoch])\n",
        "        fps.append(checkpoint)\n",
        "\n",
        "model_path = sorted(fps)[-1]\n",
        "print('Found model {}'.format(model_path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ko1GvcSuvZgS",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "command = ['mv {} {}/{}_mask_rcnn_pneumonia.h5'.format(model_path, ROOT_DIR, IMG_PROC_SIZE),\n",
        "           'rm -r {}/pneumonia2018*'.format(ROOT_DIR),\n",
        "           'ls {}'.format(ROOT_DIR)]\n",
        "execute_in_shell(command = command, verbose = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GkEekraQmrl3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! ls ./pneumonia_detection/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zDcDjM9UrY0Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Upload weights file to Google drive"
      ]
    },
    {
      "metadata": {
        "id": "rcrEJqU2v2M1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if colab_mode:\n",
        "    drive = cloud_authenticate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "S4eec6uiiA2G",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_dir = '{}'.format(ROOT_DIR)\n",
        "checkpoint_file = '{}_mask_rcnn_pneumonia.h5'.format(IMG_PROC_SIZE)\n",
        "\n",
        "upload = False\n",
        "if colab_mode:\n",
        "    upload = True\n",
        "    googledrive_save(file_name = checkpoint_file,\n",
        "               file_dir = file_dir,\n",
        "               upload = upload)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9qTd18r629pp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "drive_name = 'googledrive'\n",
        "cloud_folder = 'Pneumonia_detection'\n",
        "local_folder = '{}/{}_mask_rcnn_pneumonia.h5'.format(ROOT_DIR, IMG_PROC_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yF_l6AX029pv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if not colab_mode:\n",
        "    rClone_upload(drive_name = drive_name,\n",
        "                  local_folder = local_folder,\n",
        "                  cloud_folder = cloud_folder,\n",
        "                  verbose = True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rc_Beo_OsoXj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create a function to generate predictions using MRCNN"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zPeq8EnpcxLp",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class InferenceConfig(DetectorConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "inference_config = InferenceConfig()\n",
        "\n",
        "# Recreate the model in inference mode\n",
        "model = modellib.MaskRCNN(mode='inference', \n",
        "                          config=inference_config,\n",
        "                          model_dir=ROOT_DIR)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zQH3mACtzY5L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if gen_preds:\n",
        "  # Exclude the last layers because they require a matching\n",
        "  # number of classes\n",
        "  try:\n",
        "    model_path = '{}/{}_mmask_rcnn_pneumonia.h5'.format(ROOT_DIR, IMG_PROC_SIZE)\n",
        "\n",
        "    # Load trained weights (fill in path to trained weights here)\n",
        "    assert model_path != \"\", \"Provide path to trained weights\"\n",
        "    model.load_weights(model_path, by_name=True)\n",
        "    print(\"Loading weights from \", model_path)\n",
        "  except:\n",
        "      try:\n",
        "        model.load_weights('{}/mask_rcnn_pneumonia.h5'.format(ROOT_DIR), by_name=True)\n",
        "        print ('Loaded weights from {}'.format('{}/mask_rcnn_pneumonia.h5'.format(ROOT_DIR)))\n",
        "      except:\n",
        "        model.load_weights('./mask_rcnn_pneumonia.h5', by_name=True)\n",
        "        print ('Loaded weights from {}'.format('./mask_rcnn_pneumonia.h5'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nzssPUUIsyVW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Set color for predictions class"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "w7jVb8p_3Bqg",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_colors_for_class_ids(class_ids):\n",
        "    colors = []\n",
        "    for class_id in class_ids:\n",
        "        if class_id == 1:\n",
        "            colors.append((.941, .204, .204))\n",
        "    return colors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4TAB9jN-rklC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Display a few example of ground truth vs. predictions on the validation dataset "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VUQzduNY3G8p",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset = dataset_val\n",
        "fig = plt.figure(figsize=(10, 30))\n",
        "\n",
        "for i in range(4):\n",
        "\n",
        "    image_id = random.choice(dataset.image_ids)\n",
        "    \n",
        "    original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "        modellib.load_image_gt(dataset_val, inference_config, \n",
        "                               image_id, use_mini_mask=False)\n",
        "        \n",
        "    plt.subplot(6, 2, 2*i + 1)\n",
        "    visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "                                dataset.class_names,\n",
        "                                colors=get_colors_for_class_ids(gt_class_id), ax=fig.axes[-1])\n",
        "    \n",
        "    plt.subplot(6, 2, 2*i + 2)\n",
        "    results = model.detect([original_image]) #, verbose=1)\n",
        "    r = results[0]\n",
        "    visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "                                dataset.class_names, r['scores'], \n",
        "                                colors=get_colors_for_class_ids(r['class_ids']), ax=fig.axes[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1qpGvE4trwPY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Get filenames of test dataset DICOM images"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-4u3EGRv3L1L",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if gen_preds:\n",
        "  test_image_fps = get_dicom_fps(test_dicom_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DaYmWSKer5Zv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Make predictions on test images and write out submission file"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "CyL8HfdW3RZM",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict(image_fps, filepath='sample_submission.csv', min_conf=0.98): \n",
        "    \n",
        "    # assume square image\n",
        "    resize_factor = ORIG_SIZE / config.IMAGE_SHAPE[0]\n",
        "    \n",
        "    with open(filepath, 'w') as file:\n",
        "      file.write(\"{},{}\\n\".format(\"patientId\",\t\"PredictionString\"))\n",
        "      for image_id in tqdm(image_fps): \n",
        "        ds = pydicom.read_file(image_id)\n",
        "        image = ds.pixel_array\n",
        "          \n",
        "        # If grayscale. Convert to RGB for consistency.\n",
        "        if len(image.shape) != 3 or image.shape[2] != 3:\n",
        "            image = np.stack((image,) * 3, -1)\n",
        "        image, window, scale, padding, crop = utils.resize_image(image,\n",
        "                                                                 min_dim=config.IMAGE_MIN_DIM,\n",
        "                min_scale=config.IMAGE_MIN_SCALE,\n",
        "                max_dim=config.IMAGE_MAX_DIM,\n",
        "                mode=config.IMAGE_RESIZE_MODE)\n",
        "            \n",
        "        patient_id = os.path.splitext(os.path.basename(image_id))[0]\n",
        "\n",
        "        results = model.detect([image])\n",
        "        r = results[0]\n",
        "\n",
        "        out_str = \"\"\n",
        "        out_str += patient_id \n",
        "        assert( len(r['rois']) == len(r['class_ids']) == len(r['scores']) )\n",
        "        if len(r['rois']) == 0: \n",
        "            pass\n",
        "        else: \n",
        "            num_instances = len(r['rois'])\n",
        "            out_str += \",\"\n",
        "            for i in range(num_instances): \n",
        "                if r['scores'][i] > min_conf: \n",
        "                    out_str += ' '\n",
        "                    out_str += str(round(r['scores'][i], 2))\n",
        "                    out_str += ' '\n",
        "\n",
        "                    # x1, y1, width, height \n",
        "                    x1 = r['rois'][i][1]\n",
        "                    y1 = r['rois'][i][0]\n",
        "                    width = r['rois'][i][3] - x1 \n",
        "                    height = r['rois'][i][2] - y1 \n",
        "                    bboxes_str = \"{} {} {} {}\".format(x1*resize_factor, y1*resize_factor, \\\n",
        "                                                      width*resize_factor, height*resize_factor)    \n",
        "                    out_str += bboxes_str\n",
        "\n",
        "        file.write(out_str+\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4yrGj0S1sIef",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Generate predictions"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WipC8GxF3UJ2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if gen_preds:\n",
        "  sample_submission_fp = 'MRCNN_submission.csv'\n",
        "  predict(test_image_fps, \n",
        "          filepath=sample_submission_fp, \n",
        "          min_conf=0.98)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ErHoKsgb3ZMC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if gen_preds:\n",
        "  output = pd.read_csv(sample_submission_fp)\n",
        "  print (output.head(10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lsLzJSdv4ygK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Save submission files to Google Drive"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Rg_UWwods9py",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_dir = '{}'.format('./')\n",
        "if gen_preds and colab_mode:\n",
        "  googledrive_save(file_name = sample_submission_fp,\n",
        "             file_dir = file_dir,\n",
        "             upload = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6N9ERmX2sbPn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Display a few test image predictions"
      ]
    },
    {
      "metadata": {
        "id": "Su-HievAfz8E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def visualize(): \n",
        "    image_id = random.choice(test_image_fps)\n",
        "    ds = pydicom.read_file(image_id)\n",
        "    \n",
        "    # original image \n",
        "    image = ds.pixel_array\n",
        "    \n",
        "    # assume square image \n",
        "    resize_factor = ORIG_SIZE / config.IMAGE_SHAPE[0]\n",
        "    \n",
        "    # If grayscale. Convert to RGB for consistency.\n",
        "    if len(image.shape) != 3 or image.shape[2] != 3:\n",
        "        image = np.stack((image,) * 3, -1) \n",
        "    resized_image, window, scale, padding, crop = utils.resize_image(\n",
        "        image,\n",
        "        min_dim=config.IMAGE_MIN_DIM,\n",
        "        min_scale=config.IMAGE_MIN_SCALE,\n",
        "        max_dim=config.IMAGE_MAX_DIM,\n",
        "        mode=config.IMAGE_RESIZE_MODE)\n",
        "\n",
        "    patient_id = os.path.splitext(os.path.basename(image_id))[0]\n",
        "    print(patient_id)\n",
        "\n",
        "    results = model.detect([resized_image])\n",
        "    r = results[0]\n",
        "    for bbox in r['rois']: \n",
        "        print(bbox)\n",
        "        x1 = int(bbox[1] * resize_factor)\n",
        "        y1 = int(bbox[0] * resize_factor)\n",
        "        x2 = int(bbox[3] * resize_factor)\n",
        "        y2 = int(bbox[2]  * resize_factor)\n",
        "        cv2.rectangle(image, (x1,y1), (x2,y2), (77, 255, 9), 3, 1)\n",
        "        width = x2 - x1 \n",
        "        height = y2 - y1 \n",
        "        print(\"x {} y {} h {} w {}\".format(x1, y1, width, height))\n",
        "    plt.figure() \n",
        "    plt.imshow(image, cmap=plt.cm.gist_gray)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WgF43OjjsVTj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if gen_preds:\n",
        "  visualize()\n",
        "  visualize()\n",
        "  visualize()\n",
        "  visualize()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LLytabW93d-A",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if gen_preds and download_submission and colab_mode:\n",
        "  from google.colab import files\n",
        "  files.download(sample_submission_fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WsPxfqxb6_Wd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}