{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Pneumothorax_MaskRCNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "7c1fce19a11f95416168ced03c2c70fa818b21a5",
        "colab_type": "text",
        "id": "KBeAf8WgaeSk"
      },
      "source": [
        "# [Pneumothorax segmentation](https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation)\n",
        "\n",
        "## Author:\n",
        "## [Dr. Rahul Remanan](https://www.linkedin.com/in/rahulremanan)\n",
        "\n",
        "## References:\n",
        "\n",
        "### [Mask RCNN pneumothorax segmentation using transfer learning, Keras implementation](https://www.kaggle.com/hmendonca/top-mask-rcnn-and-coco-transfer-learning)\n",
        "\n",
        "### Pre-trained weights using [COCO dataset](http://cocodataset.org)\n",
        "\n",
        "### [Keras implementation of Mask RCNN](https://github.com/matterport/Mask_RCNN/tree/master/samples/balloon)\n",
        "\n",
        "#### Note: This notebook is designed to run on [Google Colab](https://colab.research.google.com/) or a cloud environment with [rClone](https://rclone.org/)\n",
        "\n",
        "## [Launch this notebook in Google CoLab](https://colab.research.google.com/github/rahulremanan/HIMA/blob/master/examples/Notebooks/12_Kaggle_Pneumothorax_segementation/Pneumothorax_MaskRCNN.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M1h2KzzA33yi",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "coKbZkg0Kg8m",
        "colab": {}
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0ujqXe1fJM0F",
        "colab": {}
      },
      "source": [
        "setup = False\n",
        "training_mode = True\n",
        "positive_sampling = False\n",
        "stage_2= True\n",
        "reload_weights = True\n",
        "debug = False\n",
        "download_rawData = False\n",
        "retrain_network = random.SystemRandom().choice([True,\n",
        "                                                False])\n",
        "weights_averaging = True\n",
        "use_best_epoch = False\n",
        "transfer_learning = False\n",
        "colab_mode = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rn8oTexTDH6y",
        "colab": {}
      },
      "source": [
        "DETECTOR_THRESHOLD = 0.95\n",
        "EPOCHS = 15\n",
        "DATA_DIR = '/home/rahulremanan/'\n",
        "DATA_FILENAME = 'siim-train-test.zip'\n",
        "DATA_FILE = os.path.join(DATA_DIR, DATA_FILENAME)\n",
        "ROOT_DIR = '/home/rahulremanan/'\n",
        "GOOGLE_DRIVE = '/home/rahulremanan/My\\ Drive'\n",
        "RCLONE_DRIVE = 'gdrive'\n",
        "NETWORK_ID = random.SystemRandom().choice([#'MaskRCNN_ResNet50',\n",
        "                                           'MaskRCNN_ResNet100'])\n",
        "NOTEBOOK_ID = 'pneumothorax_{}'.format(NETWORK_ID)\n",
        "WEIGHTS_FILENAME = '{}.h5'.format(NOTEBOOK_ID)\n",
        "WEIGHTS_FILE = os.path.join(DATA_DIR, WEIGHTS_FILENAME)\n",
        "AVERAGED_WEIGHTS_FILENAME = '{}_averaged.h5'.format(NOTEBOOK_ID)\n",
        "AVERAGED_WEIGHTS_FILE = '{}/{}'.format(DATA_DIR,\n",
        "                                       AVERAGED_WEIGHTS_FILENAME)\n",
        "SUBMISSION_FILENAME = 'pneumothorax_stage_2_sample_submission.csv' if stage_2 else 'sample_submission_pneumothorax_segmentation.csv'\n",
        "SUBMISSION_FILE = os.path.join(DATA_DIR, SUBMISSION_FILENAME)\n",
        "STAGE_1_TEST_FILENAME = 'pneumothorax_segmentation_dicom_test.zip'\n",
        "STAGE_1_TRAIN_FILENAME = 'pneumothorax_segmentation_dicom_train.zip'\n",
        "STAGE_2_TEST_FILENAME = 'pneumothorax_stage_2_test.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kKzDOVxvucAy",
        "colab": {}
      },
      "source": [
        "if not (NETWORK_ID == 'MaskRCNN_ResNet50' or NETWORK_ID == 'MaskRCNN_ResNet100'):\n",
        "  raise Exception('NETWORK_ID should be either: {} or {} ...'.format('MaskRCNN_ResNet100', \n",
        "                                                                     'MaskRCNN_ResNet50'))\n",
        "print ('Mask-RCNN network type: {} ...'.format(NETWORK_ID))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wrJmOcWzDF_s",
        "colab": {}
      },
      "source": [
        "if setup and colab_mode:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wEgFox37DNJf",
        "colab": {}
      },
      "source": [
        "if setup:\n",
        "  ! pip3 install pydicom retrying google-auth sklearn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-KGxvBASv1_l",
        "colab": {}
      },
      "source": [
        "\"\"\"Script to download all instances in a DICOM Store.\"\"\"\n",
        "import os\n",
        "import posixpath\n",
        "from concurrent import futures\n",
        "from retrying import retry\n",
        "import google.auth\n",
        "from google.auth.transport.requests import AuthorizedSession\n",
        "\n",
        "# URL of CHC API\n",
        "CHC_API_URL = 'https://healthcare.googleapis.com/v1beta1'\n",
        "PROJECT_ID = 'kaggle-siim-healthcare'\n",
        "REGION = 'us-central1'\n",
        "DATASET_ID = 'siim-pneumothorax'\n",
        "TRAIN_DICOM_STORE_ID = 'dicom-images-train'\n",
        "TEST_DICOM_STORE_ID = 'dicom-images-test'\n",
        "\n",
        "\n",
        "@retry(wait_exponential_multiplier=1000, wait_exponential_max=10000)\n",
        "def download_instance(dicom_web_url, dicom_store_id, study_uid, series_uid,\n",
        "                      instance_uid, credentials):\n",
        "    \"\"\"Downloads a DICOM instance and saves it under the current folder.\"\"\"\n",
        "    instance_url = posixpath.join(dicom_web_url, 'studies', study_uid, 'series',\n",
        "                                  series_uid, 'instances', instance_uid)\n",
        "    authed_session = AuthorizedSession(credentials)\n",
        "    response = authed_session.get(\n",
        "        instance_url, headers={'Accept': 'application/dicom; transfer-syntax=*'})\n",
        "    file_path = posixpath.join(dicom_store_id, study_uid, series_uid,\n",
        "                               instance_uid)\n",
        "    filename = '%s.dcm' % file_path\n",
        "    if not os.path.exists(filename):\n",
        "        os.makedirs(os.path.dirname(filename))\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "\n",
        "\n",
        "def download_all_instances(dicom_store_id, credentials):\n",
        "    \"\"\"Downloads all DICOM instances in the specified DICOM store.\"\"\"\n",
        "    # Get a list of all instances.\n",
        "    dicom_web_url = posixpath.join(CHC_API_URL, 'projects', PROJECT_ID,\n",
        "                                   'locations', REGION, 'datasets', DATASET_ID,\n",
        "                                   'dicomStores', dicom_store_id, 'dicomWeb')\n",
        "    qido_url = posixpath.join(dicom_web_url, 'instances')\n",
        "    authed_session = AuthorizedSession(credentials)\n",
        "    response = authed_session.get(qido_url, params={'limit': '15000'})\n",
        "    if response.status_code != 200:\n",
        "        print(response.text)\n",
        "        return\n",
        "    content = response.json()\n",
        "    # DICOM Tag numbers\n",
        "    study_instance_uid_tag = '0020000D'\n",
        "    series_instance_uid_tag = '0020000E'\n",
        "    sop_instance_uid_tag = '00080018'\n",
        "    value_key = 'Value'\n",
        "    with futures.ThreadPoolExecutor() as executor:\n",
        "        future_to_study_uid = {}\n",
        "        for instance in content:\n",
        "            study_uid = instance[study_instance_uid_tag][value_key][0]\n",
        "            series_uid = instance[series_instance_uid_tag][value_key][0]\n",
        "            instance_uid = instance[sop_instance_uid_tag][value_key][0]\n",
        "            future = executor.submit(download_instance, dicom_web_url, dicom_store_id,\n",
        "                                     study_uid, series_uid, instance_uid, credentials)\n",
        "            future_to_study_uid[future] = study_uid\n",
        "        processed_count = 0\n",
        "        for future in futures.as_completed(future_to_study_uid):\n",
        "            try:\n",
        "                future.result()\n",
        "                processed_count += 1\n",
        "                if not processed_count % 100 or processed_count == len(content):\n",
        "                    print('Processed instance %d out of %d' %\n",
        "                          (processed_count, len(content)))\n",
        "            except Exception as e:\n",
        "                print('Failed to download a study. UID: %s \\n exception: %s' %\n",
        "                      (future_to_study_uid[future], e))\n",
        "\n",
        "\n",
        "def download_dicomData(argv=None):\n",
        "    credentials, _ = google.auth.default()\n",
        "    print('Downloading all instances in %s DICOM store' % TRAIN_DICOM_STORE_ID)\n",
        "    download_all_instances(TRAIN_DICOM_STORE_ID, credentials)\n",
        "    print('Downloading all instances in %s DICOM store' % TEST_DICOM_STORE_ID)\n",
        "    download_all_instances(TEST_DICOM_STORE_ID, credentials)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CS4-vRWtv2JW",
        "colab": {}
      },
      "source": [
        "if download_rawData and not(os.path.exists('./pneumothorax_segmentation_dicom_train.zip')):\n",
        "  ! gcloud auth application-default login\n",
        "  download_dicomData()\n",
        "  ! zip -r -q ./pneumothorax_segmentation_dicom_test.zip ./dicom-images-test/\n",
        "  ! zip -r -q ./pneumothorax_segmentation_dicom_s_train.zip ./dicom-images-train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1t2hr_R38FOS",
        "colab": {}
      },
      "source": [
        "if download_rawData and os.path.exists('./pneumothorax_segmentation_dicom_test.zip') and os.path.exists('./pneumothorax_segmentation_dicom_train.zip'):\n",
        "  ! cp ./pneumothorax_segmentation_dicom_test.zip {GOOGLE_DRIVE}/\n",
        "  ! cp ./pneumothorax_segmentation_dicom_train.zip {GOOGLE_DRIVE}/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hjT3Hx8zDh-W",
        "colab": {}
      },
      "source": [
        "if download_rawData and not stage_2 and colab_mode:\n",
        "  ! kaggle datasets download -d seesee/siim-train-test\n",
        "  ! cp {DATA_FILE} {GOOGLE_DRIVE}/\n",
        "elif setup and not stage_2 and colab_mode:\n",
        "  ! cp {GOOGLE_DRIVE}/{DATA_FILENAME} {DATA_DIR}\n",
        "  print ('Downloaded Stage 1 train and test data ...')\n",
        "  ! unzip -q {DATA_FILE}\n",
        "  print ('Unzipped Stage 1 train and test data ...')\n",
        "elif setup and stage_2 and colab_mode:\n",
        "  ! cp {GOOGLE_DRIVE}/{STAGE_1_TEST_FILENAME} {DATA_DIR}\n",
        "  ! cp {GOOGLE_DRIVE}/{STAGE_1_TRAIN_FILENAME} {DATA_DIR}\n",
        "  ! cp {GOOGLE_DRIVE}/{STAGE_2_TEST_FILENAME} {DATA_DIR}\n",
        "  print ('Downloaded Stage 2 train and test data ...')\n",
        "elif setup and stage_2:\n",
        "  ! rclone copy {RCLONE_DRIVE}:{STAGE_1_TEST_FILENAME} {DATA_DIR}\n",
        "  ! rclone copy {RCLONE_DRIVE}:{STAGE_1_TRAIN_FILENAME} {DATA_DIR}\n",
        "  ! rclone copy {RCLONE_DRIVE}:{STAGE_2_TEST_FILENAME} {DATA_DIR}  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64PZBVf_T7Je",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if setup and stage_2:\n",
        "  ! unzip -q {DATA_DIR}/{STAGE_1_TEST_FILENAME} -d {DATA_DIR}\n",
        "  ! unzip -q {DATA_DIR}/{STAGE_1_TRAIN_FILENAME} -d {DATA_DIR}\n",
        "  ! cp -r {DATA_DIR}/dicom-images-test/1.* {DATA_DIR}/dicom-images-train/\n",
        "  ! rm -r {DATA_DIR}/dicom-images-test/\n",
        "  print ('Processed train data ...')\n",
        "  ! mkdir {DATA_DIR}/dicom-images-test/\n",
        "  ! unzip -q {DATA_DIR}/{STAGE_2_TEST_FILENAME} -d {DATA_DIR}/dicom-images-test/\n",
        "  print ('Processed test data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6AMDQGy08t57",
        "colab": {}
      },
      "source": [
        "if setup or reload_weights or not os.path.exists(WEIGHTS_FILE):\n",
        "    if colab_mode:\n",
        "      ! cp {GOOGLE_DRIVE}/{WEIGHTS_FILENAME} {DATA_DIR}\n",
        "    else:\n",
        "      ! rclone copy {RCLONE_DRIVE}:{WEIGHTS_FILENAME} {DATA_DIR}\n",
        "print ('Downloaded {} weights: {} magically from the clouds ...'.format(NETWORK_ID, WEIGHTS_FILENAME))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "40c67b3ff0fa04587dec508363308adaa3ceaf34",
        "colab_type": "code",
        "id": "4kjcC6QqywWl",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pydicom\n",
        "from imgaug import augmenters as iaa\n",
        "from tqdm import tqdm\n",
        "import pandas as pd \n",
        "import glob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dYhQusisEEqt",
        "colab": {}
      },
      "source": [
        "def mask2rle(img, width, height):\n",
        "    rle = []\n",
        "    lastColor = 0;\n",
        "    currentPixel = 0;\n",
        "    runStart = -1;\n",
        "    runLength = 0;\n",
        "\n",
        "    for x in range(width):\n",
        "        for y in range(height):\n",
        "            currentColor = img[x][y]\n",
        "            #print (currentColor)\n",
        "            if currentColor != lastColor:\n",
        "                if currentColor == 255:\n",
        "                    runStart = currentPixel;\n",
        "                    runLength = 1;\n",
        "                else:\n",
        "                    rle.append(str(runStart));\n",
        "                    rle.append(str(runLength));\n",
        "                    runStart = -1;\n",
        "                    runLength = 0;\n",
        "                    currentPixel = 0;\n",
        "            elif runStart > -1:\n",
        "                runLength += 1\n",
        "            lastColor = currentColor;\n",
        "            currentPixel+=1;\n",
        "\n",
        "    return \" \".join(rle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RFWSk12FEE91",
        "colab": {}
      },
      "source": [
        "def rle2mask(rle, width, height):\n",
        "    mask= np.zeros(width* height)\n",
        "    array = []\n",
        "    for item in rle.split():\n",
        "      try:\n",
        "        array.append(int(item))\n",
        "      except:\n",
        "        pass\n",
        "    array = np.asarray(array, dtype=np.int64)\n",
        "\n",
        "    starts = array[0::2]\n",
        "    lengths = array[1::2]\n",
        "\n",
        "    current_position = 0\n",
        "    for index, start in enumerate(starts):\n",
        "        current_position += start\n",
        "        try:\n",
        "          mask[current_position:current_position+lengths[index]] = 255\n",
        "        except:\n",
        "          pass\n",
        "          #print ('An exception occured')\n",
        "        try:\n",
        "          current_position += lengths[index]\n",
        "        except:\n",
        "          pass\n",
        "          #print ('Another exception occured')\n",
        "    \n",
        "    return mask.reshape(width, height)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "6e5764759e6a0a9b698b44645658f66873edd807",
        "colab_type": "code",
        "id": "yP0XLJx_x_6o",
        "colab": {}
      },
      "source": [
        "!ls {DATA_DIR}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "576df4c47a23d08b1bdb384245e09aa69f88bbd3",
        "colab_type": "text",
        "id": "kdYzLq1zfKL4"
      },
      "source": [
        "### Install Matterport's [Keras implementation of Mask-RCNN](https://github.com/matterport/Mask_RCNN) model from github."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "b37d22551d332f0f7b722cc7204eb614524b6c21",
        "colab_type": "code",
        "id": "KgllzLnDr7kF",
        "colab": {}
      },
      "source": [
        "if setup:  \n",
        "  # !pip install 'keras==2.1.6' --force-reinstall\n",
        "  !git clone https://www.github.com/matterport/Mask_RCNN.git\n",
        "  os.chdir('Mask_RCNN')\n",
        "  #!python setup.py -q install\n",
        "  !ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "3acbbbe055b6a409d3c50ae0f893acf51b5ae7ba",
        "colab_type": "code",
        "id": "-KZXyWwhzOVU",
        "colab": {}
      },
      "source": [
        "# Import Mask RCNN\n",
        "sys.path.append(os.path.join(ROOT_DIR, 'Mask_RCNN'))  # To find local version of the library\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import utils\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import visualize\n",
        "from mrcnn.model import log"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "50089cc61791871cdf6a5c0037dc4f28b7b7d7cc",
        "colab_type": "code",
        "id": "FghMmiMjzOX2",
        "colab": {}
      },
      "source": [
        "train_dicom_dir = os.path.join(DATA_DIR, 'dicom-images-train')\n",
        "test_dicom_dir = os.path.join(DATA_DIR, 'dicom-images-test')\n",
        "\n",
        "# count files\n",
        "!ls -m {train_dicom_dir} | wc\n",
        "!ls -m {test_dicom_dir} | wc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "f108beef7838be8a64dd512d395c5dc0ad952790",
        "colab_type": "text",
        "id": "0kZEbs61C1oJ"
      },
      "source": [
        "### Download COCO pre-trained weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "c3ee0cd0ee0b1defdec97b94bc736587c1f7631f",
        "colab_type": "code",
        "id": "eXPeDxabC1oM",
        "colab": {}
      },
      "source": [
        "if setup and transfer_learning:  \n",
        "  !wget --quiet https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\n",
        "  !ls -lh mask_rcnn_coco.h5\n",
        "\n",
        "COCO_WEIGHTS_PATH = \"mask_rcnn_coco.h5\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "032cc5fe4baa051108106675e6ca4f4fdb2846ed",
        "colab_type": "text",
        "id": "gj-tvDvEaDiC"
      },
      "source": [
        "### Some setup functions and classes for Mask-RCNN\n",
        "\n",
        "- dicom_fps is a list of the dicom image path and filenames \n",
        "- image_annotions is a dictionary of the annotations keyed by the filenames\n",
        "- parsing the dataset returns a list of the image filenames and the annotations dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "dfcffc4eaa94a41497717851dee9f702d8a2a73b",
        "colab_type": "code",
        "id": "_SfzTa-1zOck",
        "colab": {}
      },
      "source": [
        "# The following parameters have been selected to reduce running time for demonstration purposes \n",
        "# These are not optimal\n",
        "\n",
        "IMAGE_DIM = (1024, 1024)\n",
        "\n",
        "class DetectorConfig(Config):    \n",
        "    # Give the configuration a recognizable name  \n",
        "    NAME = NOTEBOOK_ID\n",
        "    \n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 2\n",
        "    \n",
        "    BACKBONE = 'resnet50' if NETWORK_ID.lower() == 'maskRCNN_ResNet50'.lower() else 'resnet101'\n",
        "    \n",
        "    BACKBONE_STRIDES = [4, 8, 16, 32, 64]\n",
        "    NUM_CLASSES = 2  # background and pneumothorax classes\n",
        "    \n",
        "    IMAGE_MIN_DIM = IMAGE_DIM[0]\n",
        "    IMAGE_MAX_DIM = IMAGE_DIM[1]\n",
        "    \n",
        "    RPN_ANCHOR_SCALES = random.SystemRandom().choice([(64, 128, 256, 512, 1024),\n",
        "                                                      (16, 32, 64, 128),\n",
        "                                                      (8, 16, 32, 64)])\n",
        "    \n",
        "    TRAIN_ROIS_PER_IMAGE = random.SystemRandom().choice([64,\n",
        "                                                         128,\n",
        "                                                         196])\n",
        "    MAX_GT_INSTANCES = 16\n",
        "    DETECTION_MAX_INSTANCES = 10 \n",
        "    DETECTION_MIN_CONFIDENCE = 0.6 if NETWORK_ID.lower() == 'maskRCNN_ResNet50'.lower() else DETECTOR_THRESHOLD\n",
        "    DETECTION_NMS_THRESHOLD = 0.1 #0.0\n",
        "\n",
        "    STEPS_PER_EPOCH = 15 if debug else 6884\n",
        "    VALIDATION_STEPS = 10 if debug else 100\n",
        "    \n",
        "    ## balance out losses\n",
        "    LOSS_WEIGHTS = {\n",
        "        \"rpn_class_loss\": 30.0,\n",
        "        \"rpn_bbox_loss\": 0.6,\n",
        "        \"mrcnn_class_loss\": 6.0,\n",
        "        \"mrcnn_bbox_loss\": 0.1, #1.0\n",
        "        \"mrcnn_mask_loss\": 2.4\n",
        "    }\n",
        "\n",
        "config = DetectorConfig()\n",
        "config.display()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "6136132b1f1b311e297d9432772ec4a81230924f",
        "colab_type": "code",
        "id": "f0hmgFquC1om",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.cm import get_cmap\n",
        "from skimage.segmentation import mark_boundaries\n",
        "from skimage.util import montage\n",
        "from skimage.morphology import binary_opening, disk, label\n",
        "import gc; gc.enable() # memory is tight\n",
        "\n",
        "montage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n",
        "\n",
        "def multi_rle_encode(img, **kwargs):\n",
        "    ''' Encode disconnected regions as separated masks\n",
        "    '''\n",
        "    labels = label(img)\n",
        "    if img.ndim > 2:\n",
        "        return [rle2mask(np.sum(labels==k, axis=2), **kwargs) for k in np.unique(labels[labels>0])]\n",
        "    else:\n",
        "        return [rle2mask(labels==k, **kwargs) for k in np.unique(labels[labels>0])]\n",
        "\n",
        "def masks_as_image(rle_list, shape=IMAGE_DIM):\n",
        "    # Take the individual masks and create a single mask array\n",
        "    all_masks = np.zeros(shape, dtype=np.uint8)\n",
        "    for mask in rle_list:\n",
        "        if isinstance(mask, str) and mask != '-1':\n",
        "            all_masks |= rle2mask(mask, shape[0], shape[1]).T.astype(bool)\n",
        "    return all_masks\n",
        "\n",
        "def masks_as_color(rle_list, shape=IMAGE_DIM):\n",
        "    # Take the individual masks and create a color mask array\n",
        "    all_masks = np.zeros(shape, dtype=np.float)\n",
        "    scale = lambda x: (len(rle_list)+x+1) / (len(rle_list)*2) ## scale the heatmap image to shift \n",
        "    for i,mask in enumerate(rle_list):\n",
        "        if isinstance(mask, str) and mask != '-1':\n",
        "            all_masks[:,:] += scale(i) * rle2mask(mask, shape[0], shape[1]).T\n",
        "    return all_masks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d3e05fa1a38c637fa228acd62b92dd41117a6672",
        "colab_type": "code",
        "id": "dGmgFuBxC1ou",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_glob = f'{train_dicom_dir}/*/*/*.dcm'\n",
        "if stage_2:\n",
        "  test_glob = f'{test_dicom_dir}/*.dcm'\n",
        "else:  \n",
        "  test_glob = f'{test_dicom_dir}/*/*/*.dcm'\n",
        "\n",
        "exclude_list = []\n",
        "train_names = [f for f in sorted(glob.glob(train_glob)) if f not in exclude_list]\n",
        "test_names = [f for f in sorted(glob.glob(test_glob)) if f not in exclude_list]\n",
        "\n",
        "print(len(train_names), len(test_names))\n",
        "# print(train_names[0], test_names[0])\n",
        "# !ls -l {os.path.join(train_dicom_dir, train_names[0])}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0Sj9U-7BGsGG",
        "colab": {}
      },
      "source": [
        "STAGE_2_SAMPLE_SUBMISSION = 'pneumothorax_stage_2_sample_submission.csv'\n",
        "if stage_2 and setup and colab_mode:\n",
        "  ! cp {GOOGLE_DRIVE}/{STAGE_2_SAMPLE_SUBMISSION} {DATA_DIR}\n",
        "elif stage_2 and setup:\n",
        "  ! rclone copy {RCLONE_DRIVE}:{STAGE_2_SAMPLE_SUBMISSION} {DATA_DIR}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdQ7Nk7jT7L6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STAGE_2_SEGMENTATION_FILE = 'pneumothorax_stage_2_train.csv.zip'\n",
        "if stage_2 and setup and colab_mode:\n",
        "  ! cp {GOOGLE_DRIVE}/{STAGE_2_SEGMENTATION_FILE} {DATA_DIR}\n",
        "elif stage_2 and setup:\n",
        "  ! rclone copy {RCLONE_DRIVE}:{STAGE_2_SEGMENTATION_FILE} {DATA_DIR}\n",
        "print ('Downloaded segmentation data ...')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HMNAXCgT7MD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if stage_2 and setup:\n",
        "  ! unzip -q {DATA_DIR}/{STAGE_2_SEGMENTATION_FILE} -d {DATA_DIR}\n",
        "  ! chmod 777 {DATA_DIR}/{STAGE_2_SEGMENTATION_FILE}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "3050fa77026411ffdc27bed4a9b667ec0467e4ce",
        "colab_type": "code",
        "id": "ESsemcWKC1o5",
        "colab": {}
      },
      "source": [
        "# training dataset\n",
        "if stage_2:\n",
        "  SEGMENTATION_DATA_FILENAME = 'stage_2_train.csv'\n",
        "  print ('Reading from Stage 2 segmentation data ...')\n",
        "else:\n",
        "  SEGMENTATION_DATA_FILENAME = 'train-rle.csv'\n",
        "  print ('Reading from Stage 1 segmentation data ...')\n",
        "  \n",
        "SEGMENTATION = os.path.join(DATA_DIR, SEGMENTATION_DATA_FILENAME)\n",
        "print (SEGMENTATION)\n",
        "anns = pd.read_csv(SEGMENTATION)\n",
        "anns.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NX9KZTMtC1pE",
        "colab": {}
      },
      "source": [
        "# get rid of damn space in column name\n",
        "anns.columns = ['ImageId', 'EncodedPixels']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "904636402355a305f7b2ccacb8cc55d52151d2e6",
        "colab_type": "code",
        "id": "2XLPtpVoC1pM",
        "colab": {}
      },
      "source": [
        "# discard healthy patients\n",
        "unique_anns = anns[anns.EncodedPixels != '-1' if stage_2 else ' -1'].ImageId.unique().tolist()\n",
        "print('Number of unique annotations: ', len(unique_anns))\n",
        "train_names = [fp for fp in train_names if fp.split('/')[-1][:-4] in unique_anns]  if positive_sampling else [fp for fp in train_names if fp.split('/')[-1][:-4] in anns.ImageId.unique().tolist()]## override only with pneumothorax\n",
        "print ('Total number of training images: {} ...'.format(len(train_names)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "w_kzsdhZMSqg"
      },
      "source": [
        "## Create train-validation split:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "udzwrDAXMQ7y",
        "colab": {}
      },
      "source": [
        "test_size = config.VALIDATION_STEPS * config.IMAGES_PER_GPU\n",
        "image_fps_train, image_fps_val = train_test_split(train_names, \n",
        "                                                  test_size=test_size, \n",
        "                                                  random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sL_bJpvsKG7Y",
        "colab": {}
      },
      "source": [
        "test_image_fps = test_names\n",
        "\n",
        "if debug:\n",
        "    print('DEBUG subsampling from:', len(image_fps_train), len(image_fps_val), len(test_image_fps))\n",
        "    image_fps_train = image_fps_train[:150]\n",
        "    image_fps_val = image_fps_val[:150]\n",
        "    test_image_fps = test_names[:150]\n",
        "    \n",
        "print(len(image_fps_train), len(image_fps_val), len(test_image_fps))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "52bd3ffbdde0173a363055482d675da51c2aba99",
        "colab_type": "code",
        "id": "8EBVA1M60yAj",
        "colab": {}
      },
      "source": [
        "class DetectorDataset(utils.Dataset):\n",
        "    \"\"\"Dataset class for training our dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, image_fps, image_annotations, orig_height, orig_width):\n",
        "        super().__init__(self)\n",
        "        \n",
        "        # Add classes\n",
        "        self.add_class('pneumothorax', 1, 'Pneumothorax')\n",
        "        \n",
        "        # add images \n",
        "        for i, fp in enumerate(image_fps):\n",
        "            image_id = fp.split('/')[-1][:-4]\n",
        "            annotations = image_annotations.query(f\"ImageId=='{image_id}'\")['EncodedPixels']\n",
        "            self.add_image('pneumothorax', image_id=i, path=fp, \n",
        "                           annotations=annotations, \n",
        "                           orig_height=orig_height, \n",
        "                           orig_width=orig_width)\n",
        "            \n",
        "    def image_reference(self, image_id):\n",
        "        info = self.image_info[image_id]\n",
        "        return info['path']\n",
        "\n",
        "    def load_image(self, image_id):\n",
        "        info = self.image_info[image_id]\n",
        "        fp = info['path']\n",
        "        ds = pydicom.read_file(fp)\n",
        "        image = ds.pixel_array\n",
        "        # If grayscale. Convert to RGB for consistency.\n",
        "        if len(image.shape) != 3 or image.shape[2] != 3:\n",
        "            image = np.stack((image,) * 3, -1)\n",
        "        return image\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        info = self.image_info[image_id]\n",
        "        annotations = info['annotations']\n",
        "#         print(image_id, annotations)\n",
        "        count = len(annotations)\n",
        "        if count == 0 or (count == 1 and annotations.values[0] == '-1' if stage_2 else ' -1'): # empty annotation\n",
        "            mask = np.zeros((info['orig_height'], info['orig_width'], 1), dtype=np.uint8)\n",
        "            class_ids = np.zeros((1,), dtype=np.int32)\n",
        "        else:\n",
        "            mask = np.zeros((info['orig_height'], info['orig_width'], count), dtype=np.uint8)\n",
        "            class_ids = np.zeros((count,), dtype=np.int32)\n",
        "            for i, a in enumerate(annotations):\n",
        "                mask[:, :, i] = rle2mask(a, info['orig_height'], info['orig_width']).T\n",
        "                class_ids[i] = 1\n",
        "        return mask.astype(np.bool), class_ids.astype(np.int32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "1cb852e262b69d348743767d675573368ab672c9",
        "colab_type": "text",
        "id": "9RlMo04ckd98"
      },
      "source": [
        "### Examine the annotation data, parse the dataset, and view dicom fields"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "7aebc88f910b232e3b8759421914a007c6ffed94",
        "colab_type": "code",
        "id": "Mxz-pNbt5txY",
        "colab": {}
      },
      "source": [
        "image_fps, image_annotations = train_names, anns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cfyw2GFbC1p5",
        "colab": {}
      },
      "source": [
        "ds = pydicom.read_file(image_fps[0]) # read dicom image from filepath \n",
        "image = ds.pixel_array # get image array\n",
        "ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "74277ae9af4a3b044e62b664d10d76b23848bb43",
        "colab_type": "code",
        "id": "gYNSd1AhRqOV",
        "colab": {}
      },
      "source": [
        "# Original image size: 1024 x 1024\n",
        "ORIG_SIZE = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "a5143c19dc22bc00d318a3b28cb7e13c7fbacc8a",
        "colab_type": "text",
        "id": "9KUvacUbgiEX"
      },
      "source": [
        "### Create and prepare the training dataset using the DetectorDataset class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "86c3333d4dfb8b7d00ce1f401693d0df4e6254e1",
        "colab_type": "code",
        "id": "jwMkhotP0yFf",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "# prepare the training dataset\n",
        "dataset_train = DetectorDataset(image_fps_train, \n",
        "                                image_annotations, \n",
        "                                ORIG_SIZE, ORIG_SIZE)\n",
        "dataset_train.prepare()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "313347d838fa8321a714858c8073f98c50c5be26",
        "colab_type": "code",
        "id": "K1TkWuGP0yHl",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "# prepare the validation dataset\n",
        "dataset_val = DetectorDataset(image_fps_val, \n",
        "                              image_annotations, \n",
        "                              ORIG_SIZE, ORIG_SIZE)\n",
        "dataset_val.prepare()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "600a8135d4e382f62797d69e9358f5697873c8f9",
        "colab_type": "text",
        "id": "pEXEt8fygWuC"
      },
      "source": [
        "### Display a random image with bounding boxes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "491b78ec96d28fcdbbf8e2d7f9320a05d64c9249",
        "colab_type": "code",
        "id": "4xwsrf9G1lHR",
        "colab": {}
      },
      "source": [
        "# Load and display random sample and their bounding boxes\n",
        "\n",
        "class_ids = [0]\n",
        "while class_ids[0] == 0:  ## look for a mask\n",
        "    image_id = random.choice(dataset_val.image_ids)\n",
        "    image_fp = dataset_val.image_reference(image_id)\n",
        "    image = dataset_val.load_image(image_id)\n",
        "    mask, class_ids = dataset_val.load_mask(image_id)\n",
        "\n",
        "print(image.shape)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "masked = np.zeros(image.shape[:2])\n",
        "for i in range(mask.shape[2]):\n",
        "    masked += image[:, :, 0] * mask[:, :, i]\n",
        "plt.imshow(masked, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "print(image_fp)\n",
        "print(class_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "342b6008873fe7a6a0870a712ee47a87f0d2828d",
        "colab_type": "text",
        "id": "ustAIH78hZI_"
      },
      "source": [
        "### Image Augmentation. Try finetuning some variables to custom values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "4ab9d6086ce611a46f189c047956c43b29783e6d",
        "colab_type": "code",
        "id": "STZnQTE61lME",
        "colab": {}
      },
      "source": [
        "# Image augmentation (light but constant)\n",
        "augmentation_1 = iaa.Sequential([\n",
        "    iaa.OneOf([ ## geometric transform\n",
        "        iaa.Affine(\n",
        "            scale={\"x\": (0.98, 1.02), \"y\": (0.98, 1.04)},\n",
        "            translate_percent={\"x\": (-0.02, 0.02), \"y\": (-0.04, 0.04)},\n",
        "            rotate=(-2, 2),\n",
        "            shear=(-1, 1),\n",
        "        ),\n",
        "        iaa.PiecewiseAffine(scale=(0.001, 0.025)),\n",
        "    ]),\n",
        "    iaa.OneOf([ ## brightness or contrast\n",
        "        iaa.Multiply((0.9, 1.1)),\n",
        "        iaa.ContrastNormalization((0.9, 1.1)),\n",
        "    ]),\n",
        "    iaa.OneOf([ ## blur or sharpen\n",
        "        iaa.GaussianBlur(sigma=(0.0, 0.1)),\n",
        "        iaa.Sharpen(alpha=(0.0, 0.1)),\n",
        "    ]),\n",
        "    iaa.OneOf([\n",
        "         iaa.Fliplr(1.0),\n",
        "         iaa.Flipud(1.0),\n",
        "    ]),\n",
        "    iaa.OneOf([\n",
        "         iaa.Affine(\n",
        "             rotate=(88, 92),\n",
        "         ),\n",
        "         iaa.Affine(\n",
        "             rotate=(178, 182),\n",
        "         ),\n",
        "    ]),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e8b-znN5hoHP",
        "colab": {}
      },
      "source": [
        "augmentation_2 = iaa.Sometimes(5/6,\n",
        "                             iaa.OneOf(\n",
        "                                            [\n",
        "                                            iaa.Fliplr(1), \n",
        "                                            iaa.Flipud(1), \n",
        "                                            iaa.Affine(rotate=(178, 182)), \n",
        "                                            iaa.Affine(rotate=(88, 92)), \n",
        "                                            iaa.Affine(scale=(0.5, 1.5))\n",
        "                                             ]\n",
        "                                        )\n",
        "                                   )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RJIHSWs_j7Fk",
        "colab": {}
      },
      "source": [
        "augmentation = random.SystemRandom().choice([augmentation_1,\n",
        "                                             augmentation_2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SpvjtbWecTRl",
        "colab": {}
      },
      "source": [
        "# test on the same image as above\n",
        "imggrid = augmentation.draw_grid(image[:, :, 0], cols=5, rows=2)\n",
        "plt.figure(figsize=(30, 12))\n",
        "_ = plt.imshow(imggrid[:, :, 0], cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3QgfpVSHyvwo",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "7e65d2cecb283f446f34cdde19b663a8a8e9590f",
        "colab_type": "text",
        "id": "M4kt7LKuc78e"
      },
      "source": [
        "### Train the Mask-RCNN model\n",
        "\n",
        "Note: the following model is for demonstration purpose only. We have limited the training to one epoch, and have set nominal values for the Detector Configuration to reduce run-time. \n",
        "\n",
        "- dataset_train and dataset_val are derived from DetectorDataset \n",
        "- DetectorDataset loads images from image filenames and  masks from the annotation data\n",
        "- model is Mask-RCNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "138d6197fc8dce9f1f8a7b5a6c27aa2069698e03",
        "colab_type": "code",
        "id": "uo4y8kuJC1rF",
        "colab": {}
      },
      "source": [
        "if training_mode:\n",
        "  model = modellib.MaskRCNN(mode='training', \n",
        "                            config=config, \n",
        "                            model_dir=ROOT_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GUl_ltbdRmzX",
        "colab": {}
      },
      "source": [
        "# Exclude the last layers because they require a matching\n",
        "# number of classes\n",
        "if setup and training_mode and not os.path.exists(WEIGHTS_FILE):\n",
        "  model.load_weights(COCO_WEIGHTS_PATH, by_name=True, exclude=[\n",
        "    \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
        "    \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "  print ('Loaded pre-trained COCO model weights ... ')\n",
        "elif transfer_learning and training_mode:\n",
        "  model.load_weights(COCO_WEIGHTS_PATH, by_name=True, exclude=[\n",
        "    \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
        "    \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "  print ('Loaded pre-trained COCO model weights ... ')\n",
        "elif training_mode:\n",
        "  model.load_weights(WEIGHTS_FILE)\n",
        "  print ('Loaded pretrained model weights from: {} ...'.format(WEIGHTS_FILE))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "64cce2581ffdb8c2b1cb07948ada4a93f64874b0",
        "colab_type": "code",
        "id": "RVgNhHjl1lOS",
        "colab": {}
      },
      "source": [
        "LEARNING_RATE = 1e-4 #0.003\n",
        "\n",
        "# Train Mask-RCNN Model \n",
        "import warnings \n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "cf339a499519d174bcdf2311a1802f0e3acb1758",
        "colab_type": "code",
        "id": "AZ_z6vp9C1rW",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "## train heads with higher lr to speedup the learning\n",
        "if training_mode:\n",
        "  model.train(dataset_train, dataset_val,\n",
        "              learning_rate=LEARNING_RATE*2,\n",
        "              epochs=2,\n",
        "              layers='heads' if retrain_network else 'all',\n",
        "              augmentation= None if retrain_network else augmentation)  ## no need to augment yet\n",
        "\n",
        "  history = model.keras_model.history.history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8l_yMBoTnNlk",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "## train heads with higher lr to speedup the learning\n",
        "if training_mode and not debug:\n",
        "  model.train(dataset_train, dataset_val,\n",
        "              learning_rate=LEARNING_RATE*2,\n",
        "              epochs= 3 if debug else EPOCHS//2,\n",
        "              layers='all',\n",
        "              augmentation=augmentation)\n",
        "\n",
        "  new_history = model.keras_model.history.history\n",
        "  for k in new_history: history[k] = history[k] + new_history[k]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8004790d27f041793562e994bbe95edf67f8978b",
        "colab_type": "code",
        "id": "lbxtszd8C1rh",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "if training_mode:\n",
        "  model.train(dataset_train, dataset_val,\n",
        "              learning_rate=LEARNING_RATE,\n",
        "              epochs=4 if debug else EPOCHS,\n",
        "              layers='all',\n",
        "              augmentation=augmentation)\n",
        "\n",
        "  new_history = model.keras_model.history.history\n",
        "  for k in new_history: history[k] = history[k] + new_history[k]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8YqAMQiWbW8W",
        "colab": {}
      },
      "source": [
        "def weights_average(weights_files, \n",
        "                    model=None, \n",
        "                    file_path='averaged_weights.h5'):\n",
        "  for i in range(len(weights_files)-1):\n",
        "    if i == 0 and model is not None:\n",
        "      model.load_weights(weights_files[i],\n",
        "                                       by_name=True)\n",
        "      model_weights = model.get_weights()\n",
        "      model.load_weights(weights_files[i+1],\n",
        "                         by_name=True)\n",
        "      next_model_weights = model.get_weights()\n",
        "      for i, layer in enumerate(model.layers):\n",
        "        model_weights[i] = (model_weights[i] + next_model_weights[i])/2\n",
        "      model.set_weights(model_weights)\n",
        "      model.save_weights(file_path)\n",
        "    elif os.path.exists(file_path) and model is not None:\n",
        "      model.load_weights(file_path,\n",
        "                         by_name=True)\n",
        "      averaged_weights = model.get_weights()\n",
        "      model.load_weights(weights_files[i+1],\n",
        "                         by_name=True)\n",
        "      next_model_weights = model.get_weights()\n",
        "      for i, layer in enumerate(model.layers):\n",
        "        averaged_weights[i] = (averaged_weights[i] + next_model_weights[i])/2\n",
        "      model.set_weights(averaged_weights)\n",
        "      model.save_weights(file_path)\n",
        "  return True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "abbFtssghsgn",
        "colab": {}
      },
      "source": [
        "if training_mode and weights_averaging:  \n",
        "  weights_files = []\n",
        "  if os.path.exists(WEIGHTS_FILE):\n",
        "    weights_files.append(WEIGHTS_FILE)\n",
        "  # select trained model \n",
        "  dir_names = next(os.walk(model.model_dir))[1]\n",
        "  key = config.NAME.lower()\n",
        "  dir_names = filter(lambda f: f.startswith(key), \n",
        "                     dir_names)\n",
        "  dir_names = sorted(dir_names)\n",
        "\n",
        "  if not dir_names:\n",
        "      import errno\n",
        "      raise FileNotFoundError(\n",
        "          errno.ENOENT,\n",
        "          \"Could not find model directory under {}\".format(model_dir))\n",
        "\n",
        "  fps = []\n",
        "  # Pick last directory\n",
        "  try:\n",
        "    for d in dir_names: \n",
        "        dir_name = os.path.join(model.model_dir, d)\n",
        "        # Find the last checkpoint\n",
        "        checkpoints = next(os.walk(dir_name))[2]\n",
        "        checkpoints = filter(lambda f: f.startswith(\"mask_rcnn\"), \\\n",
        "                             checkpoints)\n",
        "        checkpoints = sorted(checkpoints)\n",
        "        print ('Found {} model weights ...'.format(len(checkpoints)))\n",
        "        for checkpoint in checkpoints:\n",
        "          weights_files.append(os.path.join(dir_name, checkpoint))\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rr1ur5xriiwG",
        "colab": {}
      },
      "source": [
        "if training_mode and weights_averaging:\n",
        "  print (weights_files)\n",
        "  weights_average(weights_files=weights_files, \n",
        "                  model=model.keras_model, \n",
        "                  file_path=AVERAGED_WEIGHTS_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "71abf32327a102e1c22e944b24d98690c71d9560",
        "colab_type": "code",
        "id": "IdCn_kwqC1r8",
        "colab": {}
      },
      "source": [
        "if training_mode:\n",
        "  epochs = range(1, len(history['loss'])+1)\n",
        "  pd.DataFrame(history, index=epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "fb3b69242b91dcc49697ff076ceeb957347372e1",
        "colab_type": "code",
        "id": "IhEtVRmaC1sG",
        "colab": {}
      },
      "source": [
        "if training_mode:\n",
        "  plt.figure(figsize=(21,11))\n",
        "\n",
        "  plt.subplot(231)\n",
        "  plt.plot(epochs, history[\"loss\"], label=\"Train loss\")\n",
        "  plt.plot(epochs, history[\"val_loss\"], label=\"Valid loss\")\n",
        "  plt.legend()\n",
        "  plt.subplot(232)\n",
        "  plt.plot(epochs, history[\"rpn_class_loss\"], label=\"Train RPN class ce\")\n",
        "  plt.plot(epochs, history[\"val_rpn_class_loss\"], label=\"Valid RPN class ce\")\n",
        "  plt.legend()\n",
        "  plt.subplot(233)\n",
        "  plt.plot(epochs, history[\"rpn_bbox_loss\"], label=\"Train RPN box loss\")\n",
        "  plt.plot(epochs, history[\"val_rpn_bbox_loss\"], label=\"Valid RPN box loss\")\n",
        "  plt.legend()\n",
        "  plt.subplot(234)\n",
        "  plt.plot(epochs, history[\"mrcnn_class_loss\"], label=\"Train MRCNN class ce\")\n",
        "  plt.plot(epochs, history[\"val_mrcnn_class_loss\"], label=\"Valid MRCNN class ce\")\n",
        "  plt.legend()\n",
        "  plt.subplot(235)\n",
        "  plt.plot(epochs, history[\"mrcnn_bbox_loss\"], label=\"Train MRCNN box loss\")\n",
        "  plt.plot(epochs, history[\"val_mrcnn_bbox_loss\"], label=\"Valid MRCNN box loss\")\n",
        "  plt.legend()\n",
        "  plt.subplot(236)\n",
        "  plt.plot(epochs, history[\"mrcnn_mask_loss\"], label=\"Train Mask loss\")\n",
        "  plt.plot(epochs, history[\"val_mrcnn_mask_loss\"], label=\"Valid Mask loss\")\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "5c2b38ecbc84575295dd62657ed175c5a0b72021",
        "colab_type": "code",
        "id": "yFDHZL43C1sP",
        "colab": {}
      },
      "source": [
        "if training_mode:\n",
        "  best_epoch = np.argmin(history[\"val_loss\"])\n",
        "  score = history[\"val_loss\"][best_epoch]\n",
        "  print(f'Best Epoch:{best_epoch+1} val_loss:{score}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "db5c10d3f7da099e5751a04a6e6d49819882ecd4",
        "colab_type": "code",
        "id": "eraRlzgPmmIZ",
        "colab": {}
      },
      "source": [
        "if training_mode:\n",
        "  # select trained model \n",
        "  dir_names = next(os.walk(model.model_dir))[1]\n",
        "  key = config.NAME.lower()\n",
        "  dir_names = filter(lambda f: f.startswith(key), \n",
        "                     dir_names)\n",
        "  dir_names = sorted(dir_names)\n",
        "\n",
        "  if not dir_names:\n",
        "      import errno\n",
        "      raise FileNotFoundError(\n",
        "          errno.ENOENT,\n",
        "          \"Could not find model directory under {}\".format(self.model_dir))\n",
        "\n",
        "  fps = []\n",
        "  # Pick last directory\n",
        "  try:\n",
        "    for d in dir_names: \n",
        "        dir_name = os.path.join(model.model_dir, d)\n",
        "        # Find the last checkpoint\n",
        "        checkpoints = next(os.walk(dir_name))[2]\n",
        "        checkpoints = filter(lambda f: f.startswith(\"mask_rcnn\"), \n",
        "                             checkpoints)\n",
        "        checkpoints = sorted(checkpoints)\n",
        "        if not checkpoints:\n",
        "            print('No weight files in {}'.format(dir_name))\n",
        "        else:\n",
        "            checkpoint = os.path.join(dir_name, \n",
        "                                      checkpoints[best_epoch])\n",
        "            fps.append(checkpoint)\n",
        "\n",
        "    model_path = sorted(fps)[-1]\n",
        "    print('Found model {}'.format(model_path))\n",
        "  except:\n",
        "    model_path = WEIGHTS_FILE\n",
        "    print ('Best model path: {} ...'.format(model_path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNho6j6oT7Qp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_best_epoch = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FqIYeqadpLcX",
        "colab": {}
      },
      "source": [
        "if use_best_epoch and training_mode:\n",
        "  model_path = model_path\n",
        "  print ('Saving model file: {}'.format(model_path))\n",
        "elif weights_averaging and training_mode and os.path.exists(AVERAGED_WEIGHTS_FILE):\n",
        "  model_path = AVERAGED_WEIGHTS_FILE\n",
        "  print ('Saving model file: {}'.format(model_path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OIu7PzBT7RA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if training_mode:\n",
        "  ! mv {model_path} {WEIGHTS_FILE}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ETFtQ_v-2Uri",
        "colab": {}
      },
      "source": [
        "if training_mode and colab_mode:\n",
        "  ! cp {WEIGHTS_FILE} {GOOGLE_DRIVE}/\n",
        "  ! cp {AVERAGED_WEIGHTS_FILE} {GOOGLE_DRIVE}/\n",
        "elif training_mode:\n",
        "  ! rclone copy {WEIGHTS_FILE} {RCLONE_DRIVE}: -v\n",
        "  ! rclone copy {AVERAGED_WEIGHTS_FILE} {RCLONE_DRIVE}: -v\n",
        "print ('Saved model weights: {} to the cloud...'.format(model_path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GgR8Iq5FoPgy"
      },
      "source": [
        "### Prepare the Mask-RCNN model for inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "52138636b2ae5bf444bba808518cd8313bde65cd",
        "colab_type": "code",
        "id": "TgpT9AzC2Bgz",
        "colab": {}
      },
      "source": [
        "class InferenceConfig(DetectorConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    DETECTION_MIN_CONFIDENCE = 0.9\n",
        "\n",
        "inference_config = InferenceConfig()\n",
        "\n",
        "# Recreate the model in inference mode\n",
        "model = modellib.MaskRCNN(mode='inference', \n",
        "                          config=inference_config,\n",
        "                          model_dir=ROOT_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rYDEpkfVQsGA",
        "colab": {}
      },
      "source": [
        "# Load trained weights (fill in path to trained weights here)\n",
        "try:\n",
        "  assert model_path != \"\", \"Provide path to trained weights\"\n",
        "  model.load_weights(model_path, by_name=True)\n",
        "  print(\"Loaded weights from \", model_path)\n",
        "except:\n",
        "  model.load_weights(WEIGHTS_FILE, by_name=True)\n",
        "  print (\"Loaded weights from \", WEIGHTS_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "e13c61bee23b791c61ecf1256f7512295cd4d9ab",
        "colab_type": "code",
        "id": "9mTBig7D2BjU",
        "colab": {}
      },
      "source": [
        "# set color for class\n",
        "def get_colors_for_class_ids(class_ids):\n",
        "    colors = []\n",
        "    for class_id in class_ids:\n",
        "        if class_id == 1:\n",
        "            colors.append((.941, .204, .204))\n",
        "    return colors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "f99fbd3f31ff1a2bd66764835c9b646375364598",
        "colab_type": "text",
        "id": "A8EiL2LOiCr_"
      },
      "source": [
        "### Comparing predictions to the expected values \n",
        "Generating comparison between the prediction masks and the expected masks, using the validation dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "186412199e25b98719f71cfe5e8869abcce516c4",
        "colab_type": "code",
        "id": "irheTbrW2Bl0",
        "colab": {}
      },
      "source": [
        "# Show few example of ground truth vs. predictions on the validation dataset \n",
        "dataset = dataset_val\n",
        "fig = plt.figure(figsize=(10, 40))\n",
        "\n",
        "for i in range(8):\n",
        "\n",
        "    image_id = random.choice(dataset.image_ids)\n",
        "    \n",
        "    original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "        modellib.load_image_gt(dataset_val, \n",
        "                               inference_config, \n",
        "                               image_id, \n",
        "                               use_mini_mask=False)\n",
        "    \n",
        "    # print(original_image.shape)\n",
        "    plt.subplot(8, 2, 2*i + 1)\n",
        "    visualize.display_instances(original_image, \n",
        "                                gt_bbox, \n",
        "                                gt_mask, \n",
        "                                gt_class_id, \n",
        "                                dataset.class_names,\n",
        "                                colors=get_colors_for_class_ids(gt_class_id), \n",
        "                                ax=fig.axes[-1])\n",
        "    \n",
        "    plt.subplot(8, 2, 2*i + 2)\n",
        "    results = model.detect([original_image]) #, verbose=1)\n",
        "    r = results[0]\n",
        "    visualize.display_instances(original_image, \n",
        "                                r['rois'], \n",
        "                                r['masks'], \n",
        "                                r['class_ids'], \n",
        "                                dataset.class_names, \n",
        "                                r['scores'], \n",
        "                                colors=get_colors_for_class_ids(r['class_ids']), \n",
        "                                ax=fig.axes[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "04LFwGeX04NQ",
        "colab": {}
      },
      "source": [
        "if (setup or not os.path.exists(SUBMISSION_FILE)) and colab_mode:\n",
        "  ! cp {GOOGLE_DRIVE}/{SUBMISSION_FILENAME} {DATA_DIR}\n",
        "elif (setup or not os.path.exists(SUBMISSION_FILE)):\n",
        "  ! rclone copy {RCLONE_DRIVE}:{SUBMISSION_FILE} {DATA_DIR}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "164e18701a830bc6c42a791feea13549de37289b",
        "colab_type": "text",
        "id": "WcV1cL_aiSc4"
      },
      "source": [
        "### Final steps - Create the filtered submission file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "02321d63a0610d91f9dae621002dc7d4cce57034",
        "colab_type": "code",
        "id": "alibO54fC1tP",
        "colab": {}
      },
      "source": [
        "sub = pd.read_csv(SUBMISSION_FILE)\n",
        "\n",
        "tmp = sub.groupby('ImageId')['ImageId'].count().reset_index(name='N')\n",
        "tmp = tmp.loc[tmp.N >= 1 if stage_2 else tmp.N > 1 ] #find image id's with more than 1 row -> has pneumothorax mask!\n",
        "\n",
        "possible_patients = tmp.ImageId.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w2-BsSwbLRzb",
        "colab": {}
      },
      "source": [
        "print ('Number of possible patients: {} ...'.format(len(possible_patients)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "4a5c0c6134408ddbf5a34496d7e9d7be5692e9a1",
        "colab_type": "code",
        "id": "C6UWVrbM2Bob",
        "colab": {}
      },
      "source": [
        "# Make predictions on test images, write out sample submission\n",
        "def predict(image_fps, filepath='submission_maskRCNN_ResNet100.csv', min_conf=config.DETECTION_MIN_CONFIDENCE):\n",
        "    # assume square image\n",
        "    resize_factor = ORIG_SIZE / config.IMAGE_SHAPE[0]\n",
        "    with open(filepath, 'w') as file:\n",
        "        file.write(\"ImageId,EncodedPixels\\n\")\n",
        "\n",
        "        for fp in tqdm(image_fps):\n",
        "            #print (fp)\n",
        "            image_id = fp.split('/')[-1][:-4]\n",
        "            found = False\n",
        "            \n",
        "            if image_id in possible_patients:\n",
        "                ds = pydicom.read_file(fp)\n",
        "                image = ds.pixel_array\n",
        "                # If grayscale. Convert to RGB for consistency.\n",
        "                if len(image.shape) != 3 or image.shape[2] != 3:\n",
        "                    image = np.stack((image,) * 3, -1)\n",
        "                image, window, scale, padding, crop = utils.resize_image(\n",
        "                    image,\n",
        "                    min_dim=config.IMAGE_MIN_DIM,\n",
        "                    min_scale=config.IMAGE_MIN_SCALE,\n",
        "                    max_dim=config.IMAGE_MAX_DIM,\n",
        "                    mode=config.IMAGE_RESIZE_MODE)\n",
        "\n",
        "                results = model.detect([image])\n",
        "                r = results[0]\n",
        "\n",
        "                assert( len(r['rois']) == len(r['class_ids']) == len(r['scores']) )\n",
        "                if len(r['rois']) == 0:\n",
        "                    pass ## no pneumothorax; '-1' written below\n",
        "                else:\n",
        "                    num_instances = len(r['rois'])\n",
        "\n",
        "                    for i in range(num_instances):\n",
        "                        if r['scores'][i] > min_conf and np.sum(r['masks'][...,i]) > 1:\n",
        "#                             print(r['scores'][i], r['rois'][i], r['masks'].shape, np.max(r['masks'][...,i]))\n",
        "#                             plt.imshow(r['masks'][...,i], cmap=get_cmap('jet'))\n",
        "                            file.write(image_id + \",\" + mask2rle(r['masks'][...,i].T*255, IMAGE_DIM[0], IMAGE_DIM[1]) + \"\\n\")\n",
        "                            found = True\n",
        "\n",
        "            if not found:\n",
        "                file.write(image_id + \",-1\\n\")  ## no pneumothorax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "0406e7f5aaa4867782c4f9c064f90bba386128e7",
        "colab_type": "code",
        "id": "C5cBpNka2Bsv",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "submission_fp = os.path.join(ROOT_DIR, 'submission_{}.csv'.format(NOTEBOOK_ID))\n",
        "predict(test_image_fps, filepath=submission_fp)\n",
        "print(submission_fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "3fd8d178fc51ef0bca94fbb3f423160f08a77edc",
        "colab_type": "code",
        "id": "_BjPE_Ee9rbA",
        "colab": {}
      },
      "source": [
        "sub = pd.read_csv(submission_fp)\n",
        "print(sub.EncodedPixels.isnull().sum(), sub.ImageId.nunique(), sub.EncodedPixels.isnull().sum()/sub.ImageId.nunique())\n",
        "sub.head(50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "ea110f197abc2acb1c3435383f7259079dc0eb0e",
        "colab_type": "code",
        "id": "64hgTl9dC1uI",
        "colab": {}
      },
      "source": [
        "# show a few test image detection example\n",
        "def visualize_test():\n",
        "    ids_with_mask = sub[sub.EncodedPixels != '-1'].ImageId.values\n",
        "    fp = random.choice([fp for fp in test_image_fps if fp.split('/')[-1][:-4] in ids_with_mask])\n",
        "#     import pdb; pdb.set_trace()\n",
        "    \n",
        "    # original image\n",
        "    image_id = fp.split('/')[-1][:-4]\n",
        "    ds = pydicom.read_file(fp)\n",
        "    image = ds.pixel_array\n",
        "    \n",
        "    # assume square image \n",
        "    resize_factor = 1 ## ORIG_SIZE / config.IMAGE_SHAPE[0]\n",
        "    \n",
        "    # If grayscale. Convert to RGB for consistency.\n",
        "    if len(image.shape) != 3 or image.shape[2] != 3:\n",
        "        image = np.stack((image,) * 3, -1) \n",
        "    image, window, scale, padding, crop = utils.resize_image(\n",
        "        image,\n",
        "        min_dim=config.IMAGE_MIN_DIM,\n",
        "        min_scale=config.IMAGE_MIN_SCALE,\n",
        "        max_dim=config.IMAGE_MAX_DIM,\n",
        "        mode=config.IMAGE_RESIZE_MODE)\n",
        "\n",
        "    results = model.detect([image])\n",
        "    r = results[0]\n",
        "    for bbox in r['rois']: \n",
        "#         print(bbox)\n",
        "        x1 = int(bbox[1] * resize_factor)\n",
        "        y1 = int(bbox[0] * resize_factor)\n",
        "        x2 = int(bbox[3] * resize_factor)\n",
        "        y2 = int(bbox[2]  * resize_factor)\n",
        "        cv2.rectangle(image, (x1,y1), (x2,y2), (77, 255, 9), 3, 1)\n",
        "        width = x2 - x1\n",
        "        height = y2 - y1\n",
        "#         print(\"x {} y {} h {} w {}\".format(x1, y1, width, height))\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    ax1.set_title(image_id)\n",
        "    ax1.imshow(image)\n",
        "    ax2.set_title(f\"{np.count_nonzero(image_id == ids_with_mask)} masks in csv\")\n",
        "    ax2.imshow(masks_as_color(sub.query(f\"ImageId=='{image_id}'\")['EncodedPixels'].values, IMAGE_DIM))\n",
        "    ax3.set_title(f\"{len(r['rois'])} masks predicted again\")\n",
        "    ax3.imshow(r['masks'].max(-1))  # get max (overlap) between all masks in this prediction\n",
        "#     print(f\"ImageId=='{image_id}'\", sub.query(f\"ImageId=='{image_id}'\")['EncodedPixels'])\n",
        "\n",
        "for i in range(8):\n",
        "    visualize_test()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jxhQx-Zb1iDR",
        "colab": {}
      },
      "source": [
        "# ! mkdir /root/.kaggle/\n",
        "# ! mv /content/kaggle.json /root/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "835a15c9d018acd5deb16e9e02f9b765f68d0e78",
        "colab_type": "code",
        "id": "BQyVnzWDC1ub",
        "colab": {}
      },
      "source": [
        "#!kaggle competitions submit -c siim-acr-pneumothorax-segmentation -f {submission_fp} -m \"Keras Mask RCNN\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w2Q77Hvb1uy0",
        "colab": {}
      },
      "source": [
        "if colab_mode:\n",
        "    from google.colab import files\n",
        "    files.download(submission_fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WYNnp_w5yVKa",
        "colab": {}
      },
      "source": [
        "! rm -r /content/pneumothorax*/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u3YAPijgR3Vt",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}